import requests
import time
import json
import csv
from urllib.parse import quote

LANGUAGE = "en"  # Langue par dÃ©faut pour la recherche
LIMIT = 50  # Nombre de rÃ©sultats par page
OFFSET = 0  # Offset pour la pagination

search_terme = input("Entrez le terme de recherche (par exemple, 'aero'): ")
search_term = quote(search_terme)  # Encoder le terme de recherche pour l'URL
if not search_term:
    print("âŒ Le terme de recherche ne peut pas Ãªtre vide.")
    exit(1)

class WikidataAeroScraper:
    def __init__(self):
        self.endpoint = "https://query.wikidata.org/sparql"
        self.headers = {
            'User-Agent': 'WikidataAeroBot/1.0 (https://github.com/May8326/wikidata-scraper)',
            'Accept': 'application/sparql-results+json'
        }
        self.results = []

    def build_query(self, search_term, language, limit, offset):
        """Construit la requÃªte SPARQL avec l'offset donnÃ©"""
        query = f"""
        SELECT ?item ?itemLabel WHERE {{
          SERVICE wikibase:mwapi {{
            bd:serviceParam wikibase:endpoint "www.wikidata.org";
                            wikibase:api "EntitySearch";
                            mwapi:search "{search_term}";
                            mwapi:language "{language}";
                            mwapi:limit "{limit}";
                            mwapi:continue "{offset}".
            ?item wikibase:apiOutputItem mwapi:item.
          }}
          
          SERVICE wikibase:label {{ 
            bd:serviceParam wikibase:language "en". 
          }}
        }}
        """
        return query
    
    def execute_query(self, query):
        """ExÃ©cute une requÃªte SPARQL et retourne les rÃ©sultats"""
        try:
            response = requests.get(
                self.endpoint,
                params={'query': query, 'format': 'json'},
                headers=self.headers,
                timeout=30
            )
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"Erreur lors de la requÃªte: {e}")
            return None
    
    def extract_results(self, data):
        """Extrait les rÃ©sultats du JSON retournÃ©"""
        if not data or 'results' not in data:
            return []
        
        results = []
        for binding in data['results']['bindings']:
            item_uri = binding.get('item', {}).get('value', '')
            item_label = binding.get('itemLabel', {}).get('value', '')
            
            # Extraire l'ID Wikidata de l'URI
            item_id = item_uri.split('/')[-1] if item_uri else ''
            
            results.append({
                'wikidata_id': item_id,
                'label': item_label,
                'uri': item_uri
            })
        
        return results
    
    def scrape_all_results(self):
        """Scrape tous les rÃ©sultats en paginant automatiquement"""
        offset = 0
        page = 1
        total_results = 0
        
        print("ğŸš€ DÃ©but du scraping des entitÃ©s contenant 'aero'...")
        print("=" * 60)
        
        while True:
            print(f"ğŸ“„ Page {page} (offset: {offset})...")
            
            # Construire et exÃ©cuter la requÃªte
            query = self.build_query(search_term, LANGUAGE, LIMIT, offset)
            data = self.execute_query(query)
            
            if not data:
                print("âŒ Erreur lors de l'exÃ©cution de la requÃªte")
                break
            
            # Extraire les rÃ©sultats
            page_results = self.extract_results(data)
            
            if not page_results:
                print(f"âœ… Fin des rÃ©sultats atteinte (page {page})")
                break
            
            # Ajouter aux rÃ©sultats totaux
            self.results.extend(page_results)
            total_results += len(page_results)
            
            print(f"   â†’ {len(page_results)} rÃ©sultats trouvÃ©s")
            print(f"   â†’ Total cumulÃ©: {total_results}")
            
            # VÃ©rifier si on a moins de 50 rÃ©sultats (derniÃ¨re page)
            if len(page_results) < 50:
                print(f"âœ… DerniÃ¨re page atteinte ({len(page_results)} < 50 rÃ©sultats)")
                break
            
            # PrÃ©parer la page suivante
            offset += 50
            page += 1
            
            # Pause pour Ãªtre respectueux envers l'API
            time.sleep(1)
        
        print("=" * 60)
        print(f"ğŸ‰ Scraping terminÃ©! Total: {total_results} rÃ©sultats")
        return self.results
    
    def save_to_csv(self, filename="wikidata_aero_results.csv"):
        """Sauvegarde les rÃ©sultats en CSV"""
        if not self.results:
            print("âŒ Aucun rÃ©sultat Ã  sauvegarder")
            return
        
        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['wikidata_id', 'label', 'uri']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            writer.writeheader()
            for result in self.results:
                writer.writerow(result)
        
        print(f"ğŸ’¾ RÃ©sultats sauvegardÃ©s dans: {filename}")
    
    def save_to_json(self, filename="wikidata_aero_results.json"):
        """Sauvegarde les rÃ©sultats en JSON"""
        if not self.results:
            print("âŒ Aucun rÃ©sultat Ã  sauvegarder")
            return
        
        with open(filename, 'w', encoding='utf-8') as jsonfile:
            json.dump(self.results, jsonfile, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ RÃ©sultats sauvegardÃ©s dans: {filename}")
    
    def print_sample_results(self, limit=10):
        """Affiche un Ã©chantillon des rÃ©sultats"""
        if not self.results:
            print("âŒ Aucun rÃ©sultat Ã  afficher")
            return
        
        print(f"\nğŸ“‹ Ã‰chantillon des rÃ©sultats (premiers {limit}):")
        print("-" * 80)
        
        for i, result in enumerate(self.results[:limit]):
            print(f"{i+1:2d}. {result['wikidata_id']:12s} | {result['label']}")
        
        if len(self.results) > limit:
            print(f"... et {len(self.results) - limit} autres rÃ©sultats")

def main():
    """Fonction principale"""
    scraper = WikidataAeroScraper()
    
    try:
        # Scraper tous les rÃ©sultats
        results = scraper.scrape_all_results()
        
        if results:
            # Afficher un Ã©chantillon
            scraper.print_sample_results()
            
            # Sauvegarder
            scraper.save_to_csv()
            scraper.save_to_json()
            
            print(f"\nğŸ¯ Mission accomplie! {len(results)} entitÃ©s 'aero' rÃ©cupÃ©rÃ©es.")
        else:
            print("âŒ Aucun rÃ©sultat trouvÃ©")
            
    except KeyboardInterrupt:
        print("\nâ›” ArrÃªt demandÃ© par l'utilisateur")
        if scraper.results:
            print(f"ğŸ’¾ Sauvegarde des {len(scraper.results)} rÃ©sultats partiels...")
            scraper.save_to_csv("wikidata_aero_partial.csv")
    except Exception as e:
        print(f"âŒ Erreur inattendue: {e}")

if __name__ == "__main__":
    main()