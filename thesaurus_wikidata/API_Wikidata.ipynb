{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "339b9f1f",
   "metadata": {},
   "source": [
    "# üöÄ Requ√™te WIKIDATA\n",
    "\n",
    "## üìë Mode d'emploi\n",
    "\n",
    "Suivre les instructions au fil du notebook et ex√©cuter une √† une les cellules de code en appuyant sur la petite fl√®che √† gauche (‚ñ∂Ô∏è)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f576147d",
   "metadata": {},
   "source": [
    "## üî® Construction de l'environnement n√©cessaire et configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74111c85",
   "metadata": {},
   "source": [
    "### Installation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdaf8794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ Installation termin√©e !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# üì¶ MODULES NECESSAIRES : NORMALEMENT, NE RUN QU'A LA PREMIERE UTILISATION\n",
    "%pip install -q SPARQLWrapper tqdm pandas\n",
    "\n",
    "print(\"‚úÖ Installation termin√©e !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e7bad",
   "metadata": {},
   "source": [
    "### Configuration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7becfc5d",
   "metadata": {},
   "source": [
    "#### Param√®tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86a25c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Imports termin√©s !\n"
     ]
    }
   ],
   "source": [
    "# üîß IMPORTS PYTHON\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "print(\"üîß Imports termin√©s !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f700d27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "                                      üöÄ CONFIGURATION TERMIN√âE                                      \n",
      "====================================================================================================\n",
      "üìÅ Dossier de sortie                  ./output\n",
      "‚è±Ô∏è  Rate limit                        3.0s entre requ√™tes\n",
      "üì¶ Taille des batches                 10\n",
      "üîÑ Nombre maximal de tentatives       3\n",
      "‚è≥ D√©lai de timeout des requ√™tes      60s\n",
      "üîç Taille du batch d'enrich.         15\n",
      "üîÅ Limite de boucle                  100 it√©rations\n",
      "üåê Endpoint Wikidata                 https://query.wikidata.org/sparql\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# üîß CONFIGURATION PERSONNALISABLE DE LA REQUETE\n",
    "\n",
    "WIKIDATA_ENDPOINT = \"https://query.wikidata.org/sparql\" # Endpoint SPARQL de Wikidata\n",
    "RATE_LIMIT_DELAY = 3.0  # D√©lai entre les requ√™tes\n",
    "BATCH_SIZE = 10  # Taille des batches pour les requ√™tes\n",
    "MAX_RETRIES = 3  # Nombre maximal de tentatives en cas d'√©chec\n",
    "REQUEST_TIMEOUT = 60 # Temps au bout duquel un requ√™te s'arr√™te automatiquement s'il n'y a pas de r√©ponse (en secondes)\n",
    "ENRICHMENT_BATCH_SIZE = 15 # Taille du batch pour l'enrichissement des donn√©es\n",
    "LOOP_LIMIT = 100 # Nombre r√©ponses limite par boucle (permet de requ√™ter petit √† petit pour ne pas surcharger l'API)\n",
    "LOOP_OFFSET = 0 # D√©calage pour la pagination des r√©sultats\n",
    "MAX_RESULTS = None  # Nombre maximal de r√©sultats √† r√©cup√©rer (pour √©viter de surcharger l'API)\n",
    "\n",
    "\n",
    "# üìÅ Configuration du dossier de sortie \n",
    "output_dir = \"./output\" # Param√®tre √† remplacer si vous souhaitez un autre dossier de sortie (faire un copier coller du chemin d'un fichier)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"üöÄ CONFIGURATION TERMIN√âE\".center(100))\n",
    "print(\"=\"*100)\n",
    "print(\n",
    "    f\"üìÅ Dossier de sortie                  {output_dir}\\n\"\n",
    "    f\"‚è±Ô∏è  Rate limit                        {RATE_LIMIT_DELAY}s entre requ√™tes\\n\"\n",
    "    f\"üì¶ Taille des batches                 {BATCH_SIZE}\\n\"\n",
    "    f\"üîÑ Nombre maximal de tentatives       {MAX_RETRIES}\\n\"\n",
    "    f\"‚è≥ D√©lai de timeout des requ√™tes      {REQUEST_TIMEOUT}s\\n\"\n",
    "    f\"üîç Taille du batch d'enrich.         {ENRICHMENT_BATCH_SIZE}\\n\"\n",
    "    f\"üîÅ Limite de boucle                  {LOOP_LIMIT} it√©rations\\n\"\n",
    "    f\"üåê Endpoint Wikidata                 {WIKIDATA_ENDPOINT}\"\n",
    ")\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27ffccf",
   "metadata": {},
   "source": [
    "#### Client sparql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519640a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonctions de requ√™te SPARQL pr√™tes !\n"
     ]
    }
   ],
   "source": [
    "# üõ†Ô∏è FONCTION POUR CHOISIR UN TERME A REQU√äTER\n",
    "\n",
    "def ask_query_term():\n",
    "    \"\"\"\n",
    "    Fonction pour demander √† l'utilisateur de choisir entre recherche par id ou par label\n",
    "    Et lui demande de rentrer la valeur √† rechercher\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîç Choisissez le type de recherche :\")\n",
    "    print(\"1. Recherche par ID (ex: Q42)\")\n",
    "    print(\"2. Recherche par label (ex: Douglas Adams)\")\n",
    "    \n",
    "    choice = input(\"Entrez 1 ou 2 : \").strip()\n",
    "    \n",
    "    if choice == \"2\":\n",
    "        search_term = input(\"Entrez le nom de l'entit√© √† rechercher dans wikidata, en anglais (ex: aeronautics) : \").strip()\n",
    "        if not search_term:\n",
    "            print(\"‚ùå Aucun nom d'entit√© fourni.\")\n",
    "            exit(1)\n",
    "        return f'\"{search_term}\"'  # Guillemets pour recherche textuelle\n",
    "    elif choice == \"1\":\n",
    "        search_term = input(\"Entrez l'ID de l'entit√© √† rechercher dans wikidata (ex: Q42) : \").strip()\n",
    "        # Validation de l'ID de l'entit√©\n",
    "        if not search_term or not re.match(r\"^Q\\d+$\", search_term):\n",
    "            print(\"‚ùå ID d'entit√© invalide. Veuillez entrer un ID valide (ex: Q42).\")\n",
    "            exit(1)\n",
    "        return search_term  # ‚Üê Retourner juste l'ID sans pr√©fixe\n",
    "    else:\n",
    "        print(\"Choix invalide, veuillez r√©essayer.\")\n",
    "        return ask_query_term()\n",
    "\n",
    "# üõ†Ô∏è FONCTIONS DE PARAMETRAGE DES REQU√äTES ET DU CARNET\n",
    "\n",
    "################################################################################\n",
    "# FONCTION POUR CR√âER UN CLIENT SPARQL\n",
    "################################################################################\n",
    "def create_sparql_client():\n",
    "    \"\"\"\n",
    "    Cr√©e un client SPARQL pour interagir avec Wikidata\n",
    "    :return: Instance de SPARQLWrapper configur√©e pour Wikidata\n",
    "    \"\"\"\n",
    "    sparql = SPARQLWrapper(WIKIDATA_ENDPOINT)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    sparql.setTimeout(REQUEST_TIMEOUT)\n",
    "    return sparql\n",
    "\n",
    "################################################################################\n",
    "# FONCTION PRINCIPALE POUR EX√âCUTER UNE REQU√äTE SPARQL\n",
    "################################################################################\n",
    "def execute_sparql_query(query, max_retries=MAX_RETRIES, use_pagination=False, limit=None, max_results=None):\n",
    "    \"\"\"\n",
    "    Ex√©cute une requ√™te SPARQL avec gestion des erreurs, rate limiting et pagination optionnelle\n",
    "    :param query: La requ√™te SPARQL √† ex√©cuter\n",
    "    :param max_retries: Nombre maximum de tentatives en cas d'√©chec\n",
    "    :param use_pagination: Si True, active la pagination automatique\n",
    "    :param limit: Taille des pages pour la pagination (d√©faut: LOOP_LIMIT)\n",
    "    :param max_results: Nombre maximum de r√©sultats √† r√©cup√©rer (None = illimit√©)\n",
    "    :return: R√©sultats de la requ√™te ou une liste vide en cas d'√©chec\n",
    "    \"\"\"\n",
    "    sparql = create_sparql_client()\n",
    "    print(f\"üîç Ex√©cution de la requ√™te SPARQL :\\n{query}\\n\")\n",
    "    \n",
    "    # MODE SIMPLE SANS PAGINATION\n",
    "    if not use_pagination:\n",
    "        print(\"üöÄ Mode simple (sans pagination) - Envoi de la requ√™te...\")\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                print(f\"üì° Tentative {attempt + 1}/{max_retries} - Envoi de la requ√™te...\")\n",
    "                sparql.setQuery(query)\n",
    "                \n",
    "                print(\"‚è≥ Attente de la r√©ponse du serveur...\")\n",
    "                results = sparql.query().convert()\n",
    "                \n",
    "                result_count = len(results[\"results\"][\"bindings\"])\n",
    "                print(f\"‚úÖ Requ√™te r√©ussie ! {result_count} r√©sultats obtenus\")\n",
    "                \n",
    "                \n",
    "                return results[\"results\"][\"bindings\"]\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Tentative {attempt + 1}/{max_retries} √©chou√©e: {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = RATE_LIMIT_DELAY * (attempt + 2)\n",
    "                    print(f\"‚è≥ Attente de {wait_time}s avant nouvelle tentative...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    print(f\"‚ùå Requ√™te √©chou√©e apr√®s {max_retries} tentatives\")\n",
    "                    return []\n",
    "        return []\n",
    "    \n",
    "    # MODE PAGINATION ACTIVE\n",
    "    if limit is None:\n",
    "        limit = LOOP_LIMIT\n",
    "    \n",
    "    all_results = []\n",
    "    offset = 0\n",
    "    \n",
    "    print(f\"üîç D√©but de la pagination (limit={limit})...\")\n",
    "    \n",
    "    while True:\n",
    "        paginated_query = f\"{query.rstrip()} LIMIT {limit} OFFSET {offset}\"\n",
    "        print(f\"üîπ Requ√™te OFFSET {offset}, LIMIT {limit}\")\n",
    "        success = False\n",
    "        bindings = []\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                sparql.setQuery(paginated_query)\n",
    "                results = sparql.query().convert()\n",
    "                bindings = results[\"results\"][\"bindings\"]\n",
    "                success = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Tentative {attempt + 1}/{max_retries} √©chou√©e √† l'offset {offset}: {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(RATE_LIMIT_DELAY * (attempt + 2))\n",
    "                else:\n",
    "                    print(f\"‚ùå Requ√™te √©chou√©e apr√®s {max_retries} tentatives √† l'offset {offset}\")\n",
    "                    return all_results  # Retourner ce qu'on a r√©ussi √† r√©cup√©rer\n",
    "\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        if not bindings:\n",
    "            print(\"‚úÖ Fin de la pagination - Aucun r√©sultat suppl√©mentaire.\")\n",
    "            break\n",
    "\n",
    "        all_results.extend(bindings)\n",
    "        print(f\"‚úÖ R√©cup√©r√© {len(bindings)} r√©sultats (total: {len(all_results)})\")\n",
    "        \n",
    "        if max_results and len(all_results) >= max_results:\n",
    "            print(f\"üéØ Limite de {max_results} r√©sultats atteinte.\")\n",
    "            all_results = all_results[:max_results]\n",
    "            break\n",
    "\n",
    "        offset += limit\n",
    "        print(f\"‚è≥ Attente de {RATE_LIMIT_DELAY}s...\")\n",
    "        time.sleep(RATE_LIMIT_DELAY)\n",
    "    \n",
    "    print(f\"üéØ Total final r√©cup√©r√© : {len(all_results)} r√©sultats.\")\n",
    "    return all_results\n",
    "\n",
    "################################################################################\n",
    "# FONCTION UTILITAIRE POUR EXTRAIRE LES ID DE WIKIDATA\n",
    "################################################################################\n",
    "def clean_entity_id(entity_uri):\n",
    "    \"\"\"\n",
    "    Extrait l'ID d'une entit√© √† partir de son URI\n",
    "    :param entity_uri: URI de l'entit√© (ex: \"http://www.wikidata.org/entity/Q42'\")\n",
    "    :return: ID de l'entit√© (ex: \"Q42\") ou une cha√Æne vide si l'URI est vide\n",
    "    \"\"\"\n",
    "    if not entity_uri:\n",
    "        return \"\"\n",
    "    return entity_uri.split(\"/\")[-1] if \"/\" in entity_uri else entity_uri\n",
    "\n",
    "################################################################################\n",
    "# FONCTION POUR EX√âCUTER DES REQU√äTES SPARQL EN BATCH : VERIFIER L'UTILITE\n",
    "################################################################################\n",
    "def execute_batch_queries(queries, description=\"Requ√™tes\", use_pagination=False):\n",
    "    \"\"\"\n",
    "    Ex√©cute une liste de requ√™tes SPARQL en batch\n",
    "    :param queries: Requ√™te SPARQL unique ou liste de requ√™tes\n",
    "    :param description: Description de la t√¢che pour le logging\n",
    "    :param use_pagination: Si True, active la pagination pour chaque requ√™te\n",
    "    :return: Liste de tous les r√©sultats combin√©s\n",
    "    \"\"\"\n",
    "    # V√©rifier si queries est une string ou une liste\n",
    "    if isinstance(queries, str):\n",
    "        # Si c'est une string, c'est une seule requ√™te\n",
    "        print(f\"üîπ Ex√©cution d'une requ√™te unique: {description}\")\n",
    "        return execute_sparql_query(queries, use_pagination=use_pagination)\n",
    "    \n",
    "    # Si c'est une liste, traiter comme batch\n",
    "    all_results = []\n",
    "    for i, query in enumerate(tqdm(queries, desc=description)):\n",
    "        results = execute_sparql_query(query, use_pagination=use_pagination)\n",
    "        all_results.extend(results)\n",
    "        if (i + 1) % BATCH_SIZE == 0:\n",
    "            time.sleep(RATE_LIMIT_DELAY)\n",
    "    return all_results\n",
    "\n",
    "################################################################################\n",
    "# FONCTION POUR EX√âCUTER UNE REQU√äTE SPARQL AVEC PAGINATION\n",
    "################################################################################\n",
    "def execute_paginated_query(base_query, limit=None, max_results=MAX_RESULTS, ask_term=False):\n",
    "    \"\"\"\n",
    "    Fonction helper pour ex√©cuter facilement une requ√™te avec pagination\n",
    "    \"\"\"\n",
    "    \n",
    "    # Si ask_term=True, on demande le terme √† l'utilisateur\n",
    "    if ask_term:\n",
    "        search_term = ask_query_term()\n",
    "        print(f\"üîç Recherche pour le terme : {search_term}\")\n",
    "        if search_term:\n",
    "            # D√©terminer le type de recherche et formater correctement\n",
    "            if search_term.startswith('Q'):\n",
    "                # Recherche par ID - ajouter le pr√©fixe wd:\n",
    "                formatted_term = f\"wd:{search_term}\"\n",
    "            else:\n",
    "                # Recherche textuelle - utiliser tel quel\n",
    "                formatted_term = search_term\n",
    "            \n",
    "            # Remplacer {{search_term}} dans la requ√™te\n",
    "            base_query = base_query.replace(\"{{search_term}}\", formatted_term)\n",
    "        else:\n",
    "            print(\"‚ùå Aucun terme fourni, abandon de la requ√™te.\")\n",
    "            return []\n",
    "    \n",
    "    return execute_sparql_query(\n",
    "        base_query, \n",
    "        use_pagination=True, \n",
    "        limit=limit, \n",
    "        max_results=max_results\n",
    "    )\n",
    "print(\"‚úÖ Fonctions de requ√™te SPARQL pr√™tes !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28847dc",
   "metadata": {},
   "source": [
    "#### Outils Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e417f9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINITION DES TERMES A CHERCHER\n",
    "# =================================================================================\n",
    "\n",
    "#search_term = None  # Initialisation de la variable pour le terme de recherche\n",
    "\n",
    "# def ask_query_term():\n",
    "#     \"\"\"\n",
    "#     Fonction pour demander √† l'utilisateur de choisir entre recherche par id ou par label\n",
    "#     Et lui demande de rentrer la valeur √† rechercher\n",
    "#     \"\"\"\n",
    "#     print(\"üîç Choisissez le type de recherche :\")\n",
    "#     print(\"1. Recherche par ID (ex: Q42)\")\n",
    "#     print(\"2. Recherche par label (ex: Douglas Adams)\")\n",
    "    \n",
    "#     choice = input(\"Entrez 1 ou 2 : \").strip()\n",
    "    \n",
    "#     if choice == \"2\":\n",
    "#         search_term = input(\"Entrez le nom de l'entit√© √† rechercher dans wikidata, en anglais (ex: aeronautics) : \").strip()\n",
    "#         if not search_term:\n",
    "#             print(\"‚ùå Aucun nom d'entit√© fourni.\")\n",
    "#             exit(1)  # Sortir du script si aucun nom n'est fourni\n",
    "#         return search_term \n",
    "#     elif choice == \"1\":\n",
    "#         search_term = input(\"Entrez l'ID de l'entit√© √† rechercher dans wikidata (ex: Q42) : \").strip()\n",
    "#         # Validation de l'ID de l'entit√©\n",
    "#         if not search_term or not re.match(r\"^Q\\d+$\", search_term):\n",
    "#             print(\"‚ùå ID d'entit√© invalide. Veuillez entrer un ID valide (ex: Q42).\")\n",
    "#             exit(1)  # Sortir du script si l'ID est invalide\n",
    "#         return search_term\n",
    "#     else:\n",
    "#         print(\"Choix invalide, veuillez r√©essayer.\")\n",
    "#         return ask_query_term()  # Redemander si le choix est invalide\n",
    "    \n",
    "# ask_query_term()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d392e0",
   "metadata": {},
   "source": [
    "## üßê REQU√äTES\n",
    "\n",
    "R√©sum√© des requ√™tes disponibles : \n",
    "| Type de requ√™te | R√©sum√© | Output |\n",
    "| --- | --- | --- |\n",
    "| Recherche par nom |  `SELECT ?item ?itemLabel WHERE { ?item rdfs:label ?itemLabel. FILTER(LANG(?itemLabel) = \"en\"). FILTER(CONTAINS(LCASE(?itemLabel), \"{search_entity_name}\")). }` | Label, ID\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eea4ad",
   "metadata": {},
   "source": [
    "### üìñ Biblioth√®que de requ√™tes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aafd293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Requ√™tes pr√™tes !\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================\n",
    "# DEFINITION DE REQU√äTE SPARQL POUR RECHERCHER UNE ENTIT√â PAR NOM\n",
    "# =================================================================================\n",
    "\n",
    "# REQUETE DANS LES LABELS\n",
    "query_by_label = \"\"\"\n",
    "        SELECT ?item ?itemLabel\n",
    "        WHERE {{\n",
    "            ?item rdfs:label ?itemLabel.\n",
    "            FILTER(LANG(?itemLabel) = \"en\").\n",
    "            FILTER(CONTAINS(LCASE(?itemLabel), {{search_term}})).\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "# REQUETE DANS LES PARENTS\n",
    "query_by_parent = \"\"\"\n",
    "        SELECT ?item ?itemLabel\n",
    "        WHERE {{\n",
    "            ?item wdt:P31*/wdt:P279* ?parent.\n",
    "            ?parent rdfs:label ?parentLabel.\n",
    "            FILTER(LANG(?parentLabel) = \"en\").\n",
    "            FILTER(CONTAINS(LCASE(?parentLabel), {{search_term}})).\n",
    "            SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "# =================================================================================\n",
    "# AIDES POUR LES REQUETES ULTERIEURES\n",
    "# =================================================================================\n",
    "\n",
    "# REQUETE POUR OBTENIR DANS QUELLES PROPRI√âT√âS L'ENTIT√â EST UTILIS√âE\n",
    "query_properties = \"\"\"\n",
    "SELECT ?prop WHERE {\n",
    "  {\n",
    "    SELECT ?prop \n",
    "           WHERE {\n",
    "      ?item ?prop {{search_term}}.\n",
    "    }\n",
    "    GROUP BY ?prop\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# =================================================================================\n",
    "# REQUETES THEMATIQUES\n",
    "# =================================================================================\n",
    "\n",
    "query_aero_events = \"\"\"\n",
    "SELECT ?item ?itemLabel ?lien ?lienLabel ?prop ?propLabel WHERE {\n",
    "  VALUES ?lien { wd:Q1070669 wd:Q8421 wd:Q765633 wd:Q108284447 }\n",
    "  ?item ?prop ?lien.\n",
    "  ?item wdt:P31/wdt:P279 wd:Q1656682.\n",
    "  \n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr,en,[AUTO_LANGUAGE]\". }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "query_events = \"\"\"\n",
    "SELECT DISTINCT ?item ?label\n",
    "WHERE {\n",
    "  VALUES ?type {\n",
    "    wd:Q1190554 wd:Q1656682\n",
    "    }\n",
    "  ?item wdt:P31 ?evenement .\n",
    "  ?item wdt:P585 ?date .\n",
    "  FILTER (?date > \"1800-01-01T00:00:00Z\"^^xsd:dateTime) .\n",
    "  ?item rdfs:label ?label .\n",
    "  FILTER (lang(?label) = \"en\") .\n",
    "  \n",
    "  # Regex sur labels, descriptions ou alias\n",
    "  FILTER (EXISTS {\n",
    "    {\n",
    "      ?item rdfs:label ?text.\n",
    "      FILTER(REGEX(LCASE(?text), \"(aero|aviat|flight|aircraft|airport|\\\\bplane\\\\b)\", \"i\"))\n",
    "    } UNION {\n",
    "      ?item schema:description ?text.\n",
    "      FILTER(REGEX(LCASE(?text), \"(aero|aviat|flight|aircraft|airport|\\\\bplane\\\\b)\", \"i\"))\n",
    "    } UNION {\n",
    "      ?item skos:altLabel ?text.\n",
    "      FILTER(REGEX(LCASE(?text), \"(aero|aviat|flight|aircraft|airport|\\\\bplane\\\\b)\", \"i\"))\n",
    "    }\n",
    "  })\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "query_aero_events_types = \"\"\"\n",
    "# Ce code SPARQL extrait une hi√©rarchie d‚Äô√©l√©ments Wikidata li√©s √† l‚Äôaviation, en marquant pour chaque √©l√©ment la nature du lien (direct ou h√©rit√©), la profondeur dans la hi√©rarchie, et en affichant les libell√©s.\n",
    "\n",
    "SELECT DISTINCT ?item ?itemLabel ?parent ?parentLabel ?depth ?aviationLink WHERE {\n",
    "  \n",
    "  # √âtape 1 : S√©lectionner tous les items qui ont un lien avec l‚Äôaviation.\n",
    "  {\n",
    "    SELECT DISTINCT ?aviationLinkedItem WHERE {\n",
    "      # On d√©finit trois types d'√©v√®nements de base li√©s √† l‚Äôaviation (Q1656682, Q1190554, Q108586636).\n",
    "      VALUES ?evenement {wd:Q1656682 wd:Q1190554 wd:Q108586636}\n",
    "      # On cherche les items dont le type (P31) ou un type parent (P279) correspond √† ces √©v√®nements.\n",
    "      ?aviationLinkedItem wdt:P31/wdt:P279 ?evenement.\n",
    "      \n",
    "      # FILTRE AERONAUTIQUE : D√©tection de mots-cl√©s dans les libell√©s, descriptions ou labels alternatifs.\n",
    "      {\n",
    "        ?aviationLinkedItem rdfs:label ?label.\n",
    "        FILTER(REGEX(LCASE(?label), \"(aero|aviation|aircraft|flight|aerial|plane|airport|pilot)\", \"i\"))\n",
    "      } UNION {\n",
    "        ?aviationLinkedItem schema:description ?desc.\n",
    "        FILTER(REGEX(LCASE(?desc), \"(aero|aviation|aircraft|flight|aerial|plane|airport|pilot)\", \"i\"))\n",
    "      } UNION {\n",
    "        ?aviationLinkedItem skos:altLabel ?altLabel.\n",
    "        FILTER(REGEX(LCASE(?altLabel), \"(aero|aviation|aircraft|flight|aerial|plane|airport|pilot)\", \"i\"))\n",
    "      } UNION {\n",
    "        # On regarde aussi si l‚Äôitem est li√©, via certaines propri√©t√©s, √† des entit√©s a√©ronautiques sp√©cifiques.\n",
    "        ?aviationLinkedItem (wdt:P31|wdt:P279|wdt:P361|wdt:P527|wdt:P1269) ?aeronauticEntity.\n",
    "        VALUES ?aeronauticEntity {\n",
    "          wd:Q8421      # a√©ronautique\n",
    "          wd:Q765633    # aviation  \n",
    "          wd:Q11436     # aircraft\n",
    "          wd:Q62447     # a√©rodrome\n",
    "          wd:Q1248784   # a√©roport international\n",
    "          wd:Q46970     # compagnie a√©rienne\n",
    "          wd:Q744913    # accident d'avion\n",
    "          wd:Q206021    # vol\n",
    "          wd:Q2876213   # a√©rospatiale\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # √âtape 2 : Pour chaque item li√© √† l‚Äôaviation, on remonte toute la hi√©rarchie de type (P31).\n",
    "  ?aviationLinkedItem wdt:P31* ?item.\n",
    "  \n",
    "  # On garde seulement les items dont le type ultime est Q108586636 (√©v√®nement de transport a√©rien).\n",
    "  ?item wdt:P31+ wd:Q108586636.\n",
    "  \n",
    "  # On r√©cup√®re le parent direct dans la hi√©rarchie pour l‚Äôaffichage.\n",
    "  OPTIONAL { ?item wdt:P31 ?parent }\n",
    "  \n",
    "  # Calcul de la profondeur de l‚Äôitem dans la hi√©rarchie (distance au type de base).\n",
    "  {\n",
    "    SELECT ?item (COUNT(?intermediate) AS ?depth) WHERE {\n",
    "      ?item wdt:P31+ ?intermediate.\n",
    "      ?intermediate wdt:P31* wd:Q108586636.\n",
    "    }\n",
    "    GROUP BY ?item\n",
    "  }\n",
    "  \n",
    "  # On limite la profondeur d‚Äôanalyse √† 4 pour √©viter des hi√©rarchies trop longues.\n",
    "  FILTER(?depth <= 4)\n",
    "  \n",
    "  # On marque si le lien aviation est direct (l‚Äôitem est lui-m√™me identifi√© comme aviation) ou h√©rit√© (par la hi√©rarchie).\n",
    "  BIND(IF(?item = ?aviationLinkedItem, \"DIRECT\", \"INHERITED\") AS ?aviationLink)\n",
    "  \n",
    "  # On ajoute les labels en anglais, fran√ßais, ou langue auto-d√©tect√©e.\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en,fr,[AUTO_LANGUAGE]\". }\n",
    "}\n",
    "# Tri des r√©sultats par profondeur, type de lien, parent et label.\n",
    "ORDER BY ?depth ?aviationLink ?parentLabel ?itemLabel\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"‚úÖ Requ√™tes pr√™tes !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85a5c57",
   "metadata": {},
   "source": [
    "### Aide √† la requ√™te : Lancer une requ√™te individuelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbd5d923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Ex√©cution de la requ√™te avec pagination : \n",
      "    SELECT DISTINCT ?item ?itemLabel ?prop ?itemDescription ?parent ?parentLabel\n",
      "    WHERE {\n",
      "      ?item ?prop wd:Q8421 .\n",
      "      OPTIONAL {\n",
      "      ?item (wdt:P31|wdt:P279) ?parent .\n",
      "      ?parent rdfs:label ?parentLabel .\n",
      "      ?page schema:description ?itemDescription .\n",
      "      FILTER(LANG(?parentLabel) = \"en\" || LANG(?parentLabel) = \"fr\")\n",
      "      FILTER(LANG(?itemDescription) = \"en\" || LANG(?itemDescription) = \"fr\")\n",
      "      }\n",
      "      SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr,en\". }\n",
      "    }\n",
      "    \n",
      "üîç Ex√©cution de la requ√™te SPARQL :\n",
      "\n",
      "    SELECT DISTINCT ?item ?itemLabel ?prop ?itemDescription ?parent ?parentLabel\n",
      "    WHERE {\n",
      "      ?item ?prop wd:Q8421 .\n",
      "      OPTIONAL {\n",
      "      ?item (wdt:P31|wdt:P279) ?parent .\n",
      "      ?parent rdfs:label ?parentLabel .\n",
      "      ?page schema:description ?itemDescription .\n",
      "      FILTER(LANG(?parentLabel) = \"en\" || LANG(?parentLabel) = \"fr\")\n",
      "      FILTER(LANG(?itemDescription) = \"en\" || LANG(?itemDescription) = \"fr\")\n",
      "      }\n",
      "      SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr,en\". }\n",
      "    }\n",
      "    \n",
      "\n",
      "üîç D√©but de la pagination (limit=100)...\n",
      "üîπ Requ√™te OFFSET 0, LIMIT 100\n",
      "‚ö†Ô∏è  Tentative 1/3 √©chou√©e √† l'offset 0: The read operation timed out\n",
      "‚ö†Ô∏è  Tentative 2/3 √©chou√©e √† l'offset 0: The read operation timed out\n",
      "‚ö†Ô∏è  Tentative 3/3 √©chou√©e √† l'offset 0: The read operation timed out\n",
      "‚ùå Requ√™te √©chou√©e apr√®s 3 tentatives √† l'offset 0\n"
     ]
    }
   ],
   "source": [
    "# EXECUTER UNE REQU√äTE SPARQL DEFINIE AVEC PAGINATION\n",
    "\n",
    "# =================================================================================\n",
    "# CHOISIR ICI LA REQU√äTE √Ä EX√âCUTER\n",
    "# =================================================================================\n",
    "query = query_properties_one  # Remplacer par la requ√™te souhait√©e\n",
    "\n",
    "# =================================================================================\n",
    "# FONCTION POUR EX√âCUTER LA REQU√äTE SPARQL AVEC PAGINATION\n",
    "# =================================================================================\n",
    "def execute_specific_query(query):\n",
    "    \"\"\"\n",
    "    Ex√©cute une requ√™te SPARQL avec pagination.\n",
    "    :param query: La requ√™te SPARQL √† ex√©cuter.\n",
    "    :param limit: Nombre de r√©sultats par page (par d√©faut: MAX_RESULTS).\n",
    "    :param max_results: Nombre maximum de r√©sultats √† r√©cup√©rer (par d√©faut: MAX_RESULTS).\n",
    "    :return: Liste des r√©sultats pagin√©s.\n",
    "    \"\"\"\n",
    "    # V√©rifier si la requ√™te est vide\n",
    "    if not query:\n",
    "        print(\"‚ùå Aucune requ√™te SPARQL fournie.\")\n",
    "        return []\n",
    "    # Afficher les d√©tails de la requ√™te\n",
    "    print(f\"üîç Ex√©cution de la requ√™te avec pagination : {query}\")\n",
    "    # Ex√©cuter la requ√™te avec pagination\n",
    "    return execute_paginated_query(query)\n",
    "\n",
    "query_results = execute_specific_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97fed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"‚úÖ Requ√™te ex√©cut√©e avec succ√®s, {len(query_results)} r√©sultats obtenus.\")\n",
    "\n",
    "# Pour obtenir automatiquement le nom de la variable (ex: \"query_aero_events\") pointant vers la valeur de query,\n",
    "# on peut parcourir les variables globales et comparer leur valeur √† celle de query.\n",
    "# Attention : cela ne fonctionne que si la variable est accessible dans le scope global et que la valeur n'est pas modifi√©e.\n",
    "\n",
    "def get_query_var_name(query_value):\n",
    "    for var_name, var_val in globals().items():\n",
    "        if var_val is query_value:\n",
    "            return var_name\n",
    "    return \"query\"\n",
    "\n",
    "query_var_name = get_query_var_name(query)\n",
    "raw_json_filename = f\"{datetime.now().strftime('%Y%m%d_%H%M%S')}_RAW_{query_var_name}.json\"\n",
    "raw_json_filepath = os.path.join(output_dir, raw_json_filename)\n",
    "\n",
    "with open(raw_json_filepath, 'w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(query_results, jsonfile, ensure_ascii=False, indent=2)\n",
    "print(\"=\" * 100)\n",
    "print(f\"‚úÖ R√©sultats sauvegard√©s dans {raw_json_filepath}\")\n",
    "\n",
    "# üì© SAUVEGARDE DES R√âSULTATS EN CSV\n",
    "\n",
    "raw_csv_filename = f\"{datetime.now().strftime('%Y%m%d_%H%M%S')}_RAW_{query_var_name}.csv\"\n",
    "raw_csv_filepath = os.path.join(output_dir, raw_csv_filename)\n",
    "with open(raw_csv_filepath, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = query_results[0].keys() if query_results else []\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    for result in query_results:\n",
    "        writer.writerow({k: v['value'] if isinstance(v, dict) else v for k, v in result.items()})\n",
    "print(f\"‚úÖ R√©sultats sauvegard√©s dans {raw_csv_filepath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661655c9",
   "metadata": {},
   "source": [
    "### 1. Aide √† la requ√™te : Rechercher une entit√© par nom \n",
    "\n",
    "Cette fonction peut s'utiliser pour retirer tous les termes wikidata qui comprennent une cha√Æne de caract√®re\n",
    "1. Dans leur label\n",
    "2. Dans un de leurs termes g√©n√©riques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e118180b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Choisissez le type de recherche :\n",
      "1. Recherche par ID (ex: Q42)\n",
      "2. Recherche par label (ex: Douglas Adams)\n",
      "üîç Recherche pour le terme : \"douglas adams\"\n",
      "üîç Requ√™te APR√àS remplacement :\n",
      "\n",
      "        SELECT ?item ?itemLabel\n",
      "        WHERE {{\n",
      "            ?item rdfs:label ?itemLabel.\n",
      "            FILTER(LANG(?itemLabel) = \"en\").\n",
      "            FILTER(CONTAINS(LCASE(?itemLabel), \"douglas adams\")).\n",
      "        }}\n",
      "        \n",
      "==================================================\n",
      "üîç Ex√©cution de la requ√™te SPARQL :\n",
      "\n",
      "        SELECT ?item ?itemLabel\n",
      "        WHERE {{\n",
      "            ?item rdfs:label ?itemLabel.\n",
      "            FILTER(LANG(?itemLabel) = \"en\").\n",
      "            FILTER(CONTAINS(LCASE(?itemLabel), \"douglas adams\")).\n",
      "        }}\n",
      "        \n",
      "\n",
      "üîç D√©but de la pagination (limit=100)...\n",
      "üîπ Requ√™te OFFSET 0, LIMIT 100\n",
      "‚ö†Ô∏è  Tentative 1/3 √©chou√©e √† l'offset 0: The read operation timed out\n",
      "‚ö†Ô∏è  Tentative 2/3 √©chou√©e √† l'offset 0: The read operation timed out\n",
      "‚ö†Ô∏è  Tentative 3/3 √©chou√©e √† l'offset 0: The read operation timed out\n",
      "‚ùå Requ√™te √©chou√©e apr√®s 3 tentatives √† l'offset 0\n"
     ]
    }
   ],
   "source": [
    "# üîé RECHERCHE PAR NOM\n",
    "# =================================================================================\n",
    "\n",
    "\n",
    "# =================================================================================\n",
    "# Demande √† l'utilisateur le nom de l'entit√© √† rechercher dans Wikidata\n",
    "# =================================================================================\n",
    "\"\"\"\n",
    "search_entity_name = input(\"Entrez le nom de l'entit√© √† rechercher dans wikidata, en anglais (ex: aeronautics) : \").strip()\n",
    "if not search_entity_name:\n",
    "    print(\"‚ùå Aucun nom d'entit√© fourni.\")\n",
    "    exit(1)  # Sortir du script si aucun nom n'est fourni\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# =================================================================================\n",
    "# DEMANDE √Ä L'UTILISATEUR LE TYPE DE REQU√äTE √Ä UTILISER\n",
    "# =================================================================================\n",
    "\n",
    "# Choix de la requ√™te √† utiliser\n",
    "query_choice = input(\n",
    "    \"Quel type de requ√™te utiliser ?\\n\"\n",
    "    \"1Ô∏è‚É£ Recherche d'une cha√Æne dans les labels\\n\"\n",
    "    \"2Ô∏è‚É£ Requ√™te d'une cha√Æne dans les parents\\n\"\n",
    "    \"Entrez le num√©ro de votre choix (1 ou 2) : \"\n",
    ").strip()\n",
    "if query_choice not in [\"1\", \"2\"]:\n",
    "    print(\"‚ùå Choix invalide. Veuillez entrer 1 ou 2.\")\n",
    "    exit(1)  # Sortir du script si le choix est invalide\n",
    "\n",
    "if query_choice == \"1\":\n",
    "    query_regex = query_by_label\n",
    "elif query_choice == \"2\":\n",
    "    query_regex = query_by_parent\n",
    "\n",
    "raw_entity_by_name_results = execute_paginated_query(query_regex, ask_term=True)\n",
    "# def find_entity_by_name(search_entity_name=search_term, query_regex=query_regex):\n",
    "#     \"\"\"\n",
    "#     Demande √† l'utilisateur le nom de l'entit√© √† rechercher dans Wikidata\n",
    "#     :return: Liste des r√©sultats de la recherche\n",
    "#     \"\"\"\n",
    "    \n",
    "#     print(\"=\" * 100)\n",
    "#     print(f\"üîç RECHERCHE DES TERMES CONTENANT LA CHAINE DE CARACTERE :  '{search_entity_name}'...\")\n",
    "#     print(\"=\" * 100)\n",
    "#     print(f\"üîç REQU√äTE ENVOYEE :{query_regex}\")\n",
    "#     print(\"=\" * 100)\n",
    "#     return execute_paginated_query(query_regex)\n",
    "# raw_entity_by_name_results = find_entity_by_name()\n",
    "\n",
    "# =================================================================================\n",
    "# üì© SAUVEGARDE DES R√âSULTATS EN JSON\n",
    "# =================================================================================\n",
    "\n",
    "def save_raw_results_to_json(raw_entity_by_name_results, search_term):\n",
    "    \"\"\"\n",
    "    Sauvegarde les r√©sultats bruts de la recherche dans un fichier JSON\n",
    "    :param raw_entity_by_name_results: R√©sultats bruts de la recherche\n",
    "    :param search_entity_name: Nom de l'entit√© recherch√©e\n",
    "    \"\"\"\n",
    "    # Cr√©ation du nom de fichier avec la date et l'heure actuelles\n",
    "    raw_json_filename = f\"{datetime.now().strftime('%Y%m%d_%H%M%S')}_RAW_{search_term}.json\"\n",
    "    raw_json_filepath = os.path.join(output_dir, raw_json_filename)\n",
    "\n",
    "    with open(raw_json_filepath, 'w', encoding='utf-8') as jsonfile:\n",
    "        json.dump(raw_entity_by_name_results, jsonfile, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "    print(f\"‚úÖ RESULTATS SAUVEGARDES DANS {raw_json_filepath}\")\n",
    "#save_raw_results_to_json(raw_entity_by_name_results, search_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad135870",
   "metadata": {},
   "source": [
    "### 2. Aide √† la requ√™te : Trouver toutes les propri√©t√©s dans lesquelles un terme est utilis√©\n",
    "\n",
    "#### Ex√©cuter la requ√™te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e81aa811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Choisissez le type de recherche :\n",
      "1. Recherche par ID (ex: Q42)\n",
      "2. Recherche par label (ex: Douglas Adams)\n",
      "üîç Recherche pour le terme : Q22719\n",
      "üîç Ex√©cution de la requ√™te SPARQL :\n",
      "\n",
      "SELECT ?prop WHERE {\n",
      "  {\n",
      "    SELECT ?prop \n",
      "           WHERE {\n",
      "      ?item ?prop wd:Q22719.\n",
      "    }\n",
      "    GROUP BY ?prop\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "üîç D√©but de la pagination (limit=100)...\n",
      "üîπ Requ√™te OFFSET 0, LIMIT 100\n",
      "‚úÖ R√©cup√©r√© 43 r√©sultats (total: 43)\n",
      "‚è≥ Attente de 3.0s...\n",
      "üîπ Requ√™te OFFSET 100, LIMIT 100\n",
      "‚úÖ Fin de la pagination - Aucun r√©sultat suppl√©mentaire.\n",
      "üéØ Total final r√©cup√©r√© : 43 r√©sultats.\n"
     ]
    }
   ],
   "source": [
    "# REQUETE PAR PROPRIETE\n",
    "# =================================================================================\n",
    "\n",
    "# Ex√©cuter avec demande de terme\n",
    "query_results = execute_paginated_query(query_properties, ask_term=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb3b9e1",
   "metadata": {},
   "source": [
    "#### Cr√©er un dictionnaire avec index avec la liste de toutes les propri√©t√©s extraites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e0025f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P2650', 'owl:sameAs', 'P301', 'P31', 'P1535', 'P921', 'P1269', 'P1889', 'P101', 'P279', 'P921', 'P301', 'P31', 'P1535', 'about', 'P1269', 'P1889', 'P279', 'P101', 'P2650', 'P812', 'P101', 'P921', 'P5137', 'P9488', 'P5137', 'P9488']\n"
     ]
    }
   ],
   "source": [
    "# Extraction simple des IDs de propri√©t√© depuis query_results\n",
    "all_property_ids = [clean_entity_id(prop['prop']['value']).replace('#', ':') for prop in query_results if 'prop' in prop and 'value' in prop['prop']]\n",
    "\n",
    "print(all_property_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48ad8e8",
   "metadata": {},
   "source": [
    "#### Requ√™ter toutes les pages reli√©es √† l'identifiant recherch√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7c030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Choisissez le type de recherche :\n",
      "1. Recherche par ID (ex: Q42)\n",
      "2. Recherche par label (ex: Douglas Adams)\n",
      "wdt:P2650 owl:sameAs wdt:P301 wdt:P31 wdt:P1535 wdt:P921 wdt:P1269 wdt:P1889 wdt:P101 wdt:P279 wdt:P921 wdt:P301 wdt:P31 wdt:P1535 wdt:P1269 wdt:P1889 wdt:P279 wdt:P101 wdt:P2650 wdt:P812 wdt:P101 wdt:P921 wdt:P5137 wdt:P9488 wdt:P5137 wdt:P9488\n",
      "üîç Ex√©cution de la requ√™te SPARQL :\n",
      "    SELECT \n",
      "  ?item \n",
      "  ?itemLabel \n",
      "  (GROUP_CONCAT(DISTINCT ?propLabel; separator=\", \") AS ?props)\n",
      "  (COALESCE(?itemDescription_fr, ?itemDescription_en) AS ?itemDescription) # renvoie la premi√®re description valide trouv√©e.\n",
      "  ?parent1\n",
      "  (COALESCE(?parent1Label_fr, ?parent1Label_en) AS ?parent1Label)\n",
      "  ?parent2\n",
      "  (COALESCE(?parent2Label_fr, ?parent2Label_en) AS ?parent2Label)\n",
      "WHERE {\n",
      "  VALUES ?prop { \n",
      "    wdt:P2650 owl:sameAs wdt:P301 wdt:P31 wdt:P1535 wdt:P921 wdt:P1269 wdt:P1889 wdt:P101 wdt:P279 wdt:P921 wdt:P301 wdt:P31 wdt:P1535 wdt:P1269 wdt:P1889 wdt:P279 wdt:P101 wdt:P2650 wdt:P812 wdt:P101 wdt:P921 wdt:P5137 wdt:P9488 wdt:P5137 wdt:P9488\n",
      "  }\n",
      "  ?item ?prop  wd:Q2876213 .\n",
      "  OPTIONAL {\n",
      "  ?wd wikibase:directClaim ?prop .\n",
      "  ?wd rdfs:label ?propLabel .\n",
      "  FILTER(LANG(?propLabel) = \"fr\")\n",
      "  }\n",
      "\n",
      "  # Description fr/en selon disponibilit√©\n",
      "  OPTIONAL { ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }\n",
      "  OPTIONAL { ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }\n",
      "\n",
      "  # parent1Label fr/en selon disponibilit√©\n",
      "  OPTIONAL {\n",
      "    ?item wdt:P31 ?parent1 .\n",
      "    OPTIONAL { ?parent1 rdfs:label ?parent1Label_fr . FILTER(LANG(?parent1Label_fr) = \"fr\") }\n",
      "    OPTIONAL { ?parent1 rdfs:label ?parent1Label_en . FILTER(LANG(?parent1Label_en) = \"en\") }\n",
      "\n",
      "    # parent2Label fr/en selon disponibilit√©\n",
      "    OPTIONAL {\n",
      "      ?item wdt:P279|wdt: ?parent2 .\n",
      "      OPTIONAL { ?parent2 rdfs:label ?parent2Label_fr . FILTER(LANG(?parent2Label_fr) = \"fr\") }\n",
      "      OPTIONAL { ?parent2 rdfs:label ?parent2Label_en . FILTER(LANG(?parent2Label_en) = \"en\") }\n",
      "    }\n",
      "  }\n",
      "\n",
      "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr,en\". }\n",
      "}\n",
      "GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?parent1Label_fr ?parent1Label_en ?parent2Label_fr ?parent2Label_en ?parent1 ?parent2\n",
      "\n",
      "\n",
      "üöÄ Mode simple (sans pagination) - Envoi de la requ√™te...\n",
      "üì° Tentative 1/3 - Envoi de la requ√™te...\n",
      "‚è≥ Attente de la r√©ponse du serveur...\n",
      "‚úÖ Requ√™te r√©ussie ! 79 r√©sultats obtenus\n",
      "‚úÖ R√©sultats des pages li√©es sauvegard√©s dans ./output\\20250708_121620_related_pages_Q2876213.json\n"
     ]
    }
   ],
   "source": [
    "# G√©n√®re une requ√™te SPARQL pour trouver toutes les pages reli√©es au search_term via les propri√©t√©s de all_property_ids\n",
    "\n",
    "def build_related_pages_query(search_term, property_ids):\n",
    "    \"\"\"\n",
    "    Construit une requ√™te SPARQL pour trouver toutes les pages reli√©es √† search_term via une liste de propri√©t√©s.\n",
    "    :param search_term: ID Wikidata (ex: Q42)\n",
    "    :param property_ids: liste de propri√©t√©s (ex: ['P50', 'P170'])\n",
    "    :return: requ√™te SPARQL (str)\n",
    "    \"\"\"\n",
    "    # Pr√©pare la liste VALUES pour les propri√©t√©s\n",
    "    # Inclure toutes les propri√©t√©s qui contiennent \":\" (ex: wdt:, owl:, rdf:, etc.)\n",
    "    values_block = \" \".join(\n",
    "      (\n",
    "        f\"wdt:{pid}\" if pid.startswith(\"P\") else pid\n",
    "      )\n",
    "      for pid in property_ids\n",
    "      if (\":\" in pid) or pid.startswith(\"P\")\n",
    "    ).strip()\n",
    "    # Nettoyer les espaces multiples √©ventuels\n",
    "    values_block = \" \".join(values_block.split())\n",
    "    print(values_block)\n",
    "\n",
    "    query = f\"\"\"    SELECT \n",
    "  ?item \n",
    "  ?itemLabel \n",
    "  (GROUP_CONCAT(DISTINCT ?propLabel; separator=\", \") AS ?props)\n",
    "  (COALESCE(?itemDescription_fr, ?itemDescription_en) AS ?itemDescription) # renvoie la premi√®re description valide trouv√©e.\n",
    "  ?parent1\n",
    "  (COALESCE(?parent1Label_fr, ?parent1Label_en) AS ?parent1Label)\n",
    "  ?parent2\n",
    "  (COALESCE(?parent2Label_fr, ?parent2Label_en) AS ?parent2Label)\n",
    "WHERE {{\n",
    "  VALUES ?prop {{ \n",
    "    {values_block}\n",
    "  }}\n",
    "  ?item ?prop  wd:{search_term} .\n",
    "  OPTIONAL {{\n",
    "  ?wd wikibase:directClaim ?prop .\n",
    "  ?wd rdfs:label ?propLabel .\n",
    "  FILTER(LANG(?propLabel) = \"fr\")\n",
    "  }}\n",
    "\n",
    "  # Description fr/en selon disponibilit√©\n",
    "  OPTIONAL {{ ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }}\n",
    "  OPTIONAL {{ ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }}\n",
    "\n",
    "  # parent1Label fr/en selon disponibilit√©\n",
    "  OPTIONAL {{\n",
    "    ?item wdt:P31 ?parent1 .\n",
    "    OPTIONAL {{ ?parent1 rdfs:label ?parent1Label_fr . FILTER(LANG(?parent1Label_fr) = \"fr\") }}\n",
    "    OPTIONAL {{ ?parent1 rdfs:label ?parent1Label_en . FILTER(LANG(?parent1Label_en) = \"en\") }}\n",
    "\n",
    "    # parent2Label fr/en selon disponibilit√©\n",
    "    OPTIONAL {{\n",
    "      ?item wdt:P279|wdt: ?parent2 .\n",
    "      OPTIONAL {{ ?parent2 rdfs:label ?parent2Label_fr . FILTER(LANG(?parent2Label_fr) = \"fr\") }}\n",
    "      OPTIONAL {{ ?parent2 rdfs:label ?parent2Label_en . FILTER(LANG(?parent2Label_en) = \"en\") }}\n",
    "    }}\n",
    "  }}\n",
    "\n",
    "  SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"fr,en\". }}\n",
    "}}\n",
    "GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?parent1Label_fr ?parent1Label_en ?parent2Label_fr ?parent2Label_en ?parent1 ?parent2\n",
    "\"\"\"\n",
    "    return query\n",
    "\n",
    "# Exemple d'utilisation :\n",
    "search_term = ask_query_term()  # √† remplacer par votre variable ou input utilisateur\n",
    "query = build_related_pages_query(search_term, all_property_ids)\n",
    "\n",
    "# Ex√©cuter la requ√™te pour obtenir les pages li√©es\n",
    "related_pages_results = execute_sparql_query(query, use_pagination=False)\n",
    "\n",
    "# Sauvegarder les r√©sultats dans un fichier JSON\n",
    "related_pages_json_filename = f\"{datetime.now().strftime('%Y%m%d_%H%M%S')}_related_pages_{search_term}.json\"\n",
    "related_pages_json_filepath = os.path.join(output_dir, related_pages_json_filename)\n",
    "with open(related_pages_json_filepath, 'w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(related_pages_results, jsonfile, ensure_ascii=False, indent=2)\n",
    "print(f\"‚úÖ R√©sultats des pages li√©es sauvegard√©s dans {related_pages_json_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c2c66f",
   "metadata": {},
   "source": [
    "### REQU√äTES THEMATIQUES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295aa2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_aeronautics_extraction_queries():\n",
    "    \"\"\"Construit les requ√™tes d'extraction des donn√©es\"\"\"\n",
    "    queries = {\n",
    "        \"manufacturers\": \"\"\"\n",
    "        SELECT DISTINCT ?item \n",
    "              \n",
    "                ?itemLabel\n",
    "               (COALESCE(?itemDescription_fr, ?itemDescription_en, ?itemDescription_any, \"\") AS ?itemDescription)\n",
    "               ?parent\n",
    "               ?parentLabel\n",
    "               (GROUP_CONCAT(DISTINCT ?synonym_fr; separator=\",\") AS ?synonyms_fr)\n",
    "        WHERE {\n",
    "          # Tous les constructeurs d'aviation (instances ou sous-classes ou parties)\n",
    "          ?item wdt:P31*/wdt:P279*/wdt:P361*/wdt:P452*/wdt:P749* wd:Q936518 .\n",
    "        \n",
    "          # On cherche le parent imm√©diat selon diff√©rentes relations\n",
    "            OPTIONAL { ?item wdt:P361 ?partOf . }\n",
    "            OPTIONAL { ?item wdt:P279 ?subclassOf . }\n",
    "            OPTIONAL { ?item wdt:P31 ?instanceOf . }\n",
    "            OPTIONAL { ?item wdt:P452 ?secteur .}\n",
    "            OPTIONAL { ?item wdt:P176 ?constructeur.}\n",
    "            OPTIONAL { ?item wdt:P749 ?constructeur.}\n",
    "            \n",
    "            BIND(COALESCE(?partOf, ?subclassOf, ?instanceOf, ?secteur, ?constructeur) AS ?parent)\n",
    "        \n",
    "          # Description de l'item (fr > en > autre)\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_any .\n",
    "                     FILTER(LANG(?itemDescription_any) != \"fr\" && LANG(?itemDescription_any) != \"en\") }\n",
    "\n",
    "          # Synonymes en fran√ßais (P1709 est \"synonymes exacts\")\n",
    "          OPTIONAL { ?item skos:altLabel ?synonym_fr . FILTER(LANG(?synonym_fr) = \"fr\") }\n",
    "        \n",
    "          SERVICE wikibase:label {\n",
    "            bd:serviceParam wikibase:language \"fr,en,[AUTO_LANGUAGE]\"\n",
    "          }\n",
    "        }\n",
    "        GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?itemDescription_any ?parent ?parentLabel\n",
    "        \"\"\",\n",
    "\n",
    "        \"aircraft_models\": \"\"\"\n",
    "        SELECT DISTINCT ?item \n",
    "               ?itemLabel\n",
    "               (COALESCE(?itemDescription_fr, ?itemDescription_en, ?itemDescription_any, \"\") AS ?itemDescription)\n",
    "               ?parent\n",
    "               ?parentLabel\n",
    "               (GROUP_CONCAT(DISTINCT ?synonym_fr; separator=\" , \") AS ?synonyms_fr)\n",
    "        WHERE {\n",
    "          # Tous les mod√®les d'avions (instances ou sous-classes ou parties)\n",
    "          ?item wdt:P31/wdt:P279* wd:Q11436 .\n",
    "          \n",
    "        \n",
    "          # On cherche le parent imm√©diat selon diff√©rentes relations         \n",
    "            OPTIONAL { ?item wdt:P179 ?series .}\n",
    "            OPTIONAL { ?item wdt:176 ?constructeur.}\n",
    "            OPTIONAL { ?item wdt:P31 ?instanceOf . } \n",
    "            OPTIONAL { ?item wdt:P361 ?partOf . }\n",
    "            OPTIONAL { ?item wdt:P279 ?subclassOf . }\n",
    "                       \n",
    "            BIND(COALESCE(?partOf, ?subclassOf, ?instanceOf, ?series, ?constructeur) AS ?parent)\n",
    "        \n",
    "          # Description de l'item (fr > en > autre)\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_any .\n",
    "                     FILTER(LANG(?itemDescription_any) != \"fr\" && LANG(?itemDescription_any) != \"en\") }\n",
    "\n",
    "          # Synonymes en fran√ßais\n",
    "          OPTIONAL { ?item skos:altLabel ?synonym_fr . FILTER(LANG(?synonym_fr) = \"fr\") }\n",
    "        \n",
    "          SERVICE wikibase:label {\n",
    "            bd:serviceParam wikibase:language \"fr,en,[AUTO_LANGUAGE]\"\n",
    "          }\n",
    "        }\n",
    "        GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?itemDescription_any ?parent ?parentLabel\n",
    "        \"\"\",\n",
    "\n",
    "        \"aircraft_components\": \"\"\"\n",
    "        SELECT DISTINCT ?item \n",
    "               ?itemLabel\n",
    "               (COALESCE(?itemDescription_fr, ?itemDescription_en, ?itemDescription_any, \"\") AS ?itemDescription)\n",
    "               ?parent\n",
    "               ?parentLabel\n",
    "               (GROUP_CONCAT(DISTINCT ?synonym_fr; separator=\" , \") AS ?synonyms_fr)\n",
    "        WHERE {\n",
    "          # Tous les √©quipements d'aviation (instances ou sous-classes ou parties)\n",
    "          ?item wdt:P31*/wdt:P279*/wdt:P361* wd:Q16693356 .\n",
    "        \n",
    "          # On cherche le parent imm√©diat selon diff√©rentes relations\n",
    "            OPTIONAL { ?item wdt:P361 ?partOf . }\n",
    "            OPTIONAL { ?item wdt:P279 ?subclassOf . }\n",
    "            OPTIONAL { ?item wdt:P31 ?instanceOf . }\n",
    "            OPTIONAL { ?item wdt:P452 ?secteur .}\n",
    "            OPTIONAL { ?item wdt:P176 ?constructeur.}\n",
    "            \n",
    "            BIND(COALESCE(?partOf, ?subclassOf, ?instanceOf, ?secteur, ?constructeur) AS ?parent)\n",
    "        \n",
    "          # Description de l'item (fr > en > autre)\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_any .\n",
    "                     FILTER(LANG(?itemDescription_any) != \"fr\" && LANG(?itemDescription_any) != \"en\") }\n",
    "\n",
    "          # Synonymes en fran√ßais\n",
    "          OPTIONAL { ?item skos:altLabel ?synonym_fr . FILTER(LANG(?synonym_fr) = \"fr\") }\n",
    "        \n",
    "          SERVICE wikibase:label {\n",
    "            bd:serviceParam wikibase:language \"fr,en,[AUTO_LANGUAGE]\"\n",
    "          }\n",
    "        }\n",
    "        GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?itemDescription_any ?parent ?parentLabel\n",
    "        \"\"\",\n",
    "\n",
    "        \"aeronautic_profession\": \"\"\"\n",
    "        SELECT DISTINCT ?item \n",
    "               ?itemLabel\n",
    "               (COALESCE(?itemDescription_fr, ?itemDescription_en, ?itemDescription_any, \"\") AS ?itemDescription)\n",
    "               ?parent\n",
    "               ?parentLabel\n",
    "               (GROUP_CONCAT(DISTINCT ?synonym_fr; separator=\" , \") AS ?synonyms_fr)\n",
    "        WHERE {\n",
    "        ?item wdt:P425* ?domaine.\n",
    "        VALUES ?domaine { wd:Q765633 wd:Q906438 wd:Q1434048 wd:Q206814 wd:Q627716 wd:Q221395 wd:Q765633 wd:Q22719}.  \n",
    "        \n",
    "          # On cherche le parent imm√©diat selon diff√©rentes relations\n",
    "            OPTIONAL { ?item wdt:P361 ?partOf . }\n",
    "            OPTIONAL { ?item wdt:P279 ?subclassOf . }\n",
    "            OPTIONAL { ?item wdt:P31 ?instanceOf . }\n",
    "            OPTIONAL { ?item wdt:P452 ?secteur .}\n",
    "            OPTIONAL { ?item wdt:P176 ?constructeur.}\n",
    "            OPTIONAL { ?item wdt:P749 ?constructeur.}\n",
    "            \n",
    "            BIND(COALESCE(?partOf, ?subclassOf, ?instanceOf, ?secteur, ?constructeur, ?domaine) AS ?parent) # Attention √† coalesce pour √©viter les doublons\n",
    "        \n",
    "          # Description de l'item (fr > en > autre)\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_any .\n",
    "                     FILTER(LANG(?itemDescription_any) != \"fr\" && LANG(?itemDescription_any) != \"en\") }\n",
    "\n",
    "          # Synonymes en fran√ßais\n",
    "          OPTIONAL { ?item skos:altLabel ?synonym_fr . FILTER(LANG(?synonym_fr) = \"fr\") }\n",
    "        \n",
    "          SERVICE wikibase:label {\n",
    "            bd:serviceParam wikibase:language \"fr,en,[AUTO_LANGUAGE]\"\n",
    "          }\n",
    "        }\n",
    "        GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?itemDescription_any ?parent ?parentLabel\n",
    "        \"\"\"\n",
    "    }\n",
    "    return queries\n",
    "\n",
    "print(\"‚úÖ Requ√™tes d√©finies (avec synonymes fran√ßais)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea367aee",
   "metadata": {},
   "source": [
    "## üîé Lancer la recherche globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b6ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üõ†Ô∏è EXTRACTION DES DONN√âES A√âRONAUTIQUES\n",
    "def extract_all_aeronautics_data():\n",
    "    \"\"\"Extrait toutes les donn√©es a√©ronautiques de mani√®re optimis√©e\"\"\"\n",
    "    print(\"üèóÔ∏è EXTRACTION HI√âRARCHIQUE EXHAUSTIVE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    queries = build_aeronautics_extraction_queries()\n",
    "    all_results = []\n",
    "    \n",
    "    for category, query in queries.items():\n",
    "        print(f\"\\nüîç Extraction: {category}\")\n",
    "        \n",
    "        # ‚úÖ CORRECTION: Utiliser execute_paginated_query au lieu de execute_batch_queries\n",
    "        results = execute_batch_queries(query)\n",
    "        \n",
    "        # Enrichir chaque r√©sultat avec sa cat√©gorie\n",
    "        for result in results:\n",
    "            result[\"source_category\"] = category\n",
    "        \n",
    "        all_results.extend(results)\n",
    "        print(f\"‚úÖ {len(results)} entit√©s trouv√©es pour {category}\")\n",
    "    \n",
    "    print(f\"\\nüéØ TOTAL: {len(all_results)} entit√©s extraites\")\n",
    "    return all_results\n",
    "\n",
    "raw_aeronautics_data = extract_all_aeronautics_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dffabe",
   "metadata": {},
   "source": [
    "### Aper√ßu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bbfb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_aeronautics_data[:5])  # pour afficher un aper√ßu\n",
    "\n",
    "json_filename = f\"raw.json\"\n",
    "json_filepath = os.path.join(output_dir, json_filename)\n",
    "\n",
    "with open(json_filepath, 'w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(raw_aeronautics_data, jsonfile, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5639628",
   "metadata": {},
   "source": [
    "## üìÅ Export\n",
    "\n",
    "### Construction du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da268123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è CONSTRUCTION DE LA HI√âRARCHIE FINALE\n",
      "=============================================\n",
      "‚úÖ Hi√©rarchie construite: 233 entr√©es totales\n",
      "üéØ Th√©saurus final: 233 entr√©es\n"
     ]
    }
   ],
   "source": [
    "# üèóÔ∏è CONSTRUCTION DE LA HI√âRARCHIE FINALE\n",
    "\n",
    "# def get_id_from_uri(uri):\n",
    "#     # Ex: \"http://www.wikidata.org/entity/Q105557\" ‚Üí \"Q105557\"\n",
    "#     return uri.split(\"/\")[-1] if uri else \"\"\n",
    "\n",
    "def build_final_hierarchy(related_pages_results):\n",
    "    \"\"\"Construit la hi√©rarchie finale avec parents imm√©diats et cat√©gories\"\"\"\n",
    "    print(\"üèóÔ∏è CONSTRUCTION DE LA HI√âRARCHIE FINALE\")\n",
    "    print(\"=\"*45)\n",
    "    \n",
    "    # Cr√©er la hi√©rarchie structur√©e\n",
    "    hierarchy = []\n",
    "    for entry in related_pages_results:\n",
    "    \n",
    "        hierarchy.append(\n",
    "            {\n",
    "            \"ID\": clean_entity_id(entry.get(\"item\", {}).get(\"value\", \"\")),\n",
    "            \"Terme\": entry.get(\"itemLabel\", {}).get(\"value\", \"\"),\n",
    "            \"ID_TG\": clean_entity_id(entry.get(\"parent\", {}).get(\"value\", \"\")),\n",
    "            \"TG\": entry.get(\"parentLabel\", {}).get(\"value\", \"\"),\n",
    "            \"Def\": entry.get(\"itemDescription\", {}).get(\"value\", \"\"),\n",
    "            \"EP\": entry.get(\"synonyms_fr\", {}).get(\"value\", \"\"),\n",
    "            \"TA\": entry.get(\"source_category\", {})\n",
    "        }\n",
    "        )\n",
    "    \n",
    " \n",
    "    print(f\"‚úÖ Hi√©rarchie construite: {len(hierarchy)} entr√©es totales\")\n",
    "    return hierarchy\n",
    "\n",
    "final_thesaurus = build_final_hierarchy(related_pages_results)\n",
    "print(f\"üéØ Th√©saurus final: {len(final_thesaurus)} entr√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdc1047",
   "metadata": {},
   "source": [
    "### Export du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcc3e345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ EXPORT FINAL UNIQUE\n",
      "=========================\n",
      "üìÑ Export CSV: ./output\\thesaurus_aeronautique_FINAL_20250708_100339.csv\n",
      "üìÑ Export JSON: ./output\\thesaurus_aeronautique_FINAL_20250708_100339.json\n",
      "\n",
      "üéØ R√âSUM√â FINAL DU TH√âSAURUS A√âRONAUTIQUE\n",
      "==================================================\n",
      "üìä STATISTIQUES G√âN√âRALES:\n",
      "   ‚Ä¢ Total d'entr√©es: 233\n",
      "   ‚Ä¢ Entr√©es avec synonymes: 0\n",
      "   ‚Ä¢ Entr√©es avec descriptions: 0\n",
      "\n",
      "üìÇ R√âPARTITION PAR CAT√âGORIE:\n",
      "   ‚Ä¢ unknown: 233 (100.0%)\n",
      "\n",
      "üîó TYPES DE RELATIONS:\n",
      "   ‚Ä¢ unknown: 233\n",
      "\n",
      "üåê LANGUES:\n",
      "   ‚Ä¢ unknown: 233\n",
      "\n",
      "üìÅ FICHIERS G√âN√âR√âS:\n",
      "   ‚úÖ CSV: thesaurus_aeronautique_FINAL_20250708_100339.csv\n",
      "   ‚úÖ JSON: thesaurus_aeronautique_FINAL_20250708_100339.json\n",
      "\n",
      "üèÜ MISSION ACCOMPLIE !\n",
      " 233 entr√©es de th√©saurus\n"
     ]
    }
   ],
   "source": [
    "# üíæ EXPORT FINAL UNIQUE - CSV Occidental European Format (semicolon separated)\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def export_final_thesaurus(thesaurus_data):\n",
    "    \"\"\"Exporte le th√©saurus final en CSV (point-virgule, format europ√©en) et JSON\"\"\"\n",
    "    print(\"üíæ EXPORT FINAL UNIQUE\")\n",
    "    print(\"=\"*25)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 1. Export CSV - Occidental European (semicolon separator, utf-8-sig BOM)\n",
    "    csv_filename = f\"thesaurus_aeronautique_FINAL_{timestamp}.csv\"\n",
    "    csv_filepath = os.path.join(output_dir, csv_filename)\n",
    "    \n",
    "    fieldnames = [\n",
    "        'ID', 'Terme', 'ID_TG','TG', 'Def', 'EP',\n",
    "        'TA'\n",
    "    ]\n",
    "    \n",
    "    print(f\"üìÑ Export CSV: {csv_filepath}\")\n",
    "    with open(csv_filepath, 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
    "        writer = csv.DictWriter(\n",
    "            csvfile, \n",
    "            fieldnames=fieldnames,\n",
    "            delimiter=';',         # Use semicolon as separator\n",
    "            quoting=csv.QUOTE_MINIMAL\n",
    "        )\n",
    "        writer.writeheader()\n",
    "        for entry in sorted(thesaurus_data, key=lambda x: x[\"ID\"]):\n",
    "            # Ensure all values are strings and convert None to empty string\n",
    "            row = {k: ('' if v is None else str(v)) for k, v in entry.items()}\n",
    "            # Guarantee all required fields exist in row\n",
    "            for field in fieldnames:\n",
    "                row.setdefault(field, '')\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    # 2. Export JSON avec m√©tadonn√©es\n",
    "    json_filename = f\"thesaurus_aeronautique_FINAL_{timestamp}.json\"\n",
    "    json_filepath = os.path.join(output_dir, json_filename)\n",
    "    \n",
    "    stats = analyze_thesaurus_statistics(thesaurus_data)\n",
    "    \n",
    "    json_data = {\n",
    "        \"metadata\": {\n",
    "            \"title\": \"Th√©saurus A√©ronautique Final - Wikidata\",\n",
    "            \"description\": \"Th√©saurus exhaustif avec hi√©rarchie et parents imm√©diats\",\n",
    "            \"version\": \"1.0-FINAL\",\n",
    "            \"created\": timestamp,\n",
    "            \"source\": \"Wikidata SPARQL optimis√©\",\n",
    "            \"total_entries\": len(thesaurus_data),\n",
    "            \"extraction_method\": \"multi-query_hierarchical\",\n",
    "            \"parent_detection\": \"automatic_wikidata_relations\",\n",
    "            \"multilingual_support\": True,\n",
    "            \"format\": \"structured_hierarchical_thesaurus\"\n",
    "        },\n",
    "        \"statistics\": stats,\n",
    "        \"data\": thesaurus_data\n",
    "    }\n",
    "    \n",
    "    print(f\"üìÑ Export JSON: {json_filepath}\")\n",
    "    with open(json_filepath, 'w', encoding='utf-8') as jsonfile:\n",
    "        json.dump(json_data, jsonfile, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    return csv_filepath, json_filepath, stats\n",
    "\n",
    "def analyze_thesaurus_statistics(thesaurus_data):\n",
    "    \"\"\"Analyse les statistiques du th√©saurus final\"\"\"\n",
    "    stats = {\n",
    "        \"total_entries\": len(thesaurus_data),\n",
    "        \"categories\": {},\n",
    "        \"relation_types\": {},\n",
    "        \"languages\": {},\n",
    "        \"hierarchy_depth\": 0,\n",
    "        \"entries_with_synonyms\": 0,\n",
    "        \"entries_with_descriptions\": 0\n",
    "    }\n",
    "    \n",
    "    for entry in thesaurus_data:\n",
    "        # Cat√©gories\n",
    "        category = entry.get(\"category\", \"unknown\")\n",
    "        stats[\"categories\"][category] = stats[\"categories\"].get(category, 0) + 1\n",
    "        \n",
    "        # Types de relation\n",
    "        rel_type = entry.get(\"relation_type\", \"unknown\")\n",
    "        stats[\"relation_types\"][rel_type] = stats[\"relation_types\"].get(rel_type, 0) + 1\n",
    "        \n",
    "        # Langues\n",
    "        lang = entry.get(\"lang\", \"unknown\")\n",
    "        stats[\"languages\"][lang] = stats[\"languages\"].get(lang, 0) + 1\n",
    "        \n",
    "        # Enrichissements\n",
    "        if entry.get(\"synonyms\"):\n",
    "            stats[\"entries_with_synonyms\"] += 1\n",
    "        if entry.get(\"description\"):\n",
    "            stats[\"entries_with_descriptions\"] += 1\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def display_final_summary(stats, csv_file, json_file):\n",
    "    \"\"\"Affiche un r√©sum√© final du th√©saurus g√©n√©r√©\"\"\"\n",
    "    print(\"\\nüéØ R√âSUM√â FINAL DU TH√âSAURUS A√âRONAUTIQUE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"üìä STATISTIQUES G√âN√âRALES:\")\n",
    "    print(f\"   ‚Ä¢ Total d'entr√©es: {stats['total_entries']}\")\n",
    "    print(f\"   ‚Ä¢ Entr√©es avec synonymes: {stats['entries_with_synonyms']}\")\n",
    "    print(f\"   ‚Ä¢ Entr√©es avec descriptions: {stats['entries_with_descriptions']}\")\n",
    "    \n",
    "    print(f\"\\nüìÇ R√âPARTITION PAR CAT√âGORIE:\")\n",
    "    for category, count in sorted(stats[\"categories\"].items(), key=lambda x: x[1], reverse=True):\n",
    "        percentage = (count / stats['total_entries']) * 100\n",
    "        print(f\"   ‚Ä¢ {category}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nüîó TYPES DE RELATIONS:\")\n",
    "    for rel_type, count in sorted(stats[\"relation_types\"].items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"   ‚Ä¢ {rel_type}: {count}\")\n",
    "    \n",
    "    print(f\"\\nüåê LANGUES:\")\n",
    "    for lang, count in stats[\"languages\"].items():\n",
    "        print(f\"   ‚Ä¢ {lang}: {count}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ FICHIERS G√âN√âR√âS:\")\n",
    "    print(f\"   ‚úÖ CSV: {os.path.basename(csv_file)}\")\n",
    "    print(f\"   ‚úÖ JSON: {os.path.basename(json_file)}\")\n",
    "    \n",
    "    print(f\"\\nüèÜ MISSION ACCOMPLIE !\")\n",
    "    print(f\" {stats['total_entries']} entr√©es de th√©saurus\")\n",
    "\n",
    "\n",
    "# Export et r√©sum√© final\n",
    "if final_thesaurus:\n",
    "    csv_file, json_file, statistics = export_final_thesaurus(final_thesaurus)\n",
    "    display_final_summary(statistics, csv_file, json_file)\n",
    "else:\n",
    "    print(\"‚ùå Aucun th√©saurus √† exporter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d148f58",
   "metadata": {},
   "source": [
    "### Nettoyage des doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27f6dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire le CSV (remplace 'ton_fichier.csv' par le tien)\n",
    "df = pd.read_csv(csv_file, sep=';', dtype=str).fillna('')\n",
    "\n",
    "# Fonction pour concat√©ner les valeurs uniques (s√©par√©es par \"|\")\n",
    "def concat_unique(series):\n",
    "    uniques = set([v.strip() for v in series if v.strip() != ''])\n",
    "    return \" | \".join(sorted(uniques)) if uniques else ''\n",
    "\n",
    "# Grouper par 'ID', en concat√©nant les valeurs diff√©rentes pour chaque colonne\n",
    "df_clean = df.groupby('ID', as_index=False).agg(concat_unique)\n",
    "\n",
    "# Sauvegarder le r√©sultat\n",
    "df_clean.to_csv(csv_file, sep=';', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"‚úÖ CSV nettoy√© et export√© sous {csv_file}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
