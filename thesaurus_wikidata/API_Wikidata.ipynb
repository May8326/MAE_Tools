{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "339b9f1f",
   "metadata": {},
   "source": [
    "# 🚀 Requête WIKIDATA\n",
    "\n",
    "## 📑 Mode d'emploi\n",
    "\n",
    "Suivre les instructions au fil du notebook et exécuter une à une les cellules de code en appuyant sur la petite flèche à gauche (▶️)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f576147d",
   "metadata": {},
   "source": [
    "## 🔨 Construction de l'environnement nécessaire et configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74111c85",
   "metadata": {},
   "source": [
    "### Installation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdaf8794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "✅ Installation terminée !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# 📦 MODULES NECESSAIRES : NORMALEMENT, NE RUN QU'A LA PREMIERE UTILISATION\n",
    "%pip install -q SPARQLWrapper tqdm pandas\n",
    "\n",
    "print(\"✅ Installation terminée !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e7bad",
   "metadata": {},
   "source": [
    "### Configuration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7becfc5d",
   "metadata": {},
   "source": [
    "#### Paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86a25c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Imports terminés !\n"
     ]
    }
   ],
   "source": [
    "# 🔧 IMPORTS PYTHON\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "print(\"🔧 Imports terminés !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f700d27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "                                      🚀 CONFIGURATION TERMINÉE                                      \n",
      "====================================================================================================\n",
      "📁 Dossier de sortie                  ./output\n",
      "⏱️  Rate limit                        3.0s entre requêtes\n",
      "📦 Taille des batches                 10\n",
      "🔄 Nombre maximal de tentatives       3\n",
      "⏳ Délai de timeout des requêtes      60s\n",
      "🔍 Taille du batch d'enrich.         15\n",
      "🔁 Limite de boucle                  100 itérations\n",
      "🌐 Endpoint Wikidata                 https://query.wikidata.org/sparql\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 🔧 CONFIGURATION PERSONNALISABLE DE LA REQUETE\n",
    "\n",
    "WIKIDATA_ENDPOINT = \"https://query.wikidata.org/sparql\" # Endpoint SPARQL de Wikidata\n",
    "RATE_LIMIT_DELAY = 3.0  # Délai entre les requêtes\n",
    "BATCH_SIZE = 10  # Taille des batches pour les requêtes\n",
    "MAX_RETRIES = 3  # Nombre maximal de tentatives en cas d'échec\n",
    "REQUEST_TIMEOUT = 60 # Temps au bout duquel un requête s'arrête automatiquement s'il n'y a pas de réponse (en secondes)\n",
    "ENRICHMENT_BATCH_SIZE = 15 # Taille du batch pour l'enrichissement des données\n",
    "LOOP_LIMIT = 100 # Nombre réponses limite par boucle (permet de requêter petit à petit pour ne pas surcharger l'API)\n",
    "LOOP_OFFSET = 0 # Décalage pour la pagination des résultats\n",
    "MAX_RESULTS = None  # Nombre maximal de résultats à récupérer (pour éviter de surcharger l'API)\n",
    "\n",
    "\n",
    "# 📁 Configuration du dossier de sortie \n",
    "output_dir = \"./output\" # Paramètre à remplacer si vous souhaitez un autre dossier de sortie (faire un copier coller du chemin d'un fichier)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"🚀 CONFIGURATION TERMINÉE\".center(100))\n",
    "print(\"=\"*100)\n",
    "print(\n",
    "    f\"📁 Dossier de sortie                  {output_dir}\\n\"\n",
    "    f\"⏱️  Rate limit                        {RATE_LIMIT_DELAY}s entre requêtes\\n\"\n",
    "    f\"📦 Taille des batches                 {BATCH_SIZE}\\n\"\n",
    "    f\"🔄 Nombre maximal de tentatives       {MAX_RETRIES}\\n\"\n",
    "    f\"⏳ Délai de timeout des requêtes      {REQUEST_TIMEOUT}s\\n\"\n",
    "    f\"🔍 Taille du batch d'enrich.         {ENRICHMENT_BATCH_SIZE}\\n\"\n",
    "    f\"🔁 Limite de boucle                  {LOOP_LIMIT} itérations\\n\"\n",
    "    f\"🌐 Endpoint Wikidata                 {WIKIDATA_ENDPOINT}\"\n",
    ")\n",
    "print(\"=\"*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27ffccf",
   "metadata": {},
   "source": [
    "#### Client sparql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519640a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fonctions de requête SPARQL prêtes !\n"
     ]
    }
   ],
   "source": [
    "# 🛠️ FONCTION POUR CHOISIR UN TERME A REQUÊTER\n",
    "\n",
    "def ask_query_term():\n",
    "    \"\"\"\n",
    "    Fonction pour demander à l'utilisateur de choisir entre recherche par id ou par label\n",
    "    Et lui demande de rentrer la valeur à rechercher\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🔍 Choisissez le type de recherche :\")\n",
    "    print(\"1. Recherche par ID (ex: Q42)\")\n",
    "    print(\"2. Recherche par label (ex: Douglas Adams)\")\n",
    "    \n",
    "    choice = input(\"Entrez 1 ou 2 : \").strip()\n",
    "    \n",
    "    if choice == \"2\":\n",
    "        search_term = input(\"Entrez le nom de l'entité à rechercher dans wikidata, en anglais (ex: aeronautics) : \").strip()\n",
    "        if not search_term:\n",
    "            print(\"❌ Aucun nom d'entité fourni.\")\n",
    "            exit(1)\n",
    "        return f'\"{search_term}\"'  # Guillemets pour recherche textuelle\n",
    "    elif choice == \"1\":\n",
    "        search_term = input(\"Entrez l'ID de l'entité à rechercher dans wikidata (ex: Q42) : \").strip()\n",
    "        # Validation de l'ID de l'entité\n",
    "        if not search_term or not re.match(r\"^Q\\d+$\", search_term):\n",
    "            print(\"❌ ID d'entité invalide. Veuillez entrer un ID valide (ex: Q42).\")\n",
    "            exit(1)\n",
    "        return search_term  # ← Retourner juste l'ID sans préfixe\n",
    "    else:\n",
    "        print(\"Choix invalide, veuillez réessayer.\")\n",
    "        return ask_query_term()\n",
    "\n",
    "# 🛠️ FONCTIONS DE PARAMETRAGE DES REQUÊTES ET DU CARNET\n",
    "\n",
    "################################################################################\n",
    "# FONCTION POUR CRÉER UN CLIENT SPARQL\n",
    "################################################################################\n",
    "def create_sparql_client():\n",
    "    \"\"\"\n",
    "    Crée un client SPARQL pour interagir avec Wikidata\n",
    "    :return: Instance de SPARQLWrapper configurée pour Wikidata\n",
    "    \"\"\"\n",
    "    sparql = SPARQLWrapper(WIKIDATA_ENDPOINT)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    sparql.setTimeout(REQUEST_TIMEOUT)\n",
    "    return sparql\n",
    "\n",
    "################################################################################\n",
    "# FONCTION PRINCIPALE POUR EXÉCUTER UNE REQUÊTE SPARQL\n",
    "################################################################################\n",
    "def execute_sparql_query(query, max_retries=MAX_RETRIES, use_pagination=False, limit=None, max_results=None):\n",
    "    \"\"\"\n",
    "    Exécute une requête SPARQL avec gestion des erreurs, rate limiting et pagination optionnelle\n",
    "    :param query: La requête SPARQL à exécuter\n",
    "    :param max_retries: Nombre maximum de tentatives en cas d'échec\n",
    "    :param use_pagination: Si True, active la pagination automatique\n",
    "    :param limit: Taille des pages pour la pagination (défaut: LOOP_LIMIT)\n",
    "    :param max_results: Nombre maximum de résultats à récupérer (None = illimité)\n",
    "    :return: Résultats de la requête ou une liste vide en cas d'échec\n",
    "    \"\"\"\n",
    "    sparql = create_sparql_client()\n",
    "    print(f\"🔍 Exécution de la requête SPARQL :\\n{query}\\n\")\n",
    "    \n",
    "    # MODE SIMPLE SANS PAGINATION\n",
    "    if not use_pagination:\n",
    "        print(\"🚀 Mode simple (sans pagination) - Envoi de la requête...\")\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                print(f\"📡 Tentative {attempt + 1}/{max_retries} - Envoi de la requête...\")\n",
    "                sparql.setQuery(query)\n",
    "                \n",
    "                print(\"⏳ Attente de la réponse du serveur...\")\n",
    "                results = sparql.query().convert()\n",
    "                \n",
    "                result_count = len(results[\"results\"][\"bindings\"])\n",
    "                print(f\"✅ Requête réussie ! {result_count} résultats obtenus\")\n",
    "                \n",
    "                \n",
    "                return results[\"results\"][\"bindings\"]\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Tentative {attempt + 1}/{max_retries} échouée: {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = RATE_LIMIT_DELAY * (attempt + 2)\n",
    "                    print(f\"⏳ Attente de {wait_time}s avant nouvelle tentative...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    print(f\"❌ Requête échouée après {max_retries} tentatives\")\n",
    "                    return []\n",
    "        return []\n",
    "    \n",
    "    # MODE PAGINATION ACTIVE\n",
    "    if limit is None:\n",
    "        limit = LOOP_LIMIT\n",
    "    \n",
    "    all_results = []\n",
    "    offset = 0\n",
    "    \n",
    "    print(f\"🔍 Début de la pagination (limit={limit})...\")\n",
    "    \n",
    "    while True:\n",
    "        paginated_query = f\"{query.rstrip()} LIMIT {limit} OFFSET {offset}\"\n",
    "        print(f\"🔹 Requête OFFSET {offset}, LIMIT {limit}\")\n",
    "        success = False\n",
    "        bindings = []\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                sparql.setQuery(paginated_query)\n",
    "                results = sparql.query().convert()\n",
    "                bindings = results[\"results\"][\"bindings\"]\n",
    "                success = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Tentative {attempt + 1}/{max_retries} échouée à l'offset {offset}: {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(RATE_LIMIT_DELAY * (attempt + 2))\n",
    "                else:\n",
    "                    print(f\"❌ Requête échouée après {max_retries} tentatives à l'offset {offset}\")\n",
    "                    return all_results  # Retourner ce qu'on a réussi à récupérer\n",
    "\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        if not bindings:\n",
    "            print(\"✅ Fin de la pagination - Aucun résultat supplémentaire.\")\n",
    "            break\n",
    "\n",
    "        all_results.extend(bindings)\n",
    "        print(f\"✅ Récupéré {len(bindings)} résultats (total: {len(all_results)})\")\n",
    "        \n",
    "        if max_results and len(all_results) >= max_results:\n",
    "            print(f\"🎯 Limite de {max_results} résultats atteinte.\")\n",
    "            all_results = all_results[:max_results]\n",
    "            break\n",
    "\n",
    "        offset += limit\n",
    "        print(f\"⏳ Attente de {RATE_LIMIT_DELAY}s...\")\n",
    "        time.sleep(RATE_LIMIT_DELAY)\n",
    "    \n",
    "    print(f\"🎯 Total final récupéré : {len(all_results)} résultats.\")\n",
    "    return all_results\n",
    "\n",
    "################################################################################\n",
    "# FONCTION UTILITAIRE POUR EXTRAIRE LES ID DE WIKIDATA\n",
    "################################################################################\n",
    "def clean_entity_id(entity_uri):\n",
    "    \"\"\"\n",
    "    Extrait l'ID d'une entité à partir de son URI\n",
    "    :param entity_uri: URI de l'entité (ex: \"http://www.wikidata.org/entity/Q42'\")\n",
    "    :return: ID de l'entité (ex: \"Q42\") ou une chaîne vide si l'URI est vide\n",
    "    \"\"\"\n",
    "    if not entity_uri:\n",
    "        return \"\"\n",
    "    return entity_uri.split(\"/\")[-1] if \"/\" in entity_uri else entity_uri\n",
    "\n",
    "################################################################################\n",
    "# FONCTION POUR EXÉCUTER DES REQUÊTES SPARQL EN BATCH : VERIFIER L'UTILITE\n",
    "################################################################################\n",
    "def execute_batch_queries(queries, description=\"Requêtes\", use_pagination=False):\n",
    "    \"\"\"\n",
    "    Exécute une liste de requêtes SPARQL en batch\n",
    "    :param queries: Requête SPARQL unique ou liste de requêtes\n",
    "    :param description: Description de la tâche pour le logging\n",
    "    :param use_pagination: Si True, active la pagination pour chaque requête\n",
    "    :return: Liste de tous les résultats combinés\n",
    "    \"\"\"\n",
    "    # Vérifier si queries est une string ou une liste\n",
    "    if isinstance(queries, str):\n",
    "        # Si c'est une string, c'est une seule requête\n",
    "        print(f\"🔹 Exécution d'une requête unique: {description}\")\n",
    "        return execute_sparql_query(queries, use_pagination=use_pagination)\n",
    "    \n",
    "    # Si c'est une liste, traiter comme batch\n",
    "    all_results = []\n",
    "    for i, query in enumerate(tqdm(queries, desc=description)):\n",
    "        results = execute_sparql_query(query, use_pagination=use_pagination)\n",
    "        all_results.extend(results)\n",
    "        if (i + 1) % BATCH_SIZE == 0:\n",
    "            time.sleep(RATE_LIMIT_DELAY)\n",
    "    return all_results\n",
    "\n",
    "################################################################################\n",
    "# FONCTION POUR EXÉCUTER UNE REQUÊTE SPARQL AVEC PAGINATION\n",
    "################################################################################\n",
    "def execute_paginated_query(base_query, limit=None, max_results=MAX_RESULTS, ask_term=False):\n",
    "    \"\"\"\n",
    "    Fonction helper pour exécuter facilement une requête avec pagination\n",
    "    \"\"\"\n",
    "    \n",
    "    # Si ask_term=True, on demande le terme à l'utilisateur\n",
    "    if ask_term:\n",
    "        search_term = ask_query_term()\n",
    "        print(f\"🔍 Recherche pour le terme : {search_term}\")\n",
    "        if search_term:\n",
    "            # Déterminer le type de recherche et formater correctement\n",
    "            if search_term.startswith('Q'):\n",
    "                # Recherche par ID - ajouter le préfixe wd:\n",
    "                formatted_term = f\"wd:{search_term}\"\n",
    "            else:\n",
    "                # Recherche textuelle - utiliser tel quel\n",
    "                formatted_term = search_term\n",
    "            \n",
    "            # Remplacer {{search_term}} dans la requête\n",
    "            base_query = base_query.replace(\"{{search_term}}\", formatted_term)\n",
    "        else:\n",
    "            print(\"❌ Aucun terme fourni, abandon de la requête.\")\n",
    "            return []\n",
    "    \n",
    "    return execute_sparql_query(\n",
    "        base_query, \n",
    "        use_pagination=True, \n",
    "        limit=limit, \n",
    "        max_results=max_results\n",
    "    )\n",
    "print(\"✅ Fonctions de requête SPARQL prêtes !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28847dc",
   "metadata": {},
   "source": [
    "#### Outils Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e417f9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINITION DES TERMES A CHERCHER\n",
    "# =================================================================================\n",
    "\n",
    "#search_term = None  # Initialisation de la variable pour le terme de recherche\n",
    "\n",
    "# def ask_query_term():\n",
    "#     \"\"\"\n",
    "#     Fonction pour demander à l'utilisateur de choisir entre recherche par id ou par label\n",
    "#     Et lui demande de rentrer la valeur à rechercher\n",
    "#     \"\"\"\n",
    "#     print(\"🔍 Choisissez le type de recherche :\")\n",
    "#     print(\"1. Recherche par ID (ex: Q42)\")\n",
    "#     print(\"2. Recherche par label (ex: Douglas Adams)\")\n",
    "    \n",
    "#     choice = input(\"Entrez 1 ou 2 : \").strip()\n",
    "    \n",
    "#     if choice == \"2\":\n",
    "#         search_term = input(\"Entrez le nom de l'entité à rechercher dans wikidata, en anglais (ex: aeronautics) : \").strip()\n",
    "#         if not search_term:\n",
    "#             print(\"❌ Aucun nom d'entité fourni.\")\n",
    "#             exit(1)  # Sortir du script si aucun nom n'est fourni\n",
    "#         return search_term \n",
    "#     elif choice == \"1\":\n",
    "#         search_term = input(\"Entrez l'ID de l'entité à rechercher dans wikidata (ex: Q42) : \").strip()\n",
    "#         # Validation de l'ID de l'entité\n",
    "#         if not search_term or not re.match(r\"^Q\\d+$\", search_term):\n",
    "#             print(\"❌ ID d'entité invalide. Veuillez entrer un ID valide (ex: Q42).\")\n",
    "#             exit(1)  # Sortir du script si l'ID est invalide\n",
    "#         return search_term\n",
    "#     else:\n",
    "#         print(\"Choix invalide, veuillez réessayer.\")\n",
    "#         return ask_query_term()  # Redemander si le choix est invalide\n",
    "    \n",
    "# ask_query_term()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d392e0",
   "metadata": {},
   "source": [
    "## 🧐 REQUÊTES\n",
    "\n",
    "Résumé des requêtes disponibles : \n",
    "| Type de requête | Résumé | Output |\n",
    "| --- | --- | --- |\n",
    "| Recherche par nom |  `SELECT ?item ?itemLabel WHERE { ?item rdfs:label ?itemLabel. FILTER(LANG(?itemLabel) = \"en\"). FILTER(CONTAINS(LCASE(?itemLabel), \"{search_entity_name}\")). }` | Label, ID\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eea4ad",
   "metadata": {},
   "source": [
    "### 📖 Bibliothèque de requêtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aafd293e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Requêtes prêtes !\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================\n",
    "# DEFINITION DE REQUÊTE SPARQL POUR RECHERCHER UNE ENTITÉ PAR NOM\n",
    "# =================================================================================\n",
    "\n",
    "# REQUETE DANS LES LABELS\n",
    "query_by_label = \"\"\"\n",
    "        SELECT ?item ?itemLabel\n",
    "        WHERE {{\n",
    "            ?item rdfs:label ?itemLabel.\n",
    "            FILTER(LANG(?itemLabel) = \"en\").\n",
    "            FILTER(CONTAINS(LCASE(?itemLabel), {{search_term}})).\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "# REQUETE DANS LES PARENTS\n",
    "query_by_parent = \"\"\"\n",
    "        SELECT ?item ?itemLabel\n",
    "        WHERE {{\n",
    "            ?item wdt:P31*/wdt:P279* ?parent.\n",
    "            ?parent rdfs:label ?parentLabel.\n",
    "            FILTER(LANG(?parentLabel) = \"en\").\n",
    "            FILTER(CONTAINS(LCASE(?parentLabel), {{search_term}})).\n",
    "            SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "\n",
    "# =================================================================================\n",
    "# AIDES POUR LES REQUETES ULTERIEURES\n",
    "# =================================================================================\n",
    "\n",
    "# REQUETE POUR OBTENIR DANS QUELLES PROPRIÉTÉS L'ENTITÉ EST UTILISÉE\n",
    "query_properties = \"\"\"\n",
    "SELECT ?prop WHERE {\n",
    "  {\n",
    "    SELECT ?prop \n",
    "           WHERE {\n",
    "      ?item ?prop {{search_term}}.\n",
    "    }\n",
    "    GROUP BY ?prop\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# =================================================================================\n",
    "# REQUETES THEMATIQUES\n",
    "# =================================================================================\n",
    "\n",
    "query_aero_events = \"\"\"\n",
    "SELECT ?item ?itemLabel ?lien ?lienLabel ?prop ?propLabel WHERE {\n",
    "  VALUES ?lien { wd:Q1070669 wd:Q8421 wd:Q765633 wd:Q108284447 }\n",
    "  ?item ?prop ?lien.\n",
    "  ?item wdt:P31/wdt:P279 wd:Q1656682.\n",
    "  \n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr,en,[AUTO_LANGUAGE]\". }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "query_events = \"\"\"\n",
    "SELECT DISTINCT ?item ?label\n",
    "WHERE {\n",
    "  VALUES ?type {\n",
    "    wd:Q1190554 wd:Q1656682\n",
    "    }\n",
    "  ?item wdt:P31 ?evenement .\n",
    "  ?item wdt:P585 ?date .\n",
    "  FILTER (?date > \"1800-01-01T00:00:00Z\"^^xsd:dateTime) .\n",
    "  ?item rdfs:label ?label .\n",
    "  FILTER (lang(?label) = \"en\") .\n",
    "  \n",
    "  # Regex sur labels, descriptions ou alias\n",
    "  FILTER (EXISTS {\n",
    "    {\n",
    "      ?item rdfs:label ?text.\n",
    "      FILTER(REGEX(LCASE(?text), \"(aero|aviat|flight|aircraft|airport|\\\\bplane\\\\b)\", \"i\"))\n",
    "    } UNION {\n",
    "      ?item schema:description ?text.\n",
    "      FILTER(REGEX(LCASE(?text), \"(aero|aviat|flight|aircraft|airport|\\\\bplane\\\\b)\", \"i\"))\n",
    "    } UNION {\n",
    "      ?item skos:altLabel ?text.\n",
    "      FILTER(REGEX(LCASE(?text), \"(aero|aviat|flight|aircraft|airport|\\\\bplane\\\\b)\", \"i\"))\n",
    "    }\n",
    "  })\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "query_aero_events_types = \"\"\"\n",
    "# Ce code SPARQL extrait une hiérarchie d’éléments Wikidata liés à l’aviation, en marquant pour chaque élément la nature du lien (direct ou hérité), la profondeur dans la hiérarchie, et en affichant les libellés.\n",
    "\n",
    "SELECT DISTINCT ?item ?itemLabel ?parent ?parentLabel ?depth ?aviationLink WHERE {\n",
    "  \n",
    "  # Étape 1 : Sélectionner tous les items qui ont un lien avec l’aviation.\n",
    "  {\n",
    "    SELECT DISTINCT ?aviationLinkedItem WHERE {\n",
    "      # On définit trois types d'évènements de base liés à l’aviation (Q1656682, Q1190554, Q108586636).\n",
    "      VALUES ?evenement {wd:Q1656682 wd:Q1190554 wd:Q108586636}\n",
    "      # On cherche les items dont le type (P31) ou un type parent (P279) correspond à ces évènements.\n",
    "      ?aviationLinkedItem wdt:P31/wdt:P279 ?evenement.\n",
    "      \n",
    "      # FILTRE AERONAUTIQUE : Détection de mots-clés dans les libellés, descriptions ou labels alternatifs.\n",
    "      {\n",
    "        ?aviationLinkedItem rdfs:label ?label.\n",
    "        FILTER(REGEX(LCASE(?label), \"(aero|aviation|aircraft|flight|aerial|plane|airport|pilot)\", \"i\"))\n",
    "      } UNION {\n",
    "        ?aviationLinkedItem schema:description ?desc.\n",
    "        FILTER(REGEX(LCASE(?desc), \"(aero|aviation|aircraft|flight|aerial|plane|airport|pilot)\", \"i\"))\n",
    "      } UNION {\n",
    "        ?aviationLinkedItem skos:altLabel ?altLabel.\n",
    "        FILTER(REGEX(LCASE(?altLabel), \"(aero|aviation|aircraft|flight|aerial|plane|airport|pilot)\", \"i\"))\n",
    "      } UNION {\n",
    "        # On regarde aussi si l’item est lié, via certaines propriétés, à des entités aéronautiques spécifiques.\n",
    "        ?aviationLinkedItem (wdt:P31|wdt:P279|wdt:P361|wdt:P527|wdt:P1269) ?aeronauticEntity.\n",
    "        VALUES ?aeronauticEntity {\n",
    "          wd:Q8421      # aéronautique\n",
    "          wd:Q765633    # aviation  \n",
    "          wd:Q11436     # aircraft\n",
    "          wd:Q62447     # aérodrome\n",
    "          wd:Q1248784   # aéroport international\n",
    "          wd:Q46970     # compagnie aérienne\n",
    "          wd:Q744913    # accident d'avion\n",
    "          wd:Q206021    # vol\n",
    "          wd:Q2876213   # aérospatiale\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Étape 2 : Pour chaque item lié à l’aviation, on remonte toute la hiérarchie de type (P31).\n",
    "  ?aviationLinkedItem wdt:P31* ?item.\n",
    "  \n",
    "  # On garde seulement les items dont le type ultime est Q108586636 (évènement de transport aérien).\n",
    "  ?item wdt:P31+ wd:Q108586636.\n",
    "  \n",
    "  # On récupère le parent direct dans la hiérarchie pour l’affichage.\n",
    "  OPTIONAL { ?item wdt:P31 ?parent }\n",
    "  \n",
    "  # Calcul de la profondeur de l’item dans la hiérarchie (distance au type de base).\n",
    "  {\n",
    "    SELECT ?item (COUNT(?intermediate) AS ?depth) WHERE {\n",
    "      ?item wdt:P31+ ?intermediate.\n",
    "      ?intermediate wdt:P31* wd:Q108586636.\n",
    "    }\n",
    "    GROUP BY ?item\n",
    "  }\n",
    "  \n",
    "  # On limite la profondeur d’analyse à 4 pour éviter des hiérarchies trop longues.\n",
    "  FILTER(?depth <= 4)\n",
    "  \n",
    "  # On marque si le lien aviation est direct (l’item est lui-même identifié comme aviation) ou hérité (par la hiérarchie).\n",
    "  BIND(IF(?item = ?aviationLinkedItem, \"DIRECT\", \"INHERITED\") AS ?aviationLink)\n",
    "  \n",
    "  # On ajoute les labels en anglais, français, ou langue auto-détectée.\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en,fr,[AUTO_LANGUAGE]\". }\n",
    "}\n",
    "# Tri des résultats par profondeur, type de lien, parent et label.\n",
    "ORDER BY ?depth ?aviationLink ?parentLabel ?itemLabel\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"✅ Requêtes prêtes !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85a5c57",
   "metadata": {},
   "source": [
    "### Aide à la requête : Lancer une requête individuelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbd5d923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Exécution de la requête avec pagination : \n",
      "    SELECT DISTINCT ?item ?itemLabel ?prop ?itemDescription ?parent ?parentLabel\n",
      "    WHERE {\n",
      "      ?item ?prop wd:Q8421 .\n",
      "      OPTIONAL {\n",
      "      ?item (wdt:P31|wdt:P279) ?parent .\n",
      "      ?parent rdfs:label ?parentLabel .\n",
      "      ?page schema:description ?itemDescription .\n",
      "      FILTER(LANG(?parentLabel) = \"en\" || LANG(?parentLabel) = \"fr\")\n",
      "      FILTER(LANG(?itemDescription) = \"en\" || LANG(?itemDescription) = \"fr\")\n",
      "      }\n",
      "      SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr,en\". }\n",
      "    }\n",
      "    \n",
      "🔍 Exécution de la requête SPARQL :\n",
      "\n",
      "    SELECT DISTINCT ?item ?itemLabel ?prop ?itemDescription ?parent ?parentLabel\n",
      "    WHERE {\n",
      "      ?item ?prop wd:Q8421 .\n",
      "      OPTIONAL {\n",
      "      ?item (wdt:P31|wdt:P279) ?parent .\n",
      "      ?parent rdfs:label ?parentLabel .\n",
      "      ?page schema:description ?itemDescription .\n",
      "      FILTER(LANG(?parentLabel) = \"en\" || LANG(?parentLabel) = \"fr\")\n",
      "      FILTER(LANG(?itemDescription) = \"en\" || LANG(?itemDescription) = \"fr\")\n",
      "      }\n",
      "      SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr,en\". }\n",
      "    }\n",
      "    \n",
      "\n",
      "🔍 Début de la pagination (limit=100)...\n",
      "🔹 Requête OFFSET 0, LIMIT 100\n",
      "⚠️  Tentative 1/3 échouée à l'offset 0: The read operation timed out\n",
      "⚠️  Tentative 2/3 échouée à l'offset 0: The read operation timed out\n",
      "⚠️  Tentative 3/3 échouée à l'offset 0: The read operation timed out\n",
      "❌ Requête échouée après 3 tentatives à l'offset 0\n"
     ]
    }
   ],
   "source": [
    "# EXECUTER UNE REQUÊTE SPARQL DEFINIE AVEC PAGINATION\n",
    "\n",
    "# =================================================================================\n",
    "# CHOISIR ICI LA REQUÊTE À EXÉCUTER\n",
    "# =================================================================================\n",
    "query = query_properties_one  # Remplacer par la requête souhaitée\n",
    "\n",
    "# =================================================================================\n",
    "# FONCTION POUR EXÉCUTER LA REQUÊTE SPARQL AVEC PAGINATION\n",
    "# =================================================================================\n",
    "def execute_specific_query(query):\n",
    "    \"\"\"\n",
    "    Exécute une requête SPARQL avec pagination.\n",
    "    :param query: La requête SPARQL à exécuter.\n",
    "    :param limit: Nombre de résultats par page (par défaut: MAX_RESULTS).\n",
    "    :param max_results: Nombre maximum de résultats à récupérer (par défaut: MAX_RESULTS).\n",
    "    :return: Liste des résultats paginés.\n",
    "    \"\"\"\n",
    "    # Vérifier si la requête est vide\n",
    "    if not query:\n",
    "        print(\"❌ Aucune requête SPARQL fournie.\")\n",
    "        return []\n",
    "    # Afficher les détails de la requête\n",
    "    print(f\"🔍 Exécution de la requête avec pagination : {query}\")\n",
    "    # Exécuter la requête avec pagination\n",
    "    return execute_paginated_query(query)\n",
    "\n",
    "query_results = execute_specific_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97fed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"✅ Requête exécutée avec succès, {len(query_results)} résultats obtenus.\")\n",
    "\n",
    "# Pour obtenir automatiquement le nom de la variable (ex: \"query_aero_events\") pointant vers la valeur de query,\n",
    "# on peut parcourir les variables globales et comparer leur valeur à celle de query.\n",
    "# Attention : cela ne fonctionne que si la variable est accessible dans le scope global et que la valeur n'est pas modifiée.\n",
    "\n",
    "def get_query_var_name(query_value):\n",
    "    for var_name, var_val in globals().items():\n",
    "        if var_val is query_value:\n",
    "            return var_name\n",
    "    return \"query\"\n",
    "\n",
    "query_var_name = get_query_var_name(query)\n",
    "raw_json_filename = f\"{datetime.now().strftime('%Y%m%d_%H%M%S')}_RAW_{query_var_name}.json\"\n",
    "raw_json_filepath = os.path.join(output_dir, raw_json_filename)\n",
    "\n",
    "with open(raw_json_filepath, 'w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(query_results, jsonfile, ensure_ascii=False, indent=2)\n",
    "print(\"=\" * 100)\n",
    "print(f\"✅ Résultats sauvegardés dans {raw_json_filepath}\")\n",
    "\n",
    "# 📩 SAUVEGARDE DES RÉSULTATS EN CSV\n",
    "\n",
    "raw_csv_filename = f\"{datetime.now().strftime('%Y%m%d_%H%M%S')}_RAW_{query_var_name}.csv\"\n",
    "raw_csv_filepath = os.path.join(output_dir, raw_csv_filename)\n",
    "with open(raw_csv_filepath, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = query_results[0].keys() if query_results else []\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    writer.writeheader()\n",
    "    for result in query_results:\n",
    "        writer.writerow({k: v['value'] if isinstance(v, dict) else v for k, v in result.items()})\n",
    "print(f\"✅ Résultats sauvegardés dans {raw_csv_filepath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661655c9",
   "metadata": {},
   "source": [
    "### 1. Aide à la requête : Rechercher une entité par nom \n",
    "\n",
    "Cette fonction peut s'utiliser pour retirer tous les termes wikidata qui comprennent une chaîne de caractère\n",
    "1. Dans leur label\n",
    "2. Dans un de leurs termes génériques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e118180b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Choisissez le type de recherche :\n",
      "1. Recherche par ID (ex: Q42)\n",
      "2. Recherche par label (ex: Douglas Adams)\n",
      "🔍 Recherche pour le terme : \"douglas adams\"\n",
      "🔍 Requête APRÈS remplacement :\n",
      "\n",
      "        SELECT ?item ?itemLabel\n",
      "        WHERE {{\n",
      "            ?item rdfs:label ?itemLabel.\n",
      "            FILTER(LANG(?itemLabel) = \"en\").\n",
      "            FILTER(CONTAINS(LCASE(?itemLabel), \"douglas adams\")).\n",
      "        }}\n",
      "        \n",
      "==================================================\n",
      "🔍 Exécution de la requête SPARQL :\n",
      "\n",
      "        SELECT ?item ?itemLabel\n",
      "        WHERE {{\n",
      "            ?item rdfs:label ?itemLabel.\n",
      "            FILTER(LANG(?itemLabel) = \"en\").\n",
      "            FILTER(CONTAINS(LCASE(?itemLabel), \"douglas adams\")).\n",
      "        }}\n",
      "        \n",
      "\n",
      "🔍 Début de la pagination (limit=100)...\n",
      "🔹 Requête OFFSET 0, LIMIT 100\n",
      "⚠️  Tentative 1/3 échouée à l'offset 0: The read operation timed out\n",
      "⚠️  Tentative 2/3 échouée à l'offset 0: The read operation timed out\n",
      "⚠️  Tentative 3/3 échouée à l'offset 0: The read operation timed out\n",
      "❌ Requête échouée après 3 tentatives à l'offset 0\n"
     ]
    }
   ],
   "source": [
    "# 🔎 RECHERCHE PAR NOM\n",
    "# =================================================================================\n",
    "\n",
    "\n",
    "# =================================================================================\n",
    "# Demande à l'utilisateur le nom de l'entité à rechercher dans Wikidata\n",
    "# =================================================================================\n",
    "\"\"\"\n",
    "search_entity_name = input(\"Entrez le nom de l'entité à rechercher dans wikidata, en anglais (ex: aeronautics) : \").strip()\n",
    "if not search_entity_name:\n",
    "    print(\"❌ Aucun nom d'entité fourni.\")\n",
    "    exit(1)  # Sortir du script si aucun nom n'est fourni\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# =================================================================================\n",
    "# DEMANDE À L'UTILISATEUR LE TYPE DE REQUÊTE À UTILISER\n",
    "# =================================================================================\n",
    "\n",
    "# Choix de la requête à utiliser\n",
    "query_choice = input(\n",
    "    \"Quel type de requête utiliser ?\\n\"\n",
    "    \"1️⃣ Recherche d'une chaîne dans les labels\\n\"\n",
    "    \"2️⃣ Requête d'une chaîne dans les parents\\n\"\n",
    "    \"Entrez le numéro de votre choix (1 ou 2) : \"\n",
    ").strip()\n",
    "if query_choice not in [\"1\", \"2\"]:\n",
    "    print(\"❌ Choix invalide. Veuillez entrer 1 ou 2.\")\n",
    "    exit(1)  # Sortir du script si le choix est invalide\n",
    "\n",
    "if query_choice == \"1\":\n",
    "    query_regex = query_by_label\n",
    "elif query_choice == \"2\":\n",
    "    query_regex = query_by_parent\n",
    "\n",
    "raw_entity_by_name_results = execute_paginated_query(query_regex, ask_term=True)\n",
    "# def find_entity_by_name(search_entity_name=search_term, query_regex=query_regex):\n",
    "#     \"\"\"\n",
    "#     Demande à l'utilisateur le nom de l'entité à rechercher dans Wikidata\n",
    "#     :return: Liste des résultats de la recherche\n",
    "#     \"\"\"\n",
    "    \n",
    "#     print(\"=\" * 100)\n",
    "#     print(f\"🔍 RECHERCHE DES TERMES CONTENANT LA CHAINE DE CARACTERE :  '{search_entity_name}'...\")\n",
    "#     print(\"=\" * 100)\n",
    "#     print(f\"🔍 REQUÊTE ENVOYEE :{query_regex}\")\n",
    "#     print(\"=\" * 100)\n",
    "#     return execute_paginated_query(query_regex)\n",
    "# raw_entity_by_name_results = find_entity_by_name()\n",
    "\n",
    "# =================================================================================\n",
    "# 📩 SAUVEGARDE DES RÉSULTATS EN JSON\n",
    "# =================================================================================\n",
    "\n",
    "def save_raw_results_to_json(raw_entity_by_name_results, search_term):\n",
    "    \"\"\"\n",
    "    Sauvegarde les résultats bruts de la recherche dans un fichier JSON\n",
    "    :param raw_entity_by_name_results: Résultats bruts de la recherche\n",
    "    :param search_entity_name: Nom de l'entité recherchée\n",
    "    \"\"\"\n",
    "    # Création du nom de fichier avec la date et l'heure actuelles\n",
    "    raw_json_filename = f\"{datetime.now().strftime('%Y%m%d_%H%M%S')}_RAW_{search_term}.json\"\n",
    "    raw_json_filepath = os.path.join(output_dir, raw_json_filename)\n",
    "\n",
    "    with open(raw_json_filepath, 'w', encoding='utf-8') as jsonfile:\n",
    "        json.dump(raw_entity_by_name_results, jsonfile, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(\"=\" * 100)\n",
    "    print(f\"✅ RESULTATS SAUVEGARDES DANS {raw_json_filepath}\")\n",
    "#save_raw_results_to_json(raw_entity_by_name_results, search_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad135870",
   "metadata": {},
   "source": [
    "### 2. Aide à la requête : Trouver toutes les propriétés dans lesquelles un terme est utilisé\n",
    "\n",
    "#### Exécuter la requête"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e81aa811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Choisissez le type de recherche :\n",
      "1. Recherche par ID (ex: Q42)\n",
      "2. Recherche par label (ex: Douglas Adams)\n",
      "🔍 Recherche pour le terme : Q22719\n",
      "🔍 Exécution de la requête SPARQL :\n",
      "\n",
      "SELECT ?prop WHERE {\n",
      "  {\n",
      "    SELECT ?prop \n",
      "           WHERE {\n",
      "      ?item ?prop wd:Q22719.\n",
      "    }\n",
      "    GROUP BY ?prop\n",
      "  }\n",
      "}\n",
      "\n",
      "\n",
      "🔍 Début de la pagination (limit=100)...\n",
      "🔹 Requête OFFSET 0, LIMIT 100\n",
      "✅ Récupéré 43 résultats (total: 43)\n",
      "⏳ Attente de 3.0s...\n",
      "🔹 Requête OFFSET 100, LIMIT 100\n",
      "✅ Fin de la pagination - Aucun résultat supplémentaire.\n",
      "🎯 Total final récupéré : 43 résultats.\n"
     ]
    }
   ],
   "source": [
    "# REQUETE PAR PROPRIETE\n",
    "# =================================================================================\n",
    "\n",
    "# Exécuter avec demande de terme\n",
    "query_results = execute_paginated_query(query_properties, ask_term=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb3b9e1",
   "metadata": {},
   "source": [
    "#### Créer un dictionnaire avec index avec la liste de toutes les propriétés extraites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e0025f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P2650', 'owl:sameAs', 'P301', 'P31', 'P1535', 'P921', 'P1269', 'P1889', 'P101', 'P279', 'P921', 'P301', 'P31', 'P1535', 'about', 'P1269', 'P1889', 'P279', 'P101', 'P2650', 'P812', 'P101', 'P921', 'P5137', 'P9488', 'P5137', 'P9488']\n"
     ]
    }
   ],
   "source": [
    "# Extraction simple des IDs de propriété depuis query_results\n",
    "all_property_ids = [clean_entity_id(prop['prop']['value']).replace('#', ':') for prop in query_results if 'prop' in prop and 'value' in prop['prop']]\n",
    "\n",
    "print(all_property_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48ad8e8",
   "metadata": {},
   "source": [
    "#### Requêter toutes les pages reliées à l'identifiant recherché"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7c030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Choisissez le type de recherche :\n",
      "1. Recherche par ID (ex: Q42)\n",
      "2. Recherche par label (ex: Douglas Adams)\n",
      "wdt:P2650 owl:sameAs wdt:P301 wdt:P31 wdt:P1535 wdt:P921 wdt:P1269 wdt:P1889 wdt:P101 wdt:P279 wdt:P921 wdt:P301 wdt:P31 wdt:P1535 wdt:P1269 wdt:P1889 wdt:P279 wdt:P101 wdt:P2650 wdt:P812 wdt:P101 wdt:P921 wdt:P5137 wdt:P9488 wdt:P5137 wdt:P9488\n",
      "🔍 Exécution de la requête SPARQL :\n",
      "    SELECT \n",
      "  ?item \n",
      "  ?itemLabel \n",
      "  (GROUP_CONCAT(DISTINCT ?propLabel; separator=\", \") AS ?props)\n",
      "  (COALESCE(?itemDescription_fr, ?itemDescription_en) AS ?itemDescription) # renvoie la première description valide trouvée.\n",
      "  ?parent1\n",
      "  (COALESCE(?parent1Label_fr, ?parent1Label_en) AS ?parent1Label)\n",
      "  ?parent2\n",
      "  (COALESCE(?parent2Label_fr, ?parent2Label_en) AS ?parent2Label)\n",
      "WHERE {\n",
      "  VALUES ?prop { \n",
      "    wdt:P2650 owl:sameAs wdt:P301 wdt:P31 wdt:P1535 wdt:P921 wdt:P1269 wdt:P1889 wdt:P101 wdt:P279 wdt:P921 wdt:P301 wdt:P31 wdt:P1535 wdt:P1269 wdt:P1889 wdt:P279 wdt:P101 wdt:P2650 wdt:P812 wdt:P101 wdt:P921 wdt:P5137 wdt:P9488 wdt:P5137 wdt:P9488\n",
      "  }\n",
      "  ?item ?prop  wd:Q2876213 .\n",
      "  OPTIONAL {\n",
      "  ?wd wikibase:directClaim ?prop .\n",
      "  ?wd rdfs:label ?propLabel .\n",
      "  FILTER(LANG(?propLabel) = \"fr\")\n",
      "  }\n",
      "\n",
      "  # Description fr/en selon disponibilité\n",
      "  OPTIONAL { ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }\n",
      "  OPTIONAL { ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }\n",
      "\n",
      "  # parent1Label fr/en selon disponibilité\n",
      "  OPTIONAL {\n",
      "    ?item wdt:P31 ?parent1 .\n",
      "    OPTIONAL { ?parent1 rdfs:label ?parent1Label_fr . FILTER(LANG(?parent1Label_fr) = \"fr\") }\n",
      "    OPTIONAL { ?parent1 rdfs:label ?parent1Label_en . FILTER(LANG(?parent1Label_en) = \"en\") }\n",
      "\n",
      "    # parent2Label fr/en selon disponibilité\n",
      "    OPTIONAL {\n",
      "      ?item wdt:P279|wdt: ?parent2 .\n",
      "      OPTIONAL { ?parent2 rdfs:label ?parent2Label_fr . FILTER(LANG(?parent2Label_fr) = \"fr\") }\n",
      "      OPTIONAL { ?parent2 rdfs:label ?parent2Label_en . FILTER(LANG(?parent2Label_en) = \"en\") }\n",
      "    }\n",
      "  }\n",
      "\n",
      "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr,en\". }\n",
      "}\n",
      "GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?parent1Label_fr ?parent1Label_en ?parent2Label_fr ?parent2Label_en ?parent1 ?parent2\n",
      "\n",
      "\n",
      "🚀 Mode simple (sans pagination) - Envoi de la requête...\n",
      "📡 Tentative 1/3 - Envoi de la requête...\n",
      "⏳ Attente de la réponse du serveur...\n",
      "✅ Requête réussie ! 79 résultats obtenus\n",
      "✅ Résultats des pages liées sauvegardés dans ./output\\20250708_121620_related_pages_Q2876213.json\n"
     ]
    }
   ],
   "source": [
    "# Génère une requête SPARQL pour trouver toutes les pages reliées au search_term via les propriétés de all_property_ids\n",
    "\n",
    "def build_related_pages_query(search_term, property_ids):\n",
    "    \"\"\"\n",
    "    Construit une requête SPARQL pour trouver toutes les pages reliées à search_term via une liste de propriétés.\n",
    "    :param search_term: ID Wikidata (ex: Q42)\n",
    "    :param property_ids: liste de propriétés (ex: ['P50', 'P170'])\n",
    "    :return: requête SPARQL (str)\n",
    "    \"\"\"\n",
    "    # Prépare la liste VALUES pour les propriétés\n",
    "    # Inclure toutes les propriétés qui contiennent \":\" (ex: wdt:, owl:, rdf:, etc.)\n",
    "    values_block = \" \".join(\n",
    "      (\n",
    "        f\"wdt:{pid}\" if pid.startswith(\"P\") else pid\n",
    "      )\n",
    "      for pid in property_ids\n",
    "      if (\":\" in pid) or pid.startswith(\"P\")\n",
    "    ).strip()\n",
    "    # Nettoyer les espaces multiples éventuels\n",
    "    values_block = \" \".join(values_block.split())\n",
    "    print(values_block)\n",
    "\n",
    "    query = f\"\"\"    SELECT \n",
    "  ?item \n",
    "  ?itemLabel \n",
    "  (GROUP_CONCAT(DISTINCT ?propLabel; separator=\", \") AS ?props)\n",
    "  (COALESCE(?itemDescription_fr, ?itemDescription_en) AS ?itemDescription) # renvoie la première description valide trouvée.\n",
    "  ?parent1\n",
    "  (COALESCE(?parent1Label_fr, ?parent1Label_en) AS ?parent1Label)\n",
    "  ?parent2\n",
    "  (COALESCE(?parent2Label_fr, ?parent2Label_en) AS ?parent2Label)\n",
    "WHERE {{\n",
    "  VALUES ?prop {{ \n",
    "    {values_block}\n",
    "  }}\n",
    "  ?item ?prop  wd:{search_term} .\n",
    "  OPTIONAL {{\n",
    "  ?wd wikibase:directClaim ?prop .\n",
    "  ?wd rdfs:label ?propLabel .\n",
    "  FILTER(LANG(?propLabel) = \"fr\")\n",
    "  }}\n",
    "\n",
    "  # Description fr/en selon disponibilité\n",
    "  OPTIONAL {{ ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }}\n",
    "  OPTIONAL {{ ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }}\n",
    "\n",
    "  # parent1Label fr/en selon disponibilité\n",
    "  OPTIONAL {{\n",
    "    ?item wdt:P31 ?parent1 .\n",
    "    OPTIONAL {{ ?parent1 rdfs:label ?parent1Label_fr . FILTER(LANG(?parent1Label_fr) = \"fr\") }}\n",
    "    OPTIONAL {{ ?parent1 rdfs:label ?parent1Label_en . FILTER(LANG(?parent1Label_en) = \"en\") }}\n",
    "\n",
    "    # parent2Label fr/en selon disponibilité\n",
    "    OPTIONAL {{\n",
    "      ?item wdt:P279|wdt: ?parent2 .\n",
    "      OPTIONAL {{ ?parent2 rdfs:label ?parent2Label_fr . FILTER(LANG(?parent2Label_fr) = \"fr\") }}\n",
    "      OPTIONAL {{ ?parent2 rdfs:label ?parent2Label_en . FILTER(LANG(?parent2Label_en) = \"en\") }}\n",
    "    }}\n",
    "  }}\n",
    "\n",
    "  SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"fr,en\". }}\n",
    "}}\n",
    "GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?parent1Label_fr ?parent1Label_en ?parent2Label_fr ?parent2Label_en ?parent1 ?parent2\n",
    "\"\"\"\n",
    "    return query\n",
    "\n",
    "# Exemple d'utilisation :\n",
    "search_term = ask_query_term()  # à remplacer par votre variable ou input utilisateur\n",
    "query = build_related_pages_query(search_term, all_property_ids)\n",
    "\n",
    "# Exécuter la requête pour obtenir les pages liées\n",
    "related_pages_results = execute_sparql_query(query, use_pagination=False)\n",
    "\n",
    "# Sauvegarder les résultats dans un fichier JSON\n",
    "related_pages_json_filename = f\"{datetime.now().strftime('%Y%m%d_%H%M%S')}_related_pages_{search_term}.json\"\n",
    "related_pages_json_filepath = os.path.join(output_dir, related_pages_json_filename)\n",
    "with open(related_pages_json_filepath, 'w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(related_pages_results, jsonfile, ensure_ascii=False, indent=2)\n",
    "print(f\"✅ Résultats des pages liées sauvegardés dans {related_pages_json_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c2c66f",
   "metadata": {},
   "source": [
    "### REQUÊTES THEMATIQUES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295aa2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_aeronautics_extraction_queries():\n",
    "    \"\"\"Construit les requêtes d'extraction des données\"\"\"\n",
    "    queries = {\n",
    "        \"manufacturers\": \"\"\"\n",
    "        SELECT DISTINCT ?item \n",
    "              \n",
    "                ?itemLabel\n",
    "               (COALESCE(?itemDescription_fr, ?itemDescription_en, ?itemDescription_any, \"\") AS ?itemDescription)\n",
    "               ?parent\n",
    "               ?parentLabel\n",
    "               (GROUP_CONCAT(DISTINCT ?synonym_fr; separator=\",\") AS ?synonyms_fr)\n",
    "        WHERE {\n",
    "          # Tous les constructeurs d'aviation (instances ou sous-classes ou parties)\n",
    "          ?item wdt:P31*/wdt:P279*/wdt:P361*/wdt:P452*/wdt:P749* wd:Q936518 .\n",
    "        \n",
    "          # On cherche le parent immédiat selon différentes relations\n",
    "            OPTIONAL { ?item wdt:P361 ?partOf . }\n",
    "            OPTIONAL { ?item wdt:P279 ?subclassOf . }\n",
    "            OPTIONAL { ?item wdt:P31 ?instanceOf . }\n",
    "            OPTIONAL { ?item wdt:P452 ?secteur .}\n",
    "            OPTIONAL { ?item wdt:P176 ?constructeur.}\n",
    "            OPTIONAL { ?item wdt:P749 ?constructeur.}\n",
    "            \n",
    "            BIND(COALESCE(?partOf, ?subclassOf, ?instanceOf, ?secteur, ?constructeur) AS ?parent)\n",
    "        \n",
    "          # Description de l'item (fr > en > autre)\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_any .\n",
    "                     FILTER(LANG(?itemDescription_any) != \"fr\" && LANG(?itemDescription_any) != \"en\") }\n",
    "\n",
    "          # Synonymes en français (P1709 est \"synonymes exacts\")\n",
    "          OPTIONAL { ?item skos:altLabel ?synonym_fr . FILTER(LANG(?synonym_fr) = \"fr\") }\n",
    "        \n",
    "          SERVICE wikibase:label {\n",
    "            bd:serviceParam wikibase:language \"fr,en,[AUTO_LANGUAGE]\"\n",
    "          }\n",
    "        }\n",
    "        GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?itemDescription_any ?parent ?parentLabel\n",
    "        \"\"\",\n",
    "\n",
    "        \"aircraft_models\": \"\"\"\n",
    "        SELECT DISTINCT ?item \n",
    "               ?itemLabel\n",
    "               (COALESCE(?itemDescription_fr, ?itemDescription_en, ?itemDescription_any, \"\") AS ?itemDescription)\n",
    "               ?parent\n",
    "               ?parentLabel\n",
    "               (GROUP_CONCAT(DISTINCT ?synonym_fr; separator=\" , \") AS ?synonyms_fr)\n",
    "        WHERE {\n",
    "          # Tous les modèles d'avions (instances ou sous-classes ou parties)\n",
    "          ?item wdt:P31/wdt:P279* wd:Q11436 .\n",
    "          \n",
    "        \n",
    "          # On cherche le parent immédiat selon différentes relations         \n",
    "            OPTIONAL { ?item wdt:P179 ?series .}\n",
    "            OPTIONAL { ?item wdt:176 ?constructeur.}\n",
    "            OPTIONAL { ?item wdt:P31 ?instanceOf . } \n",
    "            OPTIONAL { ?item wdt:P361 ?partOf . }\n",
    "            OPTIONAL { ?item wdt:P279 ?subclassOf . }\n",
    "                       \n",
    "            BIND(COALESCE(?partOf, ?subclassOf, ?instanceOf, ?series, ?constructeur) AS ?parent)\n",
    "        \n",
    "          # Description de l'item (fr > en > autre)\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_any .\n",
    "                     FILTER(LANG(?itemDescription_any) != \"fr\" && LANG(?itemDescription_any) != \"en\") }\n",
    "\n",
    "          # Synonymes en français\n",
    "          OPTIONAL { ?item skos:altLabel ?synonym_fr . FILTER(LANG(?synonym_fr) = \"fr\") }\n",
    "        \n",
    "          SERVICE wikibase:label {\n",
    "            bd:serviceParam wikibase:language \"fr,en,[AUTO_LANGUAGE]\"\n",
    "          }\n",
    "        }\n",
    "        GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?itemDescription_any ?parent ?parentLabel\n",
    "        \"\"\",\n",
    "\n",
    "        \"aircraft_components\": \"\"\"\n",
    "        SELECT DISTINCT ?item \n",
    "               ?itemLabel\n",
    "               (COALESCE(?itemDescription_fr, ?itemDescription_en, ?itemDescription_any, \"\") AS ?itemDescription)\n",
    "               ?parent\n",
    "               ?parentLabel\n",
    "               (GROUP_CONCAT(DISTINCT ?synonym_fr; separator=\" , \") AS ?synonyms_fr)\n",
    "        WHERE {\n",
    "          # Tous les équipements d'aviation (instances ou sous-classes ou parties)\n",
    "          ?item wdt:P31*/wdt:P279*/wdt:P361* wd:Q16693356 .\n",
    "        \n",
    "          # On cherche le parent immédiat selon différentes relations\n",
    "            OPTIONAL { ?item wdt:P361 ?partOf . }\n",
    "            OPTIONAL { ?item wdt:P279 ?subclassOf . }\n",
    "            OPTIONAL { ?item wdt:P31 ?instanceOf . }\n",
    "            OPTIONAL { ?item wdt:P452 ?secteur .}\n",
    "            OPTIONAL { ?item wdt:P176 ?constructeur.}\n",
    "            \n",
    "            BIND(COALESCE(?partOf, ?subclassOf, ?instanceOf, ?secteur, ?constructeur) AS ?parent)\n",
    "        \n",
    "          # Description de l'item (fr > en > autre)\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_any .\n",
    "                     FILTER(LANG(?itemDescription_any) != \"fr\" && LANG(?itemDescription_any) != \"en\") }\n",
    "\n",
    "          # Synonymes en français\n",
    "          OPTIONAL { ?item skos:altLabel ?synonym_fr . FILTER(LANG(?synonym_fr) = \"fr\") }\n",
    "        \n",
    "          SERVICE wikibase:label {\n",
    "            bd:serviceParam wikibase:language \"fr,en,[AUTO_LANGUAGE]\"\n",
    "          }\n",
    "        }\n",
    "        GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?itemDescription_any ?parent ?parentLabel\n",
    "        \"\"\",\n",
    "\n",
    "        \"aeronautic_profession\": \"\"\"\n",
    "        SELECT DISTINCT ?item \n",
    "               ?itemLabel\n",
    "               (COALESCE(?itemDescription_fr, ?itemDescription_en, ?itemDescription_any, \"\") AS ?itemDescription)\n",
    "               ?parent\n",
    "               ?parentLabel\n",
    "               (GROUP_CONCAT(DISTINCT ?synonym_fr; separator=\" , \") AS ?synonyms_fr)\n",
    "        WHERE {\n",
    "        ?item wdt:P425* ?domaine.\n",
    "        VALUES ?domaine { wd:Q765633 wd:Q906438 wd:Q1434048 wd:Q206814 wd:Q627716 wd:Q221395 wd:Q765633 wd:Q22719}.  \n",
    "        \n",
    "          # On cherche le parent immédiat selon différentes relations\n",
    "            OPTIONAL { ?item wdt:P361 ?partOf . }\n",
    "            OPTIONAL { ?item wdt:P279 ?subclassOf . }\n",
    "            OPTIONAL { ?item wdt:P31 ?instanceOf . }\n",
    "            OPTIONAL { ?item wdt:P452 ?secteur .}\n",
    "            OPTIONAL { ?item wdt:P176 ?constructeur.}\n",
    "            OPTIONAL { ?item wdt:P749 ?constructeur.}\n",
    "            \n",
    "            BIND(COALESCE(?partOf, ?subclassOf, ?instanceOf, ?secteur, ?constructeur, ?domaine) AS ?parent) # Attention à coalesce pour éviter les doublons\n",
    "        \n",
    "          # Description de l'item (fr > en > autre)\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_any .\n",
    "                     FILTER(LANG(?itemDescription_any) != \"fr\" && LANG(?itemDescription_any) != \"en\") }\n",
    "\n",
    "          # Synonymes en français\n",
    "          OPTIONAL { ?item skos:altLabel ?synonym_fr . FILTER(LANG(?synonym_fr) = \"fr\") }\n",
    "        \n",
    "          SERVICE wikibase:label {\n",
    "            bd:serviceParam wikibase:language \"fr,en,[AUTO_LANGUAGE]\"\n",
    "          }\n",
    "        }\n",
    "        GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?itemDescription_any ?parent ?parentLabel\n",
    "        \"\"\"\n",
    "    }\n",
    "    return queries\n",
    "\n",
    "print(\"✅ Requêtes définies (avec synonymes français)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea367aee",
   "metadata": {},
   "source": [
    "## 🔎 Lancer la recherche globale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b6ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🛠️ EXTRACTION DES DONNÉES AÉRONAUTIQUES\n",
    "def extract_all_aeronautics_data():\n",
    "    \"\"\"Extrait toutes les données aéronautiques de manière optimisée\"\"\"\n",
    "    print(\"🏗️ EXTRACTION HIÉRARCHIQUE EXHAUSTIVE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    queries = build_aeronautics_extraction_queries()\n",
    "    all_results = []\n",
    "    \n",
    "    for category, query in queries.items():\n",
    "        print(f\"\\n🔍 Extraction: {category}\")\n",
    "        \n",
    "        # ✅ CORRECTION: Utiliser execute_paginated_query au lieu de execute_batch_queries\n",
    "        results = execute_batch_queries(query)\n",
    "        \n",
    "        # Enrichir chaque résultat avec sa catégorie\n",
    "        for result in results:\n",
    "            result[\"source_category\"] = category\n",
    "        \n",
    "        all_results.extend(results)\n",
    "        print(f\"✅ {len(results)} entités trouvées pour {category}\")\n",
    "    \n",
    "    print(f\"\\n🎯 TOTAL: {len(all_results)} entités extraites\")\n",
    "    return all_results\n",
    "\n",
    "raw_aeronautics_data = extract_all_aeronautics_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dffabe",
   "metadata": {},
   "source": [
    "### Aperçu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bbfb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_aeronautics_data[:5])  # pour afficher un aperçu\n",
    "\n",
    "json_filename = f\"raw.json\"\n",
    "json_filepath = os.path.join(output_dir, json_filename)\n",
    "\n",
    "with open(json_filepath, 'w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(raw_aeronautics_data, jsonfile, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5639628",
   "metadata": {},
   "source": [
    "## 📁 Export\n",
    "\n",
    "### Construction du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da268123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏗️ CONSTRUCTION DE LA HIÉRARCHIE FINALE\n",
      "=============================================\n",
      "✅ Hiérarchie construite: 233 entrées totales\n",
      "🎯 Thésaurus final: 233 entrées\n"
     ]
    }
   ],
   "source": [
    "# 🏗️ CONSTRUCTION DE LA HIÉRARCHIE FINALE\n",
    "\n",
    "# def get_id_from_uri(uri):\n",
    "#     # Ex: \"http://www.wikidata.org/entity/Q105557\" → \"Q105557\"\n",
    "#     return uri.split(\"/\")[-1] if uri else \"\"\n",
    "\n",
    "def build_final_hierarchy(related_pages_results):\n",
    "    \"\"\"Construit la hiérarchie finale avec parents immédiats et catégories\"\"\"\n",
    "    print(\"🏗️ CONSTRUCTION DE LA HIÉRARCHIE FINALE\")\n",
    "    print(\"=\"*45)\n",
    "    \n",
    "    # Créer la hiérarchie structurée\n",
    "    hierarchy = []\n",
    "    for entry in related_pages_results:\n",
    "    \n",
    "        hierarchy.append(\n",
    "            {\n",
    "            \"ID\": clean_entity_id(entry.get(\"item\", {}).get(\"value\", \"\")),\n",
    "            \"Terme\": entry.get(\"itemLabel\", {}).get(\"value\", \"\"),\n",
    "            \"ID_TG\": clean_entity_id(entry.get(\"parent\", {}).get(\"value\", \"\")),\n",
    "            \"TG\": entry.get(\"parentLabel\", {}).get(\"value\", \"\"),\n",
    "            \"Def\": entry.get(\"itemDescription\", {}).get(\"value\", \"\"),\n",
    "            \"EP\": entry.get(\"synonyms_fr\", {}).get(\"value\", \"\"),\n",
    "            \"TA\": entry.get(\"source_category\", {})\n",
    "        }\n",
    "        )\n",
    "    \n",
    " \n",
    "    print(f\"✅ Hiérarchie construite: {len(hierarchy)} entrées totales\")\n",
    "    return hierarchy\n",
    "\n",
    "final_thesaurus = build_final_hierarchy(related_pages_results)\n",
    "print(f\"🎯 Thésaurus final: {len(final_thesaurus)} entrées\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdc1047",
   "metadata": {},
   "source": [
    "### Export du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcc3e345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 EXPORT FINAL UNIQUE\n",
      "=========================\n",
      "📄 Export CSV: ./output\\thesaurus_aeronautique_FINAL_20250708_100339.csv\n",
      "📄 Export JSON: ./output\\thesaurus_aeronautique_FINAL_20250708_100339.json\n",
      "\n",
      "🎯 RÉSUMÉ FINAL DU THÉSAURUS AÉRONAUTIQUE\n",
      "==================================================\n",
      "📊 STATISTIQUES GÉNÉRALES:\n",
      "   • Total d'entrées: 233\n",
      "   • Entrées avec synonymes: 0\n",
      "   • Entrées avec descriptions: 0\n",
      "\n",
      "📂 RÉPARTITION PAR CATÉGORIE:\n",
      "   • unknown: 233 (100.0%)\n",
      "\n",
      "🔗 TYPES DE RELATIONS:\n",
      "   • unknown: 233\n",
      "\n",
      "🌐 LANGUES:\n",
      "   • unknown: 233\n",
      "\n",
      "📁 FICHIERS GÉNÉRÉS:\n",
      "   ✅ CSV: thesaurus_aeronautique_FINAL_20250708_100339.csv\n",
      "   ✅ JSON: thesaurus_aeronautique_FINAL_20250708_100339.json\n",
      "\n",
      "🏆 MISSION ACCOMPLIE !\n",
      " 233 entrées de thésaurus\n"
     ]
    }
   ],
   "source": [
    "# 💾 EXPORT FINAL UNIQUE - CSV Occidental European Format (semicolon separated)\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def export_final_thesaurus(thesaurus_data):\n",
    "    \"\"\"Exporte le thésaurus final en CSV (point-virgule, format européen) et JSON\"\"\"\n",
    "    print(\"💾 EXPORT FINAL UNIQUE\")\n",
    "    print(\"=\"*25)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 1. Export CSV - Occidental European (semicolon separator, utf-8-sig BOM)\n",
    "    csv_filename = f\"thesaurus_aeronautique_FINAL_{timestamp}.csv\"\n",
    "    csv_filepath = os.path.join(output_dir, csv_filename)\n",
    "    \n",
    "    fieldnames = [\n",
    "        'ID', 'Terme', 'ID_TG','TG', 'Def', 'EP',\n",
    "        'TA'\n",
    "    ]\n",
    "    \n",
    "    print(f\"📄 Export CSV: {csv_filepath}\")\n",
    "    with open(csv_filepath, 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
    "        writer = csv.DictWriter(\n",
    "            csvfile, \n",
    "            fieldnames=fieldnames,\n",
    "            delimiter=';',         # Use semicolon as separator\n",
    "            quoting=csv.QUOTE_MINIMAL\n",
    "        )\n",
    "        writer.writeheader()\n",
    "        for entry in sorted(thesaurus_data, key=lambda x: x[\"ID\"]):\n",
    "            # Ensure all values are strings and convert None to empty string\n",
    "            row = {k: ('' if v is None else str(v)) for k, v in entry.items()}\n",
    "            # Guarantee all required fields exist in row\n",
    "            for field in fieldnames:\n",
    "                row.setdefault(field, '')\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    # 2. Export JSON avec métadonnées\n",
    "    json_filename = f\"thesaurus_aeronautique_FINAL_{timestamp}.json\"\n",
    "    json_filepath = os.path.join(output_dir, json_filename)\n",
    "    \n",
    "    stats = analyze_thesaurus_statistics(thesaurus_data)\n",
    "    \n",
    "    json_data = {\n",
    "        \"metadata\": {\n",
    "            \"title\": \"Thésaurus Aéronautique Final - Wikidata\",\n",
    "            \"description\": \"Thésaurus exhaustif avec hiérarchie et parents immédiats\",\n",
    "            \"version\": \"1.0-FINAL\",\n",
    "            \"created\": timestamp,\n",
    "            \"source\": \"Wikidata SPARQL optimisé\",\n",
    "            \"total_entries\": len(thesaurus_data),\n",
    "            \"extraction_method\": \"multi-query_hierarchical\",\n",
    "            \"parent_detection\": \"automatic_wikidata_relations\",\n",
    "            \"multilingual_support\": True,\n",
    "            \"format\": \"structured_hierarchical_thesaurus\"\n",
    "        },\n",
    "        \"statistics\": stats,\n",
    "        \"data\": thesaurus_data\n",
    "    }\n",
    "    \n",
    "    print(f\"📄 Export JSON: {json_filepath}\")\n",
    "    with open(json_filepath, 'w', encoding='utf-8') as jsonfile:\n",
    "        json.dump(json_data, jsonfile, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    return csv_filepath, json_filepath, stats\n",
    "\n",
    "def analyze_thesaurus_statistics(thesaurus_data):\n",
    "    \"\"\"Analyse les statistiques du thésaurus final\"\"\"\n",
    "    stats = {\n",
    "        \"total_entries\": len(thesaurus_data),\n",
    "        \"categories\": {},\n",
    "        \"relation_types\": {},\n",
    "        \"languages\": {},\n",
    "        \"hierarchy_depth\": 0,\n",
    "        \"entries_with_synonyms\": 0,\n",
    "        \"entries_with_descriptions\": 0\n",
    "    }\n",
    "    \n",
    "    for entry in thesaurus_data:\n",
    "        # Catégories\n",
    "        category = entry.get(\"category\", \"unknown\")\n",
    "        stats[\"categories\"][category] = stats[\"categories\"].get(category, 0) + 1\n",
    "        \n",
    "        # Types de relation\n",
    "        rel_type = entry.get(\"relation_type\", \"unknown\")\n",
    "        stats[\"relation_types\"][rel_type] = stats[\"relation_types\"].get(rel_type, 0) + 1\n",
    "        \n",
    "        # Langues\n",
    "        lang = entry.get(\"lang\", \"unknown\")\n",
    "        stats[\"languages\"][lang] = stats[\"languages\"].get(lang, 0) + 1\n",
    "        \n",
    "        # Enrichissements\n",
    "        if entry.get(\"synonyms\"):\n",
    "            stats[\"entries_with_synonyms\"] += 1\n",
    "        if entry.get(\"description\"):\n",
    "            stats[\"entries_with_descriptions\"] += 1\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def display_final_summary(stats, csv_file, json_file):\n",
    "    \"\"\"Affiche un résumé final du thésaurus généré\"\"\"\n",
    "    print(\"\\n🎯 RÉSUMÉ FINAL DU THÉSAURUS AÉRONAUTIQUE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"📊 STATISTIQUES GÉNÉRALES:\")\n",
    "    print(f\"   • Total d'entrées: {stats['total_entries']}\")\n",
    "    print(f\"   • Entrées avec synonymes: {stats['entries_with_synonyms']}\")\n",
    "    print(f\"   • Entrées avec descriptions: {stats['entries_with_descriptions']}\")\n",
    "    \n",
    "    print(f\"\\n📂 RÉPARTITION PAR CATÉGORIE:\")\n",
    "    for category, count in sorted(stats[\"categories\"].items(), key=lambda x: x[1], reverse=True):\n",
    "        percentage = (count / stats['total_entries']) * 100\n",
    "        print(f\"   • {category}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n🔗 TYPES DE RELATIONS:\")\n",
    "    for rel_type, count in sorted(stats[\"relation_types\"].items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"   • {rel_type}: {count}\")\n",
    "    \n",
    "    print(f\"\\n🌐 LANGUES:\")\n",
    "    for lang, count in stats[\"languages\"].items():\n",
    "        print(f\"   • {lang}: {count}\")\n",
    "    \n",
    "    print(f\"\\n📁 FICHIERS GÉNÉRÉS:\")\n",
    "    print(f\"   ✅ CSV: {os.path.basename(csv_file)}\")\n",
    "    print(f\"   ✅ JSON: {os.path.basename(json_file)}\")\n",
    "    \n",
    "    print(f\"\\n🏆 MISSION ACCOMPLIE !\")\n",
    "    print(f\" {stats['total_entries']} entrées de thésaurus\")\n",
    "\n",
    "\n",
    "# Export et résumé final\n",
    "if final_thesaurus:\n",
    "    csv_file, json_file, statistics = export_final_thesaurus(final_thesaurus)\n",
    "    display_final_summary(statistics, csv_file, json_file)\n",
    "else:\n",
    "    print(\"❌ Aucun thésaurus à exporter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d148f58",
   "metadata": {},
   "source": [
    "### Nettoyage des doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27f6dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire le CSV (remplace 'ton_fichier.csv' par le tien)\n",
    "df = pd.read_csv(csv_file, sep=';', dtype=str).fillna('')\n",
    "\n",
    "# Fonction pour concaténer les valeurs uniques (séparées par \"|\")\n",
    "def concat_unique(series):\n",
    "    uniques = set([v.strip() for v in series if v.strip() != ''])\n",
    "    return \" | \".join(sorted(uniques)) if uniques else ''\n",
    "\n",
    "# Grouper par 'ID', en concaténant les valeurs différentes pour chaque colonne\n",
    "df_clean = df.groupby('ID', as_index=False).agg(concat_unique)\n",
    "\n",
    "# Sauvegarder le résultat\n",
    "df_clean.to_csv(csv_file, sep=';', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"✅ CSV nettoyé et exporté sous {csv_file}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
