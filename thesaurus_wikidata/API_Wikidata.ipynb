{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "339b9f1f",
   "metadata": {},
   "source": [
    "# üöÄ Requ√™te WIKIDATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f576147d",
   "metadata": {},
   "source": [
    "## üî® Construction de l'environnement n√©cessaire et configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74111c85",
   "metadata": {},
   "source": [
    "### Installation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaf8794",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install SPARQLWrapper tqdm pandas\n",
    "\n",
    "print(\"‚¨áÔ∏è Installation termin√©e !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e7bad",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "#### Param√®tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e86a25c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ CONFIGURATION TERMIN√âE\n",
      "üìÅ Dossier de sortie: ./output\n",
      "‚è±Ô∏è  Rate limit: 3.0s entre requ√™tes\n",
      "üì¶ Taille des batches: 10\n",
      "üîÑ Nombre maximal de tentatives: 3\n",
      "‚è≥ D√©lai de timeout des requ√™tes: 60s\n",
      "üîç Taille du batch d'enrichissement: 15\n",
      "üîÅ Limite de boucle: 100 it√©rations\n"
     ]
    }
   ],
   "source": [
    "# üîß CONFIGURATION ET IMPORTS\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "WIKIDATA_ENDPOINT = \"https://query.wikidata.org/sparql\"\n",
    "RATE_LIMIT_DELAY = 3.0 \n",
    "BATCH_SIZE = 10  \n",
    "MAX_RETRIES = 3  \n",
    "REQUEST_TIMEOUT = 60\n",
    "ENRICHMENT_BATCH_SIZE = 15\n",
    "LOOP_LIMIT = 100\n",
    "LOOP_OFFSET = 0\n",
    "\n",
    "# Dossier de sortie\n",
    "output_dir = \"./output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"üöÄ CONFIGURATION TERMIN√âE\")\n",
    "print(f\"üìÅ Dossier de sortie: {output_dir}\")\n",
    "print(f\"‚è±Ô∏è  Rate limit: {RATE_LIMIT_DELAY}s entre requ√™tes\")\n",
    "print(f\"üì¶ Taille des batches: {BATCH_SIZE}\")\n",
    "print(f\"üîÑ Nombre maximal de tentatives: {MAX_RETRIES}\")\n",
    "print(f\"‚è≥ D√©lai de timeout des requ√™tes: {REQUEST_TIMEOUT}s\")\n",
    "print(f\"üîç Taille du batch d'enrichissement: {ENRICHMENT_BATCH_SIZE}\")\n",
    "print(f\"üîÅ Limite de boucle: {LOOP_LIMIT} it√©rations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27ffccf",
   "metadata": {},
   "source": [
    "#### Client sparql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519640a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonctions de requ√™te SPARQL pr√™tes !\n"
     ]
    }
   ],
   "source": [
    "def create_sparql_client():\n",
    "    \"\"\"\n",
    "    Cr√©er un client SPARQL pour interagir avec Wikidata\n",
    "    :return: Instance de SPARQLWrapper configur√©e pour Wikidata\n",
    "    \"\"\"\n",
    "    sparql = SPARQLWrapper(WIKIDATA_ENDPOINT)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    sparql.setTimeout(REQUEST_TIMEOUT)\n",
    "    return sparql\n",
    "\n",
    "def execute_sparql_query(query, max_retries=MAX_RETRIES, use_pagination=False, limit=None, max_results=None):\n",
    "    \"\"\"\n",
    "    Ex√©cute une requ√™te SPARQL avec gestion des erreurs, rate limiting et pagination optionnelle\n",
    "    :param query: La requ√™te SPARQL √† ex√©cuter\n",
    "    :param max_retries: Nombre maximum de tentatives en cas d'√©chec\n",
    "    :param use_pagination: Si True, active la pagination automatique\n",
    "    :param limit: Taille des pages pour la pagination (d√©faut: LOOP_LIMIT)\n",
    "    :param max_results: Nombre maximum de r√©sultats √† r√©cup√©rer (None = illimit√©)\n",
    "    :return: R√©sultats de la requ√™te ou une liste vide en cas d'√©chec\n",
    "    \"\"\"\n",
    "    sparql = create_sparql_client()\n",
    "    \n",
    "    # Mode simple sans pagination\n",
    "    if not use_pagination:\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                sparql.setQuery(query)\n",
    "                results = sparql.query().convert()\n",
    "                time.sleep(RATE_LIMIT_DELAY)\n",
    "                return results[\"results\"][\"bindings\"]\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Tentative {attempt + 1}/{max_retries} √©chou√©e: {e}...\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(RATE_LIMIT_DELAY * (attempt + 2))\n",
    "                else:\n",
    "                    print(f\"‚ùå Requ√™te √©chou√©e apr√®s {max_retries} tentatives\")\n",
    "                    return []\n",
    "        return []\n",
    "    \n",
    "    # Mode pagination\n",
    "    if limit is None:\n",
    "        limit = LOOP_LIMIT\n",
    "    \n",
    "    all_results = []\n",
    "    offset = 0\n",
    "    \n",
    "    print(f\"üîç D√©but de la pagination (limit={limit})...\")\n",
    "    \n",
    "    while True:\n",
    "        # Ajouter LIMIT et OFFSET √† la requ√™te\n",
    "        paginated_query = f\"{query.rstrip()} LIMIT {limit} OFFSET {offset}\"\n",
    "        \n",
    "        print(f\"üîπ Requ√™te OFFSET {offset}, LIMIT {limit}\")\n",
    "        \n",
    "        success = False\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                sparql.setQuery(paginated_query)\n",
    "                results = sparql.query().convert()\n",
    "                bindings = results[\"results\"][\"bindings\"]\n",
    "                \n",
    "                if not bindings:\n",
    "                    print(\"‚úÖ Fin de la pagination - Aucun r√©sultat suppl√©mentaire.\")\n",
    "                    success = True\n",
    "                    break\n",
    "                \n",
    "                all_results.extend(bindings)\n",
    "                print(f\"‚úÖ R√©cup√©r√© {len(bindings)} r√©sultats (total: {len(all_results)})\")\n",
    "                \n",
    "                # V√©rifier la limite max_results\n",
    "                if max_results and len(all_results) >= max_results:\n",
    "                    print(f\"üéØ Limite de {max_results} r√©sultats atteinte.\")\n",
    "                    all_results = all_results[:max_results]  # Tronquer si n√©cessaire\n",
    "                    success = True\n",
    "                    break\n",
    "                \n",
    "                success = True\n",
    "                break\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Tentative {attempt + 1}/{max_retries} √©chou√©e √† l'offset {offset}: {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(RATE_LIMIT_DELAY * (attempt + 2))\n",
    "                else:\n",
    "                    print(f\"‚ùå Requ√™te √©chou√©e apr√®s {max_retries} tentatives √† l'offset {offset}\")\n",
    "                    return all_results  # Retourner ce qu'on a r√©ussi √† r√©cup√©rer\n",
    "        \n",
    "        if not success or (max_results and len(all_results) >= max_results):\n",
    "            break\n",
    "        \n",
    "        # Incr√©menter l'offset pour la prochaine page\n",
    "        offset += limit\n",
    "        \n",
    "        # Rate limiting crucial\n",
    "        print(f\"‚è≥ Attente de {RATE_LIMIT_DELAY}s...\")\n",
    "        time.sleep(RATE_LIMIT_DELAY)\n",
    "    \n",
    "    print(f\"üéØ Total final r√©cup√©r√© : {len(all_results)} r√©sultats.\")\n",
    "    return all_results\n",
    "\n",
    "def clean_entity_id(entity_uri):\n",
    "    \"\"\"\n",
    "    Extrait l'ID d'une entit√© √† partir de son URI\n",
    "    :param entity_uri: URI de l'entit√© (ex: \"http://www.wikidata.org/entity/Q42'\")\n",
    "    :return: ID de l'entit√© (ex: \"Q42\") ou une cha√Æne vide si l'URI est vide\n",
    "    \"\"\"\n",
    "    if not entity_uri:\n",
    "        return \"\"\n",
    "    return entity_uri.split(\"/\")[-1] if \"/\" in entity_uri else entity_uri\n",
    "\n",
    "def execute_batch_queries(queries, description=\"Requ√™tes\", use_pagination=False):\n",
    "    \"\"\"\n",
    "    Ex√©cute une liste de requ√™tes SPARQL en batch\n",
    "    :param queries: Requ√™te SPARQL unique ou liste de requ√™tes\n",
    "    :param description: Description de la t√¢che pour le logging\n",
    "    :param use_pagination: Si True, active la pagination pour chaque requ√™te\n",
    "    :return: Liste de tous les r√©sultats combin√©s\n",
    "    \"\"\"\n",
    "    # ‚úÖ CORRECTION: V√©rifier si queries est une string ou une liste\n",
    "    if isinstance(queries, str):\n",
    "        # Si c'est une string, c'est une seule requ√™te\n",
    "        print(f\"üîπ Ex√©cution d'une requ√™te unique: {description}\")\n",
    "        return execute_sparql_query(queries, use_pagination=use_pagination)\n",
    "    \n",
    "    # Si c'est une liste, traiter comme batch\n",
    "    all_results = []\n",
    "    for i, query in enumerate(tqdm(queries, desc=description)):\n",
    "        results = execute_sparql_query(query, use_pagination=use_pagination)\n",
    "        all_results.extend(results)\n",
    "        if (i + 1) % BATCH_SIZE == 0:\n",
    "            time.sleep(RATE_LIMIT_DELAY)\n",
    "    return all_results\n",
    "\n",
    "def execute_paginated_query(base_query, limit=None, max_results=None):\n",
    "    \"\"\"\n",
    "    Fonction helper pour ex√©cuter facilement une requ√™te avec pagination\n",
    "    :param base_query: Requ√™te SPARQL de base (sans LIMIT/OFFSET)\n",
    "    :param limit: Taille des pages (d√©faut: LOOP_LIMIT)\n",
    "    :param max_results: Nombre maximum de r√©sultats (None = illimit√©)\n",
    "    :return: Liste de tous les r√©sultats\n",
    "    \"\"\"\n",
    "    return execute_sparql_query(\n",
    "        base_query, \n",
    "        use_pagination=True, \n",
    "        limit=limit, \n",
    "        max_results=max_results\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Fonctions de requ√™te SPARQL pr√™tes !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d392e0",
   "metadata": {},
   "source": [
    "## üöß Construction de la requ√™te\n",
    "\n",
    "\n",
    "### Rechercher une entit√© par nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c027626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ IDENTIFICATION DE L'ENTIT√â\n",
    "\n",
    "def find_aeronautics_entity():\n",
    "    \"\"\"\n",
    "    Demande √† l'utilisateur le nom de l'entit√© √† rechercher dans Wikidata\n",
    "    :return: Tuple contenant l'ID et le label de l'entit√©\n",
    "    \"\"\"\n",
    "    entity_name = input(\"Entrez le nom de l'entit√© √† rechercher dans wikidata, en anglais (ex: aeronautics) : \").strip()\n",
    "    if not entity_name:\n",
    "        print(\"‚ùå Aucun nom d'entit√© fourni.\")\n",
    "        return None, None  # ‚úÖ Coh√©rent avec l'assignation\n",
    "\n",
    "    # Choix de la requ√™te √† utiliser\n",
    "    query_choice = input(\n",
    "        \"Quel type de requ√™te utiliser ?\\n\"\n",
    "        \"1Ô∏è‚É£ Recherche d'une cha√Æne dans les labels\\n\"\n",
    "        \"2Ô∏è‚É£ Requ√™te d'une cha√Æne dans les parents\\n\"\n",
    "        \"Entrez le num√©ro de votre choix (1 ou 2) : \"\n",
    "    ).strip()\n",
    "\n",
    "    if query_choice == \"1\":\n",
    "        query_regex = f\"\"\"\n",
    "        SELECT ?item ?itemLabel\n",
    "        WHERE {{\n",
    "            ?item rdfs:label ?itemLabel.\n",
    "            FILTER(LANG(?itemLabel) = \"en\").\n",
    "            FILTER(CONTAINS(LCASE(?itemLabel), \"{entity_name}\")).\n",
    "        }}\n",
    "        \"\"\"\n",
    "    elif query_choice == \"2\":\n",
    "        query_regex = f\"\"\"\n",
    "        SELECT ?item ?itemLabel\n",
    "        WHERE {{\n",
    "            ?item wdt:P31*/wdt:P279* ?parent.\n",
    "            ?parent rdfs:label ?parentLabel.\n",
    "            FILTER(LANG(?parentLabel) = \"en\").\n",
    "            FILTER(CONTAINS(LCASE(?parentLabel), \"{entity_name}\")).\n",
    "            SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "    else:\n",
    "        print(\"‚ùå Choix invalide. Veuillez entrer 1 ou 2.\")\n",
    "        return None, None  # ‚úÖ Coh√©rent avec l'assignation\n",
    "\n",
    "    print(f\"üîç Recherche de l'entit√© principale '{entity_name}'...\")\n",
    "    results = execute_paginated_query(query_regex)  # Limite pour voir plusieurs r√©sultats\n",
    "\n",
    "    if results:\n",
    "        print(f\"\\nüìã {len(results)} entit√©s trouv√©es:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Afficher les premiers r√©sultats pour que l'utilisateur puisse voir\n",
    "        for i, entity in enumerate(results[:5]):\n",
    "            entity_id = clean_entity_id(entity[\"item\"][\"value\"])\n",
    "            entity_label = entity[\"itemLabel\"][\"value\"]\n",
    "            print(f\"{i+1}. {entity_label} ({entity_id})\")\n",
    "        \n",
    "        if len(results) > 5:\n",
    "            print(f\"... et {len(results) - 5} autres r√©sultats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405fd9a8",
   "metadata": {},
   "source": [
    "### Test pour execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e118180b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Recherche de l'entit√© principale 'screwdriver'...\n",
      "üîç Requ√™te s√©lectionn√©e:\n",
      "        SELECT ?item ?itemLabel\n",
      "        WHERE {\n",
      "            ?item rdfs:label ?itemLabel.\n",
      "            FILTER(LANG(?itemLabel) = \"en\").\n",
      "            FILTER(CONTAINS(LCASE(?itemLabel), \"screwdriver\")).\n",
      "        }\n",
      "        \n",
      "üîç D√©but de la pagination (limit=50)...\n",
      "üîπ Requ√™te OFFSET 0, LIMIT 50\n",
      "‚ö†Ô∏è  Tentative 1/3 √©chou√©e √† l'offset 0: The read operation timed out\n",
      "‚ö†Ô∏è  Tentative 2/3 √©chou√©e √† l'offset 0: The read operation timed out\n",
      "‚ö†Ô∏è  Tentative 3/3 √©chou√©e √† l'offset 0: The read operation timed out\n",
      "‚ùå Requ√™te √©chou√©e apr√®s 3 tentatives √† l'offset 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üéØ IDENTIFICATION DE L'ENTIT√â\n",
    "\n",
    "def find_aeronautics_entity():\n",
    "    \"\"\"\n",
    "    Demande √† l'utilisateur le nom de l'entit√© √† rechercher dans Wikidata\n",
    "    :return: Tuple contenant l'ID et le label de l'entit√©\n",
    "    \"\"\"\n",
    "    entity_name = input(\"Entrez le nom de l'entit√© √† rechercher dans wikidata, en anglais (ex: aeronautics) : \").strip()\n",
    "    if not entity_name:\n",
    "        print(\"‚ùå Aucun nom d'entit√© fourni.\")\n",
    "        return None, None  # ‚úÖ Coh√©rent avec l'assignation\n",
    "\n",
    "    # Choix de la requ√™te √† utiliser\n",
    "    query_choice = input(\n",
    "        \"Quel type de requ√™te utiliser ?\\n\"\n",
    "        \"1Ô∏è‚É£ Recherche d'une cha√Æne dans les labels\\n\"\n",
    "        \"2Ô∏è‚É£ Requ√™te d'une cha√Æne dans les parents\\n\"\n",
    "        \"Entrez le num√©ro de votre choix (1 ou 2) : \"\n",
    "    ).strip()\n",
    "\n",
    "    if query_choice == \"1\":\n",
    "        query_regex = f\"\"\"\n",
    "        SELECT ?item ?itemLabel\n",
    "        WHERE {{\n",
    "            ?item rdfs:label ?itemLabel.\n",
    "            FILTER(LANG(?itemLabel) = \"en\").\n",
    "            FILTER(CONTAINS(LCASE(?itemLabel), \"{entity_name}\")).\n",
    "        }}\n",
    "        \"\"\"\n",
    "    elif query_choice == \"2\":\n",
    "        query_regex = f\"\"\"\n",
    "        SELECT ?item ?itemLabel\n",
    "        WHERE {{\n",
    "            ?item wdt:P31*/wdt:P279* ?parent.\n",
    "            ?parent rdfs:label ?parentLabel.\n",
    "            FILTER(LANG(?parentLabel) = \"en\").\n",
    "            FILTER(CONTAINS(LCASE(?parentLabel), \"{entity_name}\")).\n",
    "            SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Choix invalide. Veuillez entrer 1 ou 2.\")\n",
    "        return None, None  # ‚úÖ Coh√©rent avec l'assignation\n",
    "\n",
    "    print(f\"üîç Recherche de l'entit√© principale '{entity_name}'...\")\n",
    "    print(f\"üîç Requ√™te s√©lectionn√©e:{query_regex}\")\n",
    "    return execute_paginated_query(query_regex)\n",
    "find_aeronautics_entity()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c020b073",
   "metadata": {},
   "source": [
    "### Requ√™tes SPARQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad135870",
   "metadata": {},
   "source": [
    "# Trouver tous les endroits o√π un terme est utilis√© en propri√©t√©\n",
    "```sql\n",
    "SELECT ?item ?itemLabel ?prop ?propLabel WHERE {\n",
    "  ?item ?prop wd:Q936518.\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr\". }\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "```sql\n",
    "SELECT ?prop ?propLabel ?exemple ?exempleLabel WHERE {\n",
    "  {\n",
    "    SELECT ?prop (SAMPLE(?item) AS ?exemple) WHERE {\n",
    "      ?item ?prop wd:Q936518.\n",
    "    }\n",
    "    GROUP BY ?prop\n",
    "  }\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr\". }\n",
    "}\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295aa2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Requ√™tes d√©finies (avec synonymes fran√ßais)\n"
     ]
    }
   ],
   "source": [
    "def build_aeronautics_extraction_queries():\n",
    "    \"\"\"Construit les requ√™tes d'extraction des donn√©es\"\"\"\n",
    "    queries = {\n",
    "        \"manufacturers\": \"\"\"\n",
    "        SELECT DISTINCT ?item \n",
    "              \n",
    "                ?itemLabel\n",
    "               (COALESCE(?itemDescription_fr, ?itemDescription_en, ?itemDescription_any, \"\") AS ?itemDescription)\n",
    "               ?parent\n",
    "               ?parentLabel\n",
    "               (GROUP_CONCAT(DISTINCT ?synonym_fr; separator=\",\") AS ?synonyms_fr)\n",
    "        WHERE {\n",
    "          # Tous les constructeurs d'aviation (instances ou sous-classes ou parties)\n",
    "          ?item wdt:P31*/wdt:P279*/wdt:P361*/wdt:P452*/wdt:P749* wd:Q936518 .\n",
    "        \n",
    "          # On cherche le parent imm√©diat selon diff√©rentes relations\n",
    "            OPTIONAL { ?item wdt:P361 ?partOf . }\n",
    "            OPTIONAL { ?item wdt:P279 ?subclassOf . }\n",
    "            OPTIONAL { ?item wdt:P31 ?instanceOf . }\n",
    "            OPTIONAL { ?item wdt:P452 ?secteur .}\n",
    "            OPTIONAL { ?item wdt:P176 ?constructeur.}\n",
    "            OPTIONAL { ?item wdt:P749 ?constructeur.}\n",
    "            \n",
    "            BIND(COALESCE(?partOf, ?subclassOf, ?instanceOf, ?secteur, ?constructeur) AS ?parent)\n",
    "        \n",
    "          # Description de l'item (fr > en > autre)\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_any .\n",
    "                     FILTER(LANG(?itemDescription_any) != \"fr\" && LANG(?itemDescription_any) != \"en\") }\n",
    "\n",
    "          # Synonymes en fran√ßais (P1709 est \"synonymes exacts\")\n",
    "          OPTIONAL { ?item skos:altLabel ?synonym_fr . FILTER(LANG(?synonym_fr) = \"fr\") }\n",
    "        \n",
    "          SERVICE wikibase:label {\n",
    "            bd:serviceParam wikibase:language \"fr,en,[AUTO_LANGUAGE]\"\n",
    "          }\n",
    "        }\n",
    "        GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?itemDescription_any ?parent ?parentLabel\n",
    "        \"\"\",\n",
    "\n",
    "        \"aircraft_models\": \"\"\"\n",
    "        SELECT DISTINCT ?item \n",
    "               ?itemLabel\n",
    "               (COALESCE(?itemDescription_fr, ?itemDescription_en, ?itemDescription_any, \"\") AS ?itemDescription)\n",
    "               ?parent\n",
    "               ?parentLabel\n",
    "               (GROUP_CONCAT(DISTINCT ?synonym_fr; separator=\" , \") AS ?synonyms_fr)\n",
    "        WHERE {\n",
    "          # Tous les mod√®les d'avions (instances ou sous-classes ou parties)\n",
    "          ?item wdt:P31/wdt:P279* wd:Q11436 .\n",
    "          \n",
    "        \n",
    "          # On cherche le parent imm√©diat selon diff√©rentes relations         \n",
    "            OPTIONAL { ?item wdt:P179 ?series .}\n",
    "            OPTIONAL { ?item wdt:176 ?constructeur.}\n",
    "            OPTIONAL { ?item wdt:P31 ?instanceOf . } \n",
    "            OPTIONAL { ?item wdt:P361 ?partOf . }\n",
    "            OPTIONAL { ?item wdt:P279 ?subclassOf . }\n",
    "                       \n",
    "            BIND(COALESCE(?partOf, ?subclassOf, ?instanceOf, ?series, ?constructeur) AS ?parent)\n",
    "        \n",
    "          # Description de l'item (fr > en > autre)\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_any .\n",
    "                     FILTER(LANG(?itemDescription_any) != \"fr\" && LANG(?itemDescription_any) != \"en\") }\n",
    "\n",
    "          # Synonymes en fran√ßais\n",
    "          OPTIONAL { ?item skos:altLabel ?synonym_fr . FILTER(LANG(?synonym_fr) = \"fr\") }\n",
    "        \n",
    "          SERVICE wikibase:label {\n",
    "            bd:serviceParam wikibase:language \"fr,en,[AUTO_LANGUAGE]\"\n",
    "          }\n",
    "        }\n",
    "        GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?itemDescription_any ?parent ?parentLabel\n",
    "        \"\"\",\n",
    "\n",
    "        \"aircraft_components\": \"\"\"\n",
    "        SELECT DISTINCT ?item \n",
    "               ?itemLabel\n",
    "               (COALESCE(?itemDescription_fr, ?itemDescription_en, ?itemDescription_any, \"\") AS ?itemDescription)\n",
    "               ?parent\n",
    "               ?parentLabel\n",
    "               (GROUP_CONCAT(DISTINCT ?synonym_fr; separator=\" , \") AS ?synonyms_fr)\n",
    "        WHERE {\n",
    "          # Tous les √©quipements d'aviation (instances ou sous-classes ou parties)\n",
    "          ?item wdt:P31*/wdt:P279*/wdt:P361* wd:Q16693356 .\n",
    "        \n",
    "          # On cherche le parent imm√©diat selon diff√©rentes relations\n",
    "            OPTIONAL { ?item wdt:P361 ?partOf . }\n",
    "            OPTIONAL { ?item wdt:P279 ?subclassOf . }\n",
    "            OPTIONAL { ?item wdt:P31 ?instanceOf . }\n",
    "            OPTIONAL { ?item wdt:P452 ?secteur .}\n",
    "            OPTIONAL { ?item wdt:P176 ?constructeur.}\n",
    "            \n",
    "            BIND(COALESCE(?partOf, ?subclassOf, ?instanceOf, ?secteur, ?constructeur) AS ?parent)\n",
    "        \n",
    "          # Description de l'item (fr > en > autre)\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_any .\n",
    "                     FILTER(LANG(?itemDescription_any) != \"fr\" && LANG(?itemDescription_any) != \"en\") }\n",
    "\n",
    "          # Synonymes en fran√ßais\n",
    "          OPTIONAL { ?item skos:altLabel ?synonym_fr . FILTER(LANG(?synonym_fr) = \"fr\") }\n",
    "        \n",
    "          SERVICE wikibase:label {\n",
    "            bd:serviceParam wikibase:language \"fr,en,[AUTO_LANGUAGE]\"\n",
    "          }\n",
    "        }\n",
    "        GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?itemDescription_any ?parent ?parentLabel\n",
    "        \"\"\",\n",
    "\n",
    "        \"aeronautic_profession\": \"\"\"\n",
    "        SELECT DISTINCT ?item \n",
    "               ?itemLabel\n",
    "               (COALESCE(?itemDescription_fr, ?itemDescription_en, ?itemDescription_any, \"\") AS ?itemDescription)\n",
    "               ?parent\n",
    "               ?parentLabel\n",
    "               (GROUP_CONCAT(DISTINCT ?synonym_fr; separator=\" , \") AS ?synonyms_fr)\n",
    "        WHERE {\n",
    "        ?item wdt:P425* ?domaine.\n",
    "        VALUES ?domaine { wd:Q765633 wd:Q906438 wd:Q1434048 wd:Q206814 wd:Q627716 wd:Q221395 wd:Q765633 wd:Q22719}.  \n",
    "        \n",
    "          # On cherche le parent imm√©diat selon diff√©rentes relations\n",
    "            OPTIONAL { ?item wdt:P361 ?partOf . }\n",
    "            OPTIONAL { ?item wdt:P279 ?subclassOf . }\n",
    "            OPTIONAL { ?item wdt:P31 ?instanceOf . }\n",
    "            OPTIONAL { ?item wdt:P452 ?secteur .}\n",
    "            OPTIONAL { ?item wdt:P176 ?constructeur.}\n",
    "            OPTIONAL { ?item wdt:P749 ?constructeur.}\n",
    "            \n",
    "            BIND(COALESCE(?partOf, ?subclassOf, ?instanceOf, ?secteur, ?constructeur, ?domaine) AS ?parent) # Attention √† coalesce pour √©viter les doublons\n",
    "        \n",
    "          # Description de l'item (fr > en > autre)\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_any .\n",
    "                     FILTER(LANG(?itemDescription_any) != \"fr\" && LANG(?itemDescription_any) != \"en\") }\n",
    "\n",
    "          # Synonymes en fran√ßais\n",
    "          OPTIONAL { ?item skos:altLabel ?synonym_fr . FILTER(LANG(?synonym_fr) = \"fr\") }\n",
    "        \n",
    "          SERVICE wikibase:label {\n",
    "            bd:serviceParam wikibase:language \"fr,en,[AUTO_LANGUAGE]\"\n",
    "          }\n",
    "        }\n",
    "        GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?itemDescription_any ?parent ?parentLabel\n",
    "        \"\"\"\n",
    "    }\n",
    "    return queries\n",
    "\n",
    "print(\"‚úÖ Requ√™tes d√©finies (avec synonymes fran√ßais)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea367aee",
   "metadata": {},
   "source": [
    "## üîé Lancer la recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b6ebe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è EXTRACTION HI√âRARCHIQUE EXHAUSTIVE\n",
      "==================================================\n",
      "\n",
      "üîç Extraction: manufacturers\n",
      "üîπ Ex√©cution d'une requ√™te unique: Requ√™tes\n",
      "‚úÖ 842 entit√©s trouv√©es pour manufacturers\n",
      "\n",
      "üîç Extraction: aircraft_models\n",
      "üîπ Ex√©cution d'une requ√™te unique: Requ√™tes\n",
      "‚úÖ 11145 entit√©s trouv√©es pour aircraft_models\n",
      "\n",
      "üîç Extraction: aircraft_components\n",
      "üîπ Ex√©cution d'une requ√™te unique: Requ√™tes\n",
      "‚úÖ 4390 entit√©s trouv√©es pour aircraft_components\n",
      "\n",
      "üîç Extraction: aeronautic_profession\n",
      "üîπ Ex√©cution d'une requ√™te unique: Requ√™tes\n",
      "‚úÖ 31 entit√©s trouv√©es pour aeronautic_profession\n",
      "\n",
      "üéØ TOTAL: 16408 entit√©s extraites\n"
     ]
    }
   ],
   "source": [
    "# üõ†Ô∏è EXTRACTION DES DONN√âES A√âRONAUTIQUES\n",
    "def extract_all_aeronautics_data():\n",
    "    \"\"\"Extrait toutes les donn√©es a√©ronautiques de mani√®re optimis√©e\"\"\"\n",
    "    print(\"üèóÔ∏è EXTRACTION HI√âRARCHIQUE EXHAUSTIVE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    queries = build_aeronautics_extraction_queries()\n",
    "    all_results = []\n",
    "    \n",
    "    for category, query in queries.items():\n",
    "        print(f\"\\nüîç Extraction: {category}\")\n",
    "        \n",
    "        # ‚úÖ CORRECTION: Utiliser execute_paginated_query au lieu de execute_batch_queries\n",
    "        results = execute_batch_queries(query)\n",
    "        \n",
    "        # Enrichir chaque r√©sultat avec sa cat√©gorie\n",
    "        for result in results:\n",
    "            result[\"source_category\"] = category\n",
    "        \n",
    "        all_results.extend(results)\n",
    "        print(f\"‚úÖ {len(results)} entit√©s trouv√©es pour {category}\")\n",
    "    \n",
    "    print(f\"\\nüéØ TOTAL: {len(all_results)} entit√©s extraites\")\n",
    "    return all_results\n",
    "\n",
    "raw_aeronautics_data = extract_all_aeronautics_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dffabe",
   "metadata": {},
   "source": [
    "### Aper√ßu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85bbfb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q696016'}, 'itemLabel': {'xml:lang': 'fr', 'type': 'literal', 'value': 'Gothaer Waggonfabrik'}, 'parent': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q130640983'}, 'parentLabel': {'type': 'literal', 'value': 'Q130640983'}, 'itemDescription': {'xml:lang': 'fr', 'type': 'literal', 'value': 'constructeur allemand'}, 'synonyms_fr': {'type': 'literal', 'value': ''}, 'source_category': 'manufacturers'}, {'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q1426388'}, 'itemLabel': {'xml:lang': 'fr', 'type': 'literal', 'value': 'Glenn L. Martin Company'}, 'parent': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q936518'}, 'parentLabel': {'xml:lang': 'fr', 'type': 'literal', 'value': 'fabricant a√©ronautique et spatial'}, 'itemDescription': {'xml:lang': 'en', 'type': 'literal', 'value': 'defunct aerospace manufacturer'}, 'synonyms_fr': {'type': 'literal', 'value': 'Glenn L.Martin Company,Glenn Martin,Martin Aircraft Company,Martin Company,Martin Corporation'}, 'source_category': 'manufacturers'}, {'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q1273370'}, 'itemLabel': {'xml:lang': 'fr', 'type': 'literal', 'value': 'E.N.V. Motor Syndicate'}, 'parent': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q786820'}, 'parentLabel': {'xml:lang': 'fr', 'type': 'literal', 'value': 'constructeur automobile'}, 'itemDescription': {'xml:lang': 'fr', 'type': 'literal', 'value': 'ancien constructeur automobile'}, 'synonyms_fr': {'type': 'literal', 'value': ''}, 'source_category': 'manufacturers'}, {'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q109076862'}, 'itemLabel': {'xml:lang': 'fr', 'type': 'literal', 'value': 'Technoflug Leichtflugzeugbau'}, 'parent': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q936518'}, 'parentLabel': {'xml:lang': 'fr', 'type': 'literal', 'value': 'fabricant a√©ronautique et spatial'}, 'itemDescription': {'xml:lang': 'en', 'type': 'literal', 'value': 'German motorglider manufacturer'}, 'synonyms_fr': {'type': 'literal', 'value': 'Technoflug'}, 'source_category': 'manufacturers'}, {'item': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q3627889'}, 'itemLabel': {'xml:lang': 'fr', 'type': 'literal', 'value': 'ateliers A√©ronautiques de Suresnes'}, 'parent': {'type': 'uri', 'value': 'http://www.wikidata.org/entity/Q936518'}, 'parentLabel': {'xml:lang': 'fr', 'type': 'literal', 'value': 'fabricant a√©ronautique et spatial'}, 'itemDescription': {'xml:lang': 'en', 'type': 'literal', 'value': '1940s aircraft manufacturer in France'}, 'synonyms_fr': {'type': 'literal', 'value': ''}, 'source_category': 'manufacturers'}]\n"
     ]
    }
   ],
   "source": [
    "print(raw_aeronautics_data[:5])  # pour afficher un aper√ßu\n",
    "\n",
    "json_filename = f\"raw.json\"\n",
    "json_filepath = os.path.join(output_dir, json_filename)\n",
    "\n",
    "with open(json_filepath, 'w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(raw_aeronautics_data, jsonfile, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5639628",
   "metadata": {},
   "source": [
    "## üìÅ Export\n",
    "\n",
    "### Construction du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da268123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è CONSTRUCTION DE LA HI√âRARCHIE FINALE\n",
      "=============================================\n",
      "‚úÖ Hi√©rarchie construite: 16408 entr√©es totales\n",
      "üéØ Th√©saurus final: 16408 entr√©es\n"
     ]
    }
   ],
   "source": [
    "# üèóÔ∏è CONSTRUCTION DE LA HI√âRARCHIE FINALE\n",
    "\n",
    "# def get_id_from_uri(uri):\n",
    "#     # Ex: \"http://www.wikidata.org/entity/Q105557\" ‚Üí \"Q105557\"\n",
    "#     return uri.split(\"/\")[-1] if uri else \"\"\n",
    "\n",
    "def build_final_hierarchy(raw_aeronautics_data):\n",
    "    \"\"\"Construit la hi√©rarchie finale avec parents imm√©diats et cat√©gories\"\"\"\n",
    "    print(\"üèóÔ∏è CONSTRUCTION DE LA HI√âRARCHIE FINALE\")\n",
    "    print(\"=\"*45)\n",
    "    \n",
    "    # Cr√©er la hi√©rarchie structur√©e\n",
    "    hierarchy = []\n",
    "    for entry in raw_aeronautics_data:\n",
    "    \n",
    "        hierarchy.append(\n",
    "            {\n",
    "            \"ID\": clean_entity_id(entry.get(\"item\", {}).get(\"value\", \"\")),\n",
    "            \"Terme\": entry.get(\"itemLabel\", {}).get(\"value\", \"\"),\n",
    "            \"ID_TG\": clean_entity_id(entry.get(\"parent\", {}).get(\"value\", \"\")),\n",
    "            \"TG\": entry.get(\"parentLabel\", {}).get(\"value\", \"\"),\n",
    "            \"Def\": entry.get(\"itemDescription\", {}).get(\"value\", \"\"),\n",
    "            \"EP\": entry.get(\"synonyms_fr\", {}).get(\"value\", \"\"),\n",
    "            \"TA\": entry.get(\"source_category\", {})\n",
    "        }\n",
    "        )\n",
    "    \n",
    " \n",
    "    print(f\"‚úÖ Hi√©rarchie construite: {len(hierarchy)} entr√©es totales\")\n",
    "    return hierarchy\n",
    "\n",
    "final_thesaurus = build_final_hierarchy(raw_aeronautics_data)\n",
    "print(f\"üéØ Th√©saurus final: {len(final_thesaurus)} entr√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdc1047",
   "metadata": {},
   "source": [
    "### Export du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc3e345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ EXPORT FINAL UNIQUE - CSV Occidental European Format (semicolon separated)\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def export_final_thesaurus(thesaurus_data):\n",
    "    \"\"\"Exporte le th√©saurus final en CSV (point-virgule, format europ√©en) et JSON\"\"\"\n",
    "    print(\"üíæ EXPORT FINAL UNIQUE\")\n",
    "    print(\"=\"*25)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 1. Export CSV - Occidental European (semicolon separator, utf-8-sig BOM)\n",
    "    csv_filename = f\"thesaurus_aeronautique_FINAL_{timestamp}.csv\"\n",
    "    csv_filepath = os.path.join(output_dir, csv_filename)\n",
    "    \n",
    "    fieldnames = [\n",
    "        'ID', 'Terme', 'ID_TG','TG', 'Def', 'EP',\n",
    "        'TA'\n",
    "    ]\n",
    "    \n",
    "    print(f\"üìÑ Export CSV: {csv_filename}\")\n",
    "    with open(csv_filepath, 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
    "        writer = csv.DictWriter(\n",
    "            csvfile, \n",
    "            fieldnames=fieldnames,\n",
    "            delimiter=';',         # Use semicolon as separator\n",
    "            quoting=csv.QUOTE_MINIMAL\n",
    "        )\n",
    "        writer.writeheader()\n",
    "        for entry in sorted(thesaurus_data, key=lambda x: x[\"ID\"]):\n",
    "            # Ensure all values are strings and convert None to empty string\n",
    "            row = {k: ('' if v is None else str(v)) for k, v in entry.items()}\n",
    "            # Guarantee all required fields exist in row\n",
    "            for field in fieldnames:\n",
    "                row.setdefault(field, '')\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    # 2. Export JSON avec m√©tadonn√©es\n",
    "    json_filename = f\"thesaurus_aeronautique_FINAL_{timestamp}.json\"\n",
    "    json_filepath = os.path.join(output_dir, json_filename)\n",
    "    \n",
    "    stats = analyze_thesaurus_statistics(thesaurus_data)\n",
    "    \n",
    "    json_data = {\n",
    "        \"metadata\": {\n",
    "            \"title\": \"Th√©saurus A√©ronautique Final - Wikidata\",\n",
    "            \"description\": \"Th√©saurus exhaustif avec hi√©rarchie et parents imm√©diats\",\n",
    "            \"version\": \"1.0-FINAL\",\n",
    "            \"created\": timestamp,\n",
    "            \"source\": \"Wikidata SPARQL optimis√©\",\n",
    "            \"total_entries\": len(thesaurus_data),\n",
    "            \"extraction_method\": \"multi-query_hierarchical\",\n",
    "            \"parent_detection\": \"automatic_wikidata_relations\",\n",
    "            \"multilingual_support\": True,\n",
    "            \"format\": \"structured_hierarchical_thesaurus\"\n",
    "        },\n",
    "        \"statistics\": stats,\n",
    "        \"data\": thesaurus_data\n",
    "    }\n",
    "    \n",
    "    print(f\"üìÑ Export JSON: {json_filename}\")\n",
    "    with open(json_filepath, 'w', encoding='utf-8') as jsonfile:\n",
    "        json.dump(json_data, jsonfile, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    return csv_filepath, json_filepath, stats\n",
    "\n",
    "def analyze_thesaurus_statistics(thesaurus_data):\n",
    "    \"\"\"Analyse les statistiques du th√©saurus final\"\"\"\n",
    "    stats = {\n",
    "        \"total_entries\": len(thesaurus_data),\n",
    "        \"categories\": {},\n",
    "        \"relation_types\": {},\n",
    "        \"languages\": {},\n",
    "        \"hierarchy_depth\": 0,\n",
    "        \"entries_with_synonyms\": 0,\n",
    "        \"entries_with_descriptions\": 0\n",
    "    }\n",
    "    \n",
    "    for entry in thesaurus_data:\n",
    "        # Cat√©gories\n",
    "        category = entry.get(\"category\", \"unknown\")\n",
    "        stats[\"categories\"][category] = stats[\"categories\"].get(category, 0) + 1\n",
    "        \n",
    "        # Types de relation\n",
    "        rel_type = entry.get(\"relation_type\", \"unknown\")\n",
    "        stats[\"relation_types\"][rel_type] = stats[\"relation_types\"].get(rel_type, 0) + 1\n",
    "        \n",
    "        # Langues\n",
    "        lang = entry.get(\"lang\", \"unknown\")\n",
    "        stats[\"languages\"][lang] = stats[\"languages\"].get(lang, 0) + 1\n",
    "        \n",
    "        # Enrichissements\n",
    "        if entry.get(\"synonyms\"):\n",
    "            stats[\"entries_with_synonyms\"] += 1\n",
    "        if entry.get(\"description\"):\n",
    "            stats[\"entries_with_descriptions\"] += 1\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def display_final_summary(stats, csv_file, json_file):\n",
    "    \"\"\"Affiche un r√©sum√© final du th√©saurus g√©n√©r√©\"\"\"\n",
    "    print(\"\\nüéØ R√âSUM√â FINAL DU TH√âSAURUS A√âRONAUTIQUE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"üìä STATISTIQUES G√âN√âRALES:\")\n",
    "    print(f\"   ‚Ä¢ Total d'entr√©es: {stats['total_entries']}\")\n",
    "    print(f\"   ‚Ä¢ Entr√©es avec synonymes: {stats['entries_with_synonyms']}\")\n",
    "    print(f\"   ‚Ä¢ Entr√©es avec descriptions: {stats['entries_with_descriptions']}\")\n",
    "    \n",
    "    print(f\"\\nüìÇ R√âPARTITION PAR CAT√âGORIE:\")\n",
    "    for category, count in sorted(stats[\"categories\"].items(), key=lambda x: x[1], reverse=True):\n",
    "        percentage = (count / stats['total_entries']) * 100\n",
    "        print(f\"   ‚Ä¢ {category}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nüîó TYPES DE RELATIONS:\")\n",
    "    for rel_type, count in sorted(stats[\"relation_types\"].items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"   ‚Ä¢ {rel_type}: {count}\")\n",
    "    \n",
    "    print(f\"\\nüåê LANGUES:\")\n",
    "    for lang, count in stats[\"languages\"].items():\n",
    "        print(f\"   ‚Ä¢ {lang}: {count}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ FICHIERS G√âN√âR√âS:\")\n",
    "    print(f\"   ‚úÖ CSV: {os.path.basename(csv_file)}\")\n",
    "    print(f\"   ‚úÖ JSON: {os.path.basename(json_file)}\")\n",
    "    \n",
    "    print(f\"\\nüèÜ MISSION ACCOMPLIE !\")\n",
    "    print(f\" {stats['total_entries']} entr√©es de th√©saurus\")\n",
    "\n",
    "# Export et r√©sum√© final\n",
    "if final_thesaurus:\n",
    "    csv_file, json_file, statistics = export_final_thesaurus(final_thesaurus)\n",
    "    display_final_summary(statistics, csv_file, json_file)\n",
    "else:\n",
    "    print(\"‚ùå Aucun th√©saurus √† exporter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d148f58",
   "metadata": {},
   "source": [
    "### Nettoyage des doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27f6dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire le CSV (remplace 'ton_fichier.csv' par le tien)\n",
    "df = pd.read_csv(csv_file, sep=';', dtype=str).fillna('')\n",
    "\n",
    "# Fonction pour concat√©ner les valeurs uniques (s√©par√©es par \"|\")\n",
    "def concat_unique(series):\n",
    "    uniques = set([v.strip() for v in series if v.strip() != ''])\n",
    "    return \" | \".join(sorted(uniques)) if uniques else ''\n",
    "\n",
    "# Grouper par 'ID', en concat√©nant les valeurs diff√©rentes pour chaque colonne\n",
    "df_clean = df.groupby('ID', as_index=False).agg(concat_unique)\n",
    "\n",
    "# Sauvegarder le r√©sultat\n",
    "df_clean.to_csv(csv_file, sep=';', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"‚úÖ CSV nettoy√© et export√© sous {csv_file}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
