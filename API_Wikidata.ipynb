{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "339b9f1f",
   "metadata": {},
   "source": [
    "# üöÄ Requ√™te WIKIDATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f576147d",
   "metadata": {},
   "source": [
    "## üî® Construction de l'environnement n√©cessaire et configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74111c85",
   "metadata": {},
   "source": [
    "### Installation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaf8794",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install SPARQLWrapper tqdm pandas\n",
    "\n",
    "print(\"‚¨áÔ∏è Installation termin√©e !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266e7bad",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e86a25c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ CONFIGURATION TERMIN√âE\n",
      "üìÅ Dossier de sortie: ./output\n",
      "‚è±Ô∏è  Rate limit: 2.0s entre requ√™tes\n",
      "üì¶ Taille des batches: 10\n"
     ]
    }
   ],
   "source": [
    "# üîß CONFIGURATION ET IMPORTS\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "WIKIDATA_ENDPOINT = \"https://query.wikidata.org/sparql\"\n",
    "RATE_LIMIT_DELAY = 2.0 \n",
    "BATCH_SIZE = 10  \n",
    "MAX_RETRIES = 5  \n",
    "REQUEST_TIMEOUT = 60\n",
    "ENRICHMENT_BATCH_SIZE = 15\n",
    "\n",
    "# Dossier de sortie\n",
    "output_dir = \"./output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"üöÄ CONFIGURATION TERMIN√âE\")\n",
    "print(f\"üìÅ Dossier de sortie: {output_dir}\")\n",
    "print(f\"‚è±Ô∏è  Rate limit: {RATE_LIMIT_DELAY}s entre requ√™tes\")\n",
    "print(f\"üì¶ Taille des batches: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "519640a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó FONCTIONS CONFIGUR√âES AVEC DIAGNOSTIC AVANC√â\n"
     ]
    }
   ],
   "source": [
    "def create_sparql_client():\n",
    "    \"\"\"\n",
    "    Cr√©er un client SPARQL pour interagir avec Wikidata\n",
    "    :return: Instance de SPARQLWrapper configur√©e pour Wikidata\n",
    "    \"\"\"\n",
    "    sparql = SPARQLWrapper(WIKIDATA_ENDPOINT)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    sparql.setTimeout(REQUEST_TIMEOUT)\n",
    "    return sparql\n",
    "\n",
    "def execute_sparql_query(query, max_retries=MAX_RETRIES):\n",
    "    \"\"\"\n",
    "    Ex√©cute une requ√™te SPARQL avec gestion des erreurs et rate limiting\n",
    "    :param query: La requ√™te SPARQL √† ex√©cuter\n",
    "    :param max_retries: Nombre maximum de tentatives en cas d'√©chec\n",
    "    :return: R√©sultats de la requ√™te ou une liste vide en cas d'√©chec\n",
    "    \"\"\"\n",
    "    sparql = create_sparql_client()\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            sparql.setQuery(query)  # D√©finition de la requ√™te SPARQL √† ex√©cuter\n",
    "            results = sparql.query().convert()  # Ex√©cution de a requ√™te et conversion en JSON\n",
    "            time.sleep(RATE_LIMIT_DELAY)  # D√©lai entre les requ√™tes\n",
    "            return results[\"results\"][\"bindings\"]  # R√©sultats extraits\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Tentative {attempt + 1}/{max_retries} √©chou√©e: {e}...\")  # Affiche l'erreur et le num√©ro de tentative\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(RATE_LIMIT_DELAY * (attempt + 2))  # Attend plus longtemps avant de r√©essayer si les tentatives max ne sont pas d√©pass√©es\n",
    "            else:\n",
    "                print(f\"‚ùå Requ√™te √©chou√©e apr√®s {max_retries} tentatives\") \n",
    "                return []\n",
    "    return []\n",
    "\n",
    "def clean_entity_id(entity_uri):\n",
    "    \"\"\"\n",
    "    Extrait l'ID d'une entit√© √† partir de son URI\n",
    "    :param entity_uri: URI de l'entit√© (ex: \"http://www.wikidata.org/entity/Q42'\")\n",
    "    :return: ID de l'entit√© (ex: \"Q42\") ou une cha√Æne vide si l'URI est vide\n",
    "    \"\"\"\n",
    "    if not entity_uri:\n",
    "        return \"\"\n",
    "    return entity_uri.split(\"/\")[-1] if \"/\" in entity_uri else entity_uri\n",
    "\n",
    "def execute_batch_queries(queries, description=\"Requ√™tes\"):\n",
    "    \"\"\"\n",
    "    Ex√©cute une liste de requ√™tes SPARQL en batch\n",
    "    :param queries: Liste de requ√™tes SPARQL √† ex√©cuter\n",
    "    :param description: Description de la t√¢che pour l'affichage\n",
    "    :return: Liste de tous les r√©sultats combin√©s\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "    for i, query in enumerate(tqdm(queries, desc=description)):  # Boucle sur chaque requ√™te avec barre de progression\n",
    "        results = execute_sparql_query(query)  # Ex√©cute la requ√™te SPARQL\n",
    "        all_results.extend(results)  # Ajoute les r√©sultats √† la liste globale\n",
    "        if (i + 1) % BATCH_SIZE == 0:  # Toutes les BATCH_SIZE requ√™tes, on attend un peu\n",
    "            time.sleep(RATE_LIMIT_DELAY)  # Pause\n",
    "    return all_results  # Retourne la liste compl√®te des r√©sultats\n",
    "\n",
    "print(\"üîó FONCTIONS CONFIGUR√âES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d392e0",
   "metadata": {},
   "source": [
    "## üöß Construction de la requ√™te\n",
    "\n",
    "\n",
    "### Rechercher une entit√© par nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb3ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ IDENTIFICATION DE L'ENTIT√â\n",
    "\n",
    "def find_aeronautics_entity():\n",
    "  \"\"\"\n",
    "  Demande √† l'utilisateur le nom de l'entit√© √† rechercher dans Wikidata\n",
    "  :return: Tuple contenant l'ID, le label et la description de l'entit√©\n",
    "  \"\"\"\n",
    "  entity_name = input(\"Entrez le nom de l'entit√© √† rechercher (ex: aeronautics) : \").strip()\n",
    "  if not entity_name:\n",
    "    print(\"‚ùå Aucun nom d'entit√© fourni.\")\n",
    "    return None, None, None\n",
    "\n",
    "  aeronautics_query = f\"\"\"\n",
    "  SELECT DISTINCT ?item ?itemLabel ?itemDescription WHERE {{\n",
    "    ?item rdfs:label ?label .\n",
    "    FILTER(LANG(?label) = \"fr\" || LANG(?label) = \"en\") .\n",
    "    FILTER(REGEX(?label, \"{re.escape(entity_name)}\", \"i\"))\n",
    "    SERVICE wikibase:label {{ \n",
    "      bd:serviceParam wikibase:language \"fr,en\" . \n",
    "    }}\n",
    "  }}\n",
    "  LIMIT 5\n",
    "  \"\"\"\n",
    "\n",
    "  print(f\"üîç Recherche de l'entit√© principale '{entity_name}'...\")\n",
    "  results = execute_sparql_query(aeronautics_query)\n",
    "\n",
    "  if results:\n",
    "    entity = results[0]\n",
    "    entity_id = clean_entity_id(entity[\"item\"][\"value\"])\n",
    "    entity_label = entity[\"itemLabel\"][\"value\"]\n",
    "    entity_desc = entity.get(\"itemDescription\", {}).get(\"value\", \"\")\n",
    "\n",
    "    print(f\"‚úÖ Entit√© trouv√©e: {entity_label} ({entity_id})\")\n",
    "    print(f\"üìÑ Description: {entity_desc}\")\n",
    "\n",
    "    return entity_id, entity_label, entity_desc\n",
    "  else:\n",
    "    print(\"‚ùå Entit√© non trouv√©e\")\n",
    "    return None, None, None\n",
    "\n",
    "# Identifier l'entit√© principale\n",
    "aeronautics_entity, aeronautics_label, aeronautics_desc = find_aeronautics_entity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe64cba",
   "metadata": {},
   "source": [
    "### CELLULE DE TEST : \n",
    "```sql\n",
    "SELECT ?item ?itemLabel ?parent \n",
    "WHERE {\n",
    "  ?item wdt:P31 ?parent.\n",
    "  FILTER(CONTAINS(LCASE(?parent), \"a√©ronautique\")).\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"fr\". }\n",
    "}\n",
    "\n",
    "LIMIT 10\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c027626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Recherche de l'entit√© principale 'a√©ronautique'...\n",
      "‚ö†Ô∏è  Tentative 1/5 √©chou√©e: The read operation timed out...\n",
      "‚ö†Ô∏è  Tentative 2/5 √©chou√©e: The read operation timed out...\n",
      "‚ö†Ô∏è  Tentative 3/5 √©chou√©e: The read operation timed out...\n"
     ]
    }
   ],
   "source": [
    "# üéØ IDENTIFICATION DE L'ENTIT√â\n",
    "\n",
    "def find_aeronautics_entity():\n",
    "  \"\"\"\n",
    "  Demande √† l'utilisateur le nom de l'entit√© √† rechercher dans Wikidata\n",
    "  :return: Tuple contenant l'ID, le label et la description de l'entit√©\n",
    "  \"\"\"\n",
    "  entity_name = input(\"Entrez le nom de l'entit√© √† rechercher (ex: aeronautics) : \").strip()\n",
    "  if not entity_name:\n",
    "    print(\"‚ùå Aucun nom d'entit√© fourni.\")\n",
    "    return None, None, None\n",
    "  \n",
    "  aeronautics_query = f\"\"\"\n",
    "  SELECT ?item ?itemLabel ?parent ?itemDescription\n",
    "WHERE {{\n",
    "  ?item wdt:P31 ?parent.\n",
    "  ?parent rdfs:label ?parentLabel.\n",
    "  FILTER(LANG(?parentLabel) = \"fr\").\n",
    "  FILTER(CONTAINS(LCASE(?parentLabel), \"{entity_name}\")).\n",
    "  SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"fr\". }}\n",
    "}}\n",
    "\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "  print(f\"üîç Recherche de l'entit√© principale '{entity_name}'...\")\n",
    "  results = execute_sparql_query(aeronautics_query)\n",
    "\n",
    "  if results:\n",
    "    entity = results[0]\n",
    "    entity_id = clean_entity_id(entity[\"item\"][\"value\"])\n",
    "    entity_label = entity[\"itemLabel\"][\"value\"]\n",
    "    entity_desc = entity.get(\"itemDescription\", {}).get(\"value\", \"\")\n",
    "\n",
    "    print(f\"‚úÖ Entit√© trouv√©e: {entity_label} ({entity_id})\")\n",
    "    print(f\"üìÑ Description: {entity_desc}\")\n",
    "\n",
    "    return entity_id, entity_label, entity_desc\n",
    "  else:\n",
    "    print(\"‚ùå Entit√© non trouv√©e\")\n",
    "    return None, None, None\n",
    "\n",
    "# Identifier l'entit√© principale\n",
    "aeronautics_entity, aeronautics_label, aeronautics_desc = find_aeronautics_entity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c020b073",
   "metadata": {},
   "source": [
    "### Requ√™tes SPARQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295aa2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_aeronautics_extraction_queries():\n",
    "    \"\"\"Construit les requ√™tes d'extraction des donn√©es\"\"\"\n",
    "    queries = {\n",
    "        \"manufacturers\": \"\"\"\n",
    "        SELECT DISTINCT ?item \n",
    "              \n",
    "                ?itemLabel\n",
    "               (COALESCE(?itemDescription_fr, ?itemDescription_en, ?itemDescription_any, \"\") AS ?itemDescription)\n",
    "               ?parent\n",
    "               ?parentLabel\n",
    "               (GROUP_CONCAT(DISTINCT ?synonym_fr; separator=\",\") AS ?synonyms_fr)\n",
    "        WHERE {\n",
    "          # Tous les √©quipements d'aviation (instances ou sous-classes ou parties)\n",
    "          ?item wdt:P31*/wdt:P279*/wdt:P361*/wdt:P452*/wdt:P749* wd:Q936518 .\n",
    "        \n",
    "          # On cherche le parent imm√©diat selon diff√©rentes relations\n",
    "            OPTIONAL { ?item wdt:P361 ?partOf . }\n",
    "            OPTIONAL { ?item wdt:P279 ?subclassOf . }\n",
    "            OPTIONAL { ?item wdt:P31 ?instanceOf . }\n",
    "            OPTIONAL { ?item wdt:P452 ?secteur .}\n",
    "            OPTIONAL { ?item wdt:P176 ?constructeur.}\n",
    "            OPTIONAL { ?item wdt:P749 ?constructeur.}\n",
    "            \n",
    "            BIND(COALESCE(?partOf, ?subclassOf, ?instanceOf, ?secteur, ?constructeur) AS ?parent)\n",
    "        \n",
    "          # Description de l'item (fr > en > autre)\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_any .\n",
    "                     FILTER(LANG(?itemDescription_any) != \"fr\" && LANG(?itemDescription_any) != \"en\") }\n",
    "\n",
    "          # Synonymes en fran√ßais (P1709 est \"synonymes exacts\")\n",
    "          OPTIONAL { ?item skos:altLabel ?synonym_fr . FILTER(LANG(?synonym_fr) = \"fr\") }\n",
    "        \n",
    "          SERVICE wikibase:label {\n",
    "            bd:serviceParam wikibase:language \"fr,en,[AUTO_LANGUAGE]\"\n",
    "          }\n",
    "        }\n",
    "        GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?itemDescription_any ?parent ?parentLabel\n",
    "        \"\"\",\n",
    "\n",
    "        \"aircraft_models\": \"\"\"\n",
    "        SELECT DISTINCT ?item \n",
    "               ?itemLabel\n",
    "               (COALESCE(?itemDescription_fr, ?itemDescription_en, ?itemDescription_any, \"\") AS ?itemDescription)\n",
    "               ?parent\n",
    "               ?parentLabel\n",
    "               (GROUP_CONCAT(DISTINCT ?synonym_fr; separator=\" , \") AS ?synonyms_fr)\n",
    "        WHERE {\n",
    "          # Tous les mod√®les d'avions (instances ou sous-classes ou parties)\n",
    "          ?item wdt:P31/wdt:P279* wd:Q11436 .\n",
    "          \n",
    "        \n",
    "          # On cherche le parent imm√©diat selon diff√©rentes relations         \n",
    "            OPTIONAL { ?item wdt:P179 ?series .}\n",
    "            OPTIONAL { ?item wdt:176 ?constructeur.}\n",
    "            OPTIONAL { ?item wdt:P31 ?instanceOf . } \n",
    "            OPTIONAL { ?item wdt:P361 ?partOf . }\n",
    "            OPTIONAL { ?item wdt:P279 ?subclassOf . }\n",
    "                       \n",
    "            BIND(COALESCE(?partOf, ?subclassOf, ?instanceOf, ?series, ?constructeur) AS ?parent)\n",
    "        \n",
    "          # Description de l'item (fr > en > autre)\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_any .\n",
    "                     FILTER(LANG(?itemDescription_any) != \"fr\" && LANG(?itemDescription_any) != \"en\") }\n",
    "\n",
    "          # Synonymes en fran√ßais\n",
    "          OPTIONAL { ?item skos:altLabel ?synonym_fr . FILTER(LANG(?synonym_fr) = \"fr\") }\n",
    "        \n",
    "          SERVICE wikibase:label {\n",
    "            bd:serviceParam wikibase:language \"fr,en,[AUTO_LANGUAGE]\"\n",
    "          }\n",
    "        }\n",
    "        GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?itemDescription_any ?parent ?parentLabel\n",
    "        \"\"\",\n",
    "\n",
    "        \"aircraft_components\": \"\"\"\n",
    "        SELECT DISTINCT ?item \n",
    "               ?itemLabel\n",
    "               (COALESCE(?itemDescription_fr, ?itemDescription_en, ?itemDescription_any, \"\") AS ?itemDescription)\n",
    "               ?parent\n",
    "               ?parentLabel\n",
    "               (GROUP_CONCAT(DISTINCT ?synonym_fr; separator=\" , \") AS ?synonyms_fr)\n",
    "        WHERE {\n",
    "          # Tous les √©quipements d'aviation (instances ou sous-classes ou parties)\n",
    "          ?item wdt:P31*/wdt:P279*/wdt:P361* wd:Q16693356 .\n",
    "        \n",
    "          # On cherche le parent imm√©diat selon diff√©rentes relations\n",
    "            OPTIONAL { ?item wdt:P361 ?partOf . }\n",
    "            OPTIONAL { ?item wdt:P279 ?subclassOf . }\n",
    "            OPTIONAL { ?item wdt:P31 ?instanceOf . }\n",
    "            OPTIONAL { ?item wdt:P452 ?secteur .}\n",
    "            OPTIONAL { ?item wdt:P176 ?constructeur.}\n",
    "            \n",
    "            BIND(COALESCE(?partOf, ?subclassOf, ?instanceOf, ?secteur, ?constructeur) AS ?parent)\n",
    "        \n",
    "          # Description de l'item (fr > en > autre)\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_any .\n",
    "                     FILTER(LANG(?itemDescription_any) != \"fr\" && LANG(?itemDescription_any) != \"en\") }\n",
    "\n",
    "          # Synonymes en fran√ßais\n",
    "          OPTIONAL { ?item skos:altLabel ?synonym_fr . FILTER(LANG(?synonym_fr) = \"fr\") }\n",
    "        \n",
    "          SERVICE wikibase:label {\n",
    "            bd:serviceParam wikibase:language \"fr,en,[AUTO_LANGUAGE]\"\n",
    "          }\n",
    "        }\n",
    "        GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?itemDescription_any ?parent ?parentLabel\n",
    "        \"\"\",\n",
    "\n",
    "        \"aeronautic_profession\": \"\"\"\n",
    "        SELECT DISTINCT ?item \n",
    "               ?itemLabel\n",
    "               (COALESCE(?itemDescription_fr, ?itemDescription_en, ?itemDescription_any, \"\") AS ?itemDescription)\n",
    "               ?parent\n",
    "               ?parentLabel\n",
    "               (GROUP_CONCAT(DISTINCT ?synonym_fr; separator=\" , \") AS ?synonyms_fr)\n",
    "        WHERE {\n",
    "        ?item wdt:P425* ?domaine.\n",
    "        VALUES ?domaine { wd:Q765633 wd:Q906438 wd:Q1434048 wd:Q206814 wd:Q627716 wd:Q221395 wd:Q765633 wd:Q22719}.  \n",
    "        \n",
    "          # On cherche le parent imm√©diat selon diff√©rentes relations\n",
    "            OPTIONAL { ?item wdt:P361 ?partOf . }\n",
    "            OPTIONAL { ?item wdt:P279 ?subclassOf . }\n",
    "            OPTIONAL { ?item wdt:P31 ?instanceOf . }\n",
    "            OPTIONAL { ?item wdt:P452 ?secteur .}\n",
    "            OPTIONAL { ?item wdt:P176 ?constructeur.}\n",
    "            OPTIONAL { ?item wdt:P749 ?constructeur.}\n",
    "            \n",
    "            BIND(COALESCE(?partOf, ?subclassOf, ?instanceOf, ?secteur, ?constructeur, ?domaine) AS ?parent) # Attention √† coalesce pour √©viter les doublons\n",
    "        \n",
    "          # Description de l'item (fr > en > autre)\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_fr . FILTER(LANG(?itemDescription_fr) = \"fr\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_en . FILTER(LANG(?itemDescription_en) = \"en\") }\n",
    "          OPTIONAL { ?item schema:description ?itemDescription_any .\n",
    "                     FILTER(LANG(?itemDescription_any) != \"fr\" && LANG(?itemDescription_any) != \"en\") }\n",
    "\n",
    "          # Synonymes en fran√ßais\n",
    "          OPTIONAL { ?item skos:altLabel ?synonym_fr . FILTER(LANG(?synonym_fr) = \"fr\") }\n",
    "        \n",
    "          SERVICE wikibase:label {\n",
    "            bd:serviceParam wikibase:language \"fr,en,[AUTO_LANGUAGE]\"\n",
    "          }\n",
    "        }\n",
    "        GROUP BY ?item ?itemLabel ?itemDescription_fr ?itemDescription_en ?itemDescription_any ?parent ?parentLabel\n",
    "        \"\"\"\n",
    "    }\n",
    "    return queries\n",
    "\n",
    "print(\"‚úÖ Requ√™tes d√©finies (avec synonymes fran√ßais)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea367aee",
   "metadata": {},
   "source": [
    "## üîé Lancer la recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b6ebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_aeronautics_data():\n",
    "    \"\"\"Extrait toutes les donn√©es a√©ronautiques de mani√®re optimis√©e\"\"\"\n",
    "    print(\"üèóÔ∏è EXTRACTION HI√âRARCHIQUE EXHAUSTIVE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    queries = build_aeronautics_extraction_queries()\n",
    "    all_results = []\n",
    "    \n",
    "    for category, query in queries.items():\n",
    "        print(f\"\\nüîç Extraction: {category}\")\n",
    "        results = execute_sparql_query(query)\n",
    "        \n",
    "        # Enrichir chaque r√©sultat avec sa cat√©gorie\n",
    "        for result in results:\n",
    "            result[\"source_category\"] = category\n",
    "        \n",
    "        all_results.extend(results)\n",
    "        print(f\"‚úÖ {len(results)} entit√©s trouv√©es pour {category}\")\n",
    "    \n",
    "    print(f\"\\nüéØ TOTAL: {len(all_results)} entit√©s extraites\")\n",
    "    return all_results\n",
    "\n",
    "raw_aeronautics_data = extract_all_aeronautics_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dffabe",
   "metadata": {},
   "source": [
    "### Aper√ßu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bbfb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_aeronautics_data[:5])  # pour afficher un aper√ßu\n",
    "\n",
    "json_filename = f\"raw.json\"\n",
    "json_filepath = os.path.join(output_dir, json_filename)\n",
    "\n",
    "with open(json_filepath, 'w', encoding='utf-8') as jsonfile:\n",
    "    json.dump(raw_aeronautics_data, jsonfile, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5639628",
   "metadata": {},
   "source": [
    "## üìÅ Export\n",
    "\n",
    "### Construction du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da268123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèóÔ∏è CONSTRUCTION DE LA HI√âRARCHIE FINALE\n",
    "\n",
    "# def get_id_from_uri(uri):\n",
    "#     # Ex: \"http://www.wikidata.org/entity/Q105557\" ‚Üí \"Q105557\"\n",
    "#     return uri.split(\"/\")[-1] if uri else \"\"\n",
    "\n",
    "def build_final_hierarchy(raw_aeronautics_data):\n",
    "    \"\"\"Construit la hi√©rarchie finale avec parents imm√©diats et cat√©gories\"\"\"\n",
    "    print(\"üèóÔ∏è CONSTRUCTION DE LA HI√âRARCHIE FINALE\")\n",
    "    print(\"=\"*45)\n",
    "    \n",
    "    # Cr√©er la hi√©rarchie structur√©e\n",
    "    hierarchy = []\n",
    "    for entry in raw_aeronautics_data:\n",
    "    \n",
    "        hierarchy.append(\n",
    "            {\n",
    "            \"ID\": clean_entity_id(entry.get(\"item\", {}).get(\"value\", \"\")),\n",
    "            \"Terme\": entry.get(\"itemLabel\", {}).get(\"value\", \"\"),\n",
    "            \"ID_TG\": clean_entity_id(entry.get(\"parent\", {}).get(\"value\", \"\")),\n",
    "            \"TG\": entry.get(\"parentLabel\", {}).get(\"value\", \"\"),\n",
    "            \"Def\": entry.get(\"itemDescription\", {}).get(\"value\", \"\"),\n",
    "            \"EP\": entry.get(\"synonyms_fr\", {}).get(\"value\", \"\"),\n",
    "            \"TA\": entry.get(\"source_category\", {})\n",
    "        }\n",
    "        )\n",
    "    \n",
    " \n",
    "    print(f\"‚úÖ Hi√©rarchie construite: {len(hierarchy)} entr√©es totales\")\n",
    "    return hierarchy\n",
    "\n",
    "final_thesaurus = build_final_hierarchy(raw_aeronautics_data)\n",
    "print(f\"üéØ Th√©saurus final: {len(final_thesaurus)} entr√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdc1047",
   "metadata": {},
   "source": [
    "### Export du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc3e345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ EXPORT FINAL UNIQUE - CSV Occidental European Format (semicolon separated)\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def export_final_thesaurus(thesaurus_data):\n",
    "    \"\"\"Exporte le th√©saurus final en CSV (point-virgule, format europ√©en) et JSON\"\"\"\n",
    "    print(\"üíæ EXPORT FINAL UNIQUE\")\n",
    "    print(\"=\"*25)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 1. Export CSV - Occidental European (semicolon separator, utf-8-sig BOM)\n",
    "    csv_filename = f\"thesaurus_aeronautique_FINAL_{timestamp}.csv\"\n",
    "    csv_filepath = os.path.join(output_dir, csv_filename)\n",
    "    \n",
    "    fieldnames = [\n",
    "        'ID', 'Terme', 'ID_TG','TG', 'Def', 'EP',\n",
    "        'TA'\n",
    "    ]\n",
    "    \n",
    "    print(f\"üìÑ Export CSV: {csv_filename}\")\n",
    "    with open(csv_filepath, 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
    "        writer = csv.DictWriter(\n",
    "            csvfile, \n",
    "            fieldnames=fieldnames,\n",
    "            delimiter=';',         # Use semicolon as separator\n",
    "            quoting=csv.QUOTE_MINIMAL\n",
    "        )\n",
    "        writer.writeheader()\n",
    "        for entry in sorted(thesaurus_data, key=lambda x: x[\"ID\"]):\n",
    "            # Ensure all values are strings and convert None to empty string\n",
    "            row = {k: ('' if v is None else str(v)) for k, v in entry.items()}\n",
    "            # Guarantee all required fields exist in row\n",
    "            for field in fieldnames:\n",
    "                row.setdefault(field, '')\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    # 2. Export JSON avec m√©tadonn√©es\n",
    "    json_filename = f\"thesaurus_aeronautique_FINAL_{timestamp}.json\"\n",
    "    json_filepath = os.path.join(output_dir, json_filename)\n",
    "    \n",
    "    stats = analyze_thesaurus_statistics(thesaurus_data)\n",
    "    \n",
    "    json_data = {\n",
    "        \"metadata\": {\n",
    "            \"title\": \"Th√©saurus A√©ronautique Final - Wikidata\",\n",
    "            \"description\": \"Th√©saurus exhaustif avec hi√©rarchie et parents imm√©diats\",\n",
    "            \"version\": \"1.0-FINAL\",\n",
    "            \"created\": timestamp,\n",
    "            \"source\": \"Wikidata SPARQL optimis√©\",\n",
    "            \"total_entries\": len(thesaurus_data),\n",
    "            \"extraction_method\": \"multi-query_hierarchical\",\n",
    "            \"parent_detection\": \"automatic_wikidata_relations\",\n",
    "            \"multilingual_support\": True,\n",
    "            \"format\": \"structured_hierarchical_thesaurus\"\n",
    "        },\n",
    "        \"statistics\": stats,\n",
    "        \"data\": thesaurus_data\n",
    "    }\n",
    "    \n",
    "    print(f\"üìÑ Export JSON: {json_filename}\")\n",
    "    with open(json_filepath, 'w', encoding='utf-8') as jsonfile:\n",
    "        json.dump(json_data, jsonfile, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    return csv_filepath, json_filepath, stats\n",
    "\n",
    "def analyze_thesaurus_statistics(thesaurus_data):\n",
    "    \"\"\"Analyse les statistiques du th√©saurus final\"\"\"\n",
    "    stats = {\n",
    "        \"total_entries\": len(thesaurus_data),\n",
    "        \"categories\": {},\n",
    "        \"relation_types\": {},\n",
    "        \"languages\": {},\n",
    "        \"hierarchy_depth\": 0,\n",
    "        \"entries_with_synonyms\": 0,\n",
    "        \"entries_with_descriptions\": 0\n",
    "    }\n",
    "    \n",
    "    for entry in thesaurus_data:\n",
    "        # Cat√©gories\n",
    "        category = entry.get(\"category\", \"unknown\")\n",
    "        stats[\"categories\"][category] = stats[\"categories\"].get(category, 0) + 1\n",
    "        \n",
    "        # Types de relation\n",
    "        rel_type = entry.get(\"relation_type\", \"unknown\")\n",
    "        stats[\"relation_types\"][rel_type] = stats[\"relation_types\"].get(rel_type, 0) + 1\n",
    "        \n",
    "        # Langues\n",
    "        lang = entry.get(\"lang\", \"unknown\")\n",
    "        stats[\"languages\"][lang] = stats[\"languages\"].get(lang, 0) + 1\n",
    "        \n",
    "        # Enrichissements\n",
    "        if entry.get(\"synonyms\"):\n",
    "            stats[\"entries_with_synonyms\"] += 1\n",
    "        if entry.get(\"description\"):\n",
    "            stats[\"entries_with_descriptions\"] += 1\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def display_final_summary(stats, csv_file, json_file):\n",
    "    \"\"\"Affiche un r√©sum√© final du th√©saurus g√©n√©r√©\"\"\"\n",
    "    print(\"\\nüéØ R√âSUM√â FINAL DU TH√âSAURUS A√âRONAUTIQUE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"üìä STATISTIQUES G√âN√âRALES:\")\n",
    "    print(f\"   ‚Ä¢ Total d'entr√©es: {stats['total_entries']}\")\n",
    "    print(f\"   ‚Ä¢ Entr√©es avec synonymes: {stats['entries_with_synonyms']}\")\n",
    "    print(f\"   ‚Ä¢ Entr√©es avec descriptions: {stats['entries_with_descriptions']}\")\n",
    "    \n",
    "    print(f\"\\nüìÇ R√âPARTITION PAR CAT√âGORIE:\")\n",
    "    for category, count in sorted(stats[\"categories\"].items(), key=lambda x: x[1], reverse=True):\n",
    "        percentage = (count / stats['total_entries']) * 100\n",
    "        print(f\"   ‚Ä¢ {category}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nüîó TYPES DE RELATIONS:\")\n",
    "    for rel_type, count in sorted(stats[\"relation_types\"].items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"   ‚Ä¢ {rel_type}: {count}\")\n",
    "    \n",
    "    print(f\"\\nüåê LANGUES:\")\n",
    "    for lang, count in stats[\"languages\"].items():\n",
    "        print(f\"   ‚Ä¢ {lang}: {count}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ FICHIERS G√âN√âR√âS:\")\n",
    "    print(f\"   ‚úÖ CSV: {os.path.basename(csv_file)}\")\n",
    "    print(f\"   ‚úÖ JSON: {os.path.basename(json_file)}\")\n",
    "    \n",
    "    print(f\"\\nüèÜ MISSION ACCOMPLIE !\")\n",
    "    print(f\" {stats['total_entries']} entr√©es de th√©saurus\")\n",
    "\n",
    "# Export et r√©sum√© final\n",
    "if final_thesaurus:\n",
    "    csv_file, json_file, statistics = export_final_thesaurus(final_thesaurus)\n",
    "    display_final_summary(statistics, csv_file, json_file)\n",
    "else:\n",
    "    print(\"‚ùå Aucun th√©saurus √† exporter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d148f58",
   "metadata": {},
   "source": [
    "### Nettoyage des doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27f6dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire le CSV (remplace 'ton_fichier.csv' par le tien)\n",
    "df = pd.read_csv(csv_file, sep=';', dtype=str).fillna('')\n",
    "\n",
    "# Fonction pour concat√©ner les valeurs uniques (s√©par√©es par \"|\")\n",
    "def concat_unique(series):\n",
    "    uniques = set([v.strip() for v in series if v.strip() != ''])\n",
    "    return \" | \".join(sorted(uniques)) if uniques else ''\n",
    "\n",
    "# Grouper par 'ID', en concat√©nant les valeurs diff√©rentes pour chaque colonne\n",
    "df_clean = df.groupby('ID', as_index=False).agg(concat_unique)\n",
    "\n",
    "# Sauvegarder le r√©sultat\n",
    "df_clean.to_csv(csv_file, sep=';', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"‚úÖ CSV nettoy√© et export√© sous {csv_file}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
